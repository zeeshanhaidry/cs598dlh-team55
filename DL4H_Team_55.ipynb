{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGRuTbxYyOHp"
      },
      "source": [
        "# Deep Learning for Healthcare Team 55 Project\n",
        "### Zeeshan Haidry, Hamza Mahmood, Nithin Nathan\n",
        "\n",
        "Team 55 GitHub Repo: https://github.com/zeeshanhaidry/cs598dlh-team55\n",
        "\n",
        "Video: https://mediaspace.illinois.edu/media/t/1_x24myjzn\n",
        "\n",
        "Project based on:\n",
        "Fayyaz H, Strang A, Beheshti R. Bringing At-home Pediatric Sleep Apnea Testing Closer to Reality: A Multi-modal Transformer Approach. Proc Mach Learn Res. 2023 Aug;219:167-185. PMID: 38344396; PMCID: PMC10854997.\n",
        "\n",
        "Original GitHub: https://github.com/healthylaife/Pediatric-Apnea-Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfk8Zrul_E8V"
      },
      "outputs": [],
      "source": [
        "# instead of drive, we will be using uofi box\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tf3Il_ls9eQ",
        "outputId": "39ffabfe-2b1c-4f44-fd1e-03ea706fccaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biosppy\n",
            "  Downloading biosppy-2.2.1-py2.py3-none-any.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.3/149.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: bidict in /usr/local/lib/python3.10/dist-packages (from biosppy) (0.23.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from biosppy) (3.9.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from biosppy) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.11.4)\n",
            "Collecting shortuuid (from biosppy)\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.4.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from biosppy) (4.8.0.76)\n",
            "Requirement already satisfied: pywavelets in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.6.0)\n",
            "Collecting mock (from biosppy)\n",
            "  Downloading mock-5.1.0-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->biosppy) (3.5.0)\n",
            "Installing collected packages: shortuuid, mock, biosppy\n",
            "Successfully installed biosppy-2.2.1 mock-5.1.0 shortuuid-1.0.13\n",
            "Collecting boxsdk\n",
            "  Downloading boxsdk-3.9.2-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from boxsdk) (23.2.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from boxsdk) (2.0.7)\n",
            "Requirement already satisfied: requests<3,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from boxsdk) (2.31.0)\n",
            "Collecting requests-toolbelt>=0.4.0 (from boxsdk)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from boxsdk) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.4.3->boxsdk) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.4.3->boxsdk) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.4.3->boxsdk) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->boxsdk) (1.16.0)\n",
            "Installing collected packages: requests-toolbelt, boxsdk\n",
            "Successfully installed boxsdk-3.9.2 requests-toolbelt-1.0.0\n",
            "Collecting mne==1.0\n",
            "  Downloading mne-1.0.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (4.66.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (1.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (24.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (3.1.3)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne==1.0) (4.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne==1.0) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne==1.0) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne==1.0) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne==1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne==1.0) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne==1.0) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne==1.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne==1.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne==1.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mne==1.0) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne==1.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne==1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne==1.0) (2024.2.2)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.0.0\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# download dependencies\n",
        "\n",
        "!pip install biosppy\n",
        "!pip install boxsdk\n",
        "!pip install mne==1.0\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow-addons\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_IZxkMKF8ge"
      },
      "outputs": [],
      "source": [
        "# authenticate to connect to uofi box\n",
        "\n",
        "# Data was uploaded to box from sleepdata website. (Link provided in data section)\n",
        "# Commented to allow remaining of project to run since secrets might not be setup.\n",
        "\n",
        "from google.colab import userdata\n",
        "from boxsdk import Client, OAuth2, CCGAuth\n",
        "from boxsdk.object import file, folder\n",
        "from pprint import pformat\n",
        "import json\n",
        "\n",
        "# CLIENT_ID = userdata.get('clientid2')\n",
        "# CLIENT_SECRET = userdata.get('clientsecret2')\n",
        "# ACCESS_TOKEN = userdata.get('token2')\n",
        "\n",
        "# oauth2 = OAuth2(CLIENT_ID, CLIENT_SECRET, access_token=ACCESS_TOKEN)\n",
        "# client = Client(oauth2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ0sNuMePBXx"
      },
      "source": [
        "# Introduction\n",
        "This is an introduction to your report, you should edit this text/mardown section to compose. In this text/markdown, you should introduce:\n",
        "\n",
        "*   Background of the problem\n",
        "  * what type of problem: disease/readmission/mortality prediction,  feature engineeing, data processing, etc\n",
        "  * what is the importance/meaning of solving the problem\n",
        "  * what is the difficulty of the problem\n",
        "  * the state of the art methods and effectiveness.\n",
        "*   Paper explanation\n",
        "  * what did the paper propose\n",
        "  * what is the innovations of the method\n",
        "  * how well the proposed method work (in its own metrics)\n",
        "  * what is the contribution to the reasearch regime (referring the Background above, how important the paper is to the problem).\n",
        "\n",
        "---\n",
        "\n",
        "Obstructive sleep apnea hypopnea syndrome (OSAHS) is a breathing disorder where breathing is obstructed while sleeping (Loughlin Et al, 1996). Sleep apnea affects 1%-5% of children in the United States and can lead to other health illnesses if left untreated (Loughlin Et al, 1996; Marcus et al, 2012). Currently, at-home diagnostic tools for sleep apnea are only available for adults, leaving room for models to be created to address the needs for children (Fayyaz et al, 2023). The current state-of-the-art sleep apnea detection models created for adults (CNN (Chang et al., 2020), SE-MSCNN (Chen et al., 2022), CNN+LSTM (Zarei et al., 2022), Hybrid Transformer (Hu et al., 2022)) are effective but cannot be used for children because the sleep data differs between the two, and OSAHS symptoms for children require more attention (Choi et al, 2010; Gipson et al, 2019).\n",
        "\n",
        "Polysomnography is commonly used to diagnose OSAHS. This process is used to collect various signals while sleeping such as brain activity (EEG), eye movement (EOG), heart rhythm (ECG), blood oxygen saturation (SpO2), blood CO2 levels (ETCO2), and air flow. Although polysomnography is the best method to diagnose OSAHS, it is complex, costly, intrusive, and requires clinician involvement (Spielmanns et al, 2019). Because of these issues, it is not easy for children and their families to use polysomnography to detect OSAHS at home. To address these issues, Fayyaz et al. propose a transformer-based model to help detect OSAHS in children.  Additionally, they compared using all the available polysomnography modalities to only a subset of the available modalities in the model, which is important because a subset of modalities may be significantly easier to collect at home, so finding if a subset performs as well as all polysomnography modalities data increases the feasibility of at-home detection. In terms of metrics like F1 score and AUROC, the proposed transformer-based model outperforms the current state-of-the-art sleep apnea detection models, and an additional edge of factoring demographic data into the modalities improves the proposed model’s performance even further.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uygL9tTPSVHB"
      },
      "source": [
        "# Scope of Reproducibility:\n",
        "\n",
        "List hypotheses from the paper you will test and the corresponding experiments you will run.\n",
        "---\n",
        "\n",
        "The present study is based on the primary hypothesis that it is possible to achieve adult-level performance in detecting OSAHS. Specifically, through a custom transformer-based neural network, and its input in the form of preprocessed ECG and SPO2 signals, we hypothesize that we can effectively study and classify apnea-hypopnea in children."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      },
      "source": [
        "# Methodology\n",
        "\n",
        "This methodology is the core of your project. It consists of run-able codes with necessary annotations to show the expeiment you executed for testing the hypotheses.\n",
        "\n",
        "The methodology contains three subsections for our experiment: **environment**, **data**, and **model** in your experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lstJJxS5rEc"
      },
      "source": [
        "# Environment\n",
        "\n",
        "Several libraries/packages were used in our experiment. **Python 3** (Version Python 3.10 specifically) was the primary programming language and version used; other libraries/packages used are described below:\n",
        "\n",
        "---\n",
        "\n",
        "- boxsdk.Client\n",
        "- boxsdk.OAuth2\n",
        "- boxsdk.CCGAuth\n",
        "- boxsdk.object.file\n",
        "- boxsdk.object.folder\n",
        "\n",
        "**The boxsdk package was used to make API calls to Box API. Package was very helpful with downloading files for pre-processing & reuploading processed data for later use with models.**\n",
        "\n",
        "---\n",
        "\n",
        "- csv\n",
        "- xml.etree.ElementTree\n",
        "\n",
        "**These two packages were used to convert XML files to TSV files before they could be preprocessed.**\n",
        "\n",
        "---\n",
        "\n",
        "- gdown\n",
        "\n",
        "**The gdown package was used to download pre-trained model and loaded data for evaluation purposes.**\n",
        "\n",
        "---\n",
        "\n",
        "- glob\n",
        "\n",
        "**The glob package was used to iterate through root path and search for all .edf files.**\n",
        "\n",
        "---\n",
        "\n",
        "- keras\n",
        "- keras.Model\n",
        "-\tkeras.callbacks.LearningRateScheduler\n",
        "-\tkeras.EarlyStopping\n",
        "-\tkeras.activations.sigmoid\n",
        "-\tkeras.activations.relu\n",
        "-\tkeras.layers.Dense\n",
        "-\tkeras.layers.Input\n",
        "-\tkeras.layers.Conv1D\n",
        "-\tkeras.layers.SeparableConvolution1D\n",
        "-\tkeras.layers.concatenate\n",
        "-\tkeras.layers.Layer\n",
        "-\tkeras.layers.MultiHeadAttention\n",
        "-\tkeras.layers.Add\n",
        "-\tkeras.layers.LayerNormalization\n",
        "-\tkeras.layers.Dropout\n",
        "-\tkeras.layers.GlobalAveragePooling1D\n",
        "-\tkeras.regularizers.L2\n",
        "-\tkeras.losses.BinaryCrossentropy\n",
        "\n",
        "**Keras is an open-source library that provides functionality to build and train deep learning models. The above packages were all used in the building and training of our transformer model.**\n",
        "\n",
        "---\n",
        "\n",
        "- mne == 1.0\n",
        "\n",
        "**The mne package was used to work with several types of neurophysiological data. Specifically in our project, the package was used to load study and annotation data during the preprocessing phase. A specific version was used to match was what used in the original paper.**\n",
        "\n",
        "---\n",
        "\n",
        "- numpy\n",
        "\n",
        "**The numpy package was used to load and save data as .npz files to be fed into the transformer model.**\n",
        "\n",
        "---\n",
        "\n",
        "- os\n",
        "\n",
        "**The os package was used for several miscellaneous operations, such as making new directories, access different paths, and rename directories, just to name a few.**\n",
        "\n",
        "---\n",
        "\n",
        "- PediatricApneaDetection.data.chat.preprocessing\n",
        "-\tPediatricApneaDetection.data.chat.dataloader\n",
        "-\tPediatricApneaDetection.metrics.Result\n",
        "\n",
        "**These packages were borrowed from the original paper and modified to run with our code due to hardcoded values that were used in the original paper.**\n",
        "\n",
        "---\n",
        "\n",
        "- tensorflow\n",
        "-\ttensorflow-addons\n",
        "-\ttensorflow_addons\n",
        "-\ttensorflow.python.client.device_lib\n",
        "\n",
        "**Tensorflow is an open-source library used for computation and calculation of data by several machine learning and artificial intelligence models. The above packages were used throughout the building, training, and testing of our transformer model.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81txHSSEEPlW",
        "outputId": "52909237-d3e8-47f9-9898-22ab558cc65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Pediatric-Apnea-Detection'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 75 (delta 33), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (75/75), 31.40 KiB | 1.01 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n"
          ]
        }
      ],
      "source": [
        "# we will be re-using the authors code for data pre-processing and loading, we will also extract some code for the model\n",
        "!git clone https://github.com/healthylaife/Pediatric-Apnea-Detection.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "VSsNiJsK3BDk",
        "outputId": "88482878-bfa8-4289-c76d-5f068c670578"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 39] Directory not empty: 'Pediatric-Apnea-Detection/' -> 'PediatricApneaDetection/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b985a4ba405c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Pediatric-Apnea-Detection/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'PediatricApneaDetection/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m: [Errno 39] Directory not empty: 'Pediatric-Apnea-Detection/' -> 'PediatricApneaDetection/'"
          ]
        }
      ],
      "source": [
        "# rename cloned github folder for easier access to its functions\n",
        "\n",
        "import os\n",
        "source = 'Pediatric-Apnea-Detection/'\n",
        "dest = 'PediatricApneaDetection/'\n",
        "os.rename(source, dest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "outputs": [],
      "source": [
        "# import packages needed for data preprocessing, loading, and model training/testing\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import keras\n",
        "from keras import Model\n",
        "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
        "from keras.activations import sigmoid, relu\n",
        "from keras.layers import Dense, Input, Conv1D, SeparableConvolution1D, concatenate, Layer, MultiHeadAttention, Add, LayerNormalization, Dropout, GlobalAveragePooling1D\n",
        "from keras.regularizers import L2\n",
        "from keras.losses import BinaryCrossentropy\n",
        "\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeTeJKQiwVt0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ea1941-e5a4-44cd-a33a-99b811abd719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 10660083710439385681\n",
            "xla_global_id: -1\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "#check if gpu available.\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NbPHUTMbkD3"
      },
      "source": [
        "##  Data\n",
        "Data includes raw data (MIMIC III tables), descriptive statistics (our homework questions), and data processing (feature engineering).\n",
        "  * Source of the data: where the data is collected from; if data is synthetic or self-generated, explain how. If possible, please provide a link to the raw datasets.\n",
        "  * Statistics: include basic descriptive statistics of the dataset like size, cross validation split, label distribution, etc.\n",
        "  * Data process: how do you munipulate the data, e.g., change the class labels, split the dataset to train/valid/test, refining the dataset.\n",
        "  * Illustration: printing results, plotting figures for illustration.\n",
        "  * You can upload your raw dataset to Google Drive and mount this Colab to the same directory. If your raw dataset is too large, you can upload the processed dataset and have a code to load the processed dataset.\n",
        "\n",
        "---\n",
        "\n",
        "Data Download Instructions:\n",
        "The data is collected from the National Sleep Research Resource, an NHLBI-supported repository responsible for sharing large amounts of sleep data from various cohorts, clinical trials, and other data sources to advance sleep and circadian science. The two datasets we used can be found at these links: https://sleepdata.org/datasets/chat and https://sleepdata.org/datasets/nchsdb. Please note that we each individually needed to complete a survey intake form and get it approved by the organization in order to get access to this data.  \n",
        "\n",
        "The original authors utilized two different datasets, one from a Childhood Adenotonsillectomy Trial (CHAT)\n",
        "And the other from the NCH Sleep Data Bank (NCHSDB).\n",
        "The CHAT dataset is roughly 969 GB in size and was collected from 1,243 subjects ages 5-9 over a period of 5 years (2007-2012). The NCHSDB dataset is roughly 2.07 TB in size and was collected from 3,673 subjects ages 0-58 over a period of 2 years (2017-2019).\n",
        "Both datasets were pre-processed to only include necessary attributes before being loaded into the model for training and testing.\n",
        "\n",
        "Due to Colab only allowing for 70GB of hard drive space, we limited our report to only compare the CHAT dataset to the original paper's results.\n",
        "\n",
        "The raw data has been uploaded to a Box account for storage since the University of Illinois provides us with unlimited Box storage. Because of the limited space in Colab, we repeatedly downloaded a subset of the data, pre-processed it, uploaded the processed data, and cleared the workspace. This was beneficial because the processed dataset was about 10% the size of the raw. So to maximize how much data was used in training/testing, we prepared approximately 73 GB of processed data (~200 files, ~700GB raw data).\n",
        "\n",
        "When it came to training the model, we realized the free version of Colab only offered 12GB of RAM, which would not be enough for the size of our data. We upgraded to the premium version of Colab that allowed for ~50GB of RAM. To make sure our data was able to loaded into memory, we only used 44GB of processed data when training and testing our models. As shown below, this was the right decision because training the 6-signal model used 41GB/51Gb of available RAM. Using more data would lead to the environment crashing.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1mFozLUT2fKusICCougiB1knnS6FMT5Ud\"/>\n",
        "</div>\n",
        "\n",
        "Two file types are used for the CHAT data construction, a \\*.edf file containing time-series for multiple signals and a \\*-nsrr.xml that contains annotations of the dataset. These annotations described events that happened during the study such as obstructive apnea, central apnea, hypopnea, SpO2 desaturation, EtCO2 artifact, limb movements, etc. These events include event type/concept (description), start time (onset), and duration.\n",
        "\n",
        "For this model, we only consider apnea (Obstructive and Central grouped together) and hypopnea events.\n",
        "\n",
        "To run this notebook, the CHAT data from the sleep data site will need to be uploaded to the /chatdata/ path. Only the \\*.edf and \\*-nsrr.xml files are needed from the chat/polysomnography/edfs and chat/polysomnography/annoations-events-nsrr subdirectories in https://sleepdata.org/datasets/chat/ ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9BmsYS95LIq"
      },
      "outputs": [],
      "source": [
        "#Commented to allow rest of the nodebook to run. (No Data processing/loading/training for Submission)\n",
        "# We have the data loaded and saved, so we can avoid using compute time to download processed data and create the datasets.\n",
        "# Commented below. Instead we will just download \"chatloader\" to download the usable dataset for moedl training.\n",
        "\n",
        "def downloadFromBox(filepath, file_content):\n",
        "  with open(filepath, \"wb\") as binary_file:\n",
        "    binary_file.write(file_content)\n",
        "\n",
        "fields = [\n",
        "    'type',\n",
        "    'id',\n",
        "    'name',\n",
        "]\n",
        "\n",
        "#First Download processed data from box. Store filenames in list so we don't reupload same file.\n",
        "chat_out = '/content/chatprocessed/'\n",
        "os.makedirs(os.path.dirname(chat_out), exist_ok=True)\n",
        "# folder_chatprocessed = client.folder(folder_id='261105873173').get_items(fields=fields)\n",
        "#Only download 119 processed files because that is all that fits in Colab and enough room for data loading + model.\n",
        "# i = 0\n",
        "# for item in folder_chatprocessed:\n",
        "#   if(i>119):\n",
        "#     break\n",
        "#   print(f'download \"{item.name}\"')\n",
        "#   file_content = client.file(item.id).content()\n",
        "#   downloadFromBox(chat_out + item.name, file_content)\n",
        "#   i+=1\n",
        "\n",
        "# processed_data = os.listdir(chat_out)\n",
        "\n",
        "#get files already pre-processed so we don't do it again\n",
        "# processed_data = []\n",
        "# for item in folder_chatprocessed:\n",
        "#   print(f' \"{item.name}\"')\n",
        "#   processed_data.append(item.name)\n",
        "# print(processed_data)\n",
        "# print(\"total processed: \" + str(len(processed_data)))\n",
        "\n",
        "#Second, download raw + annot data from BOX that is not already downloaded, not in badFiles list and is not in in processed (So we don't have to re-process data)\n",
        "chat_data = '/chatdata/'\n",
        "os.makedirs(os.path.dirname(chat_data), exist_ok=True)\n",
        "curr_downloaded = os.listdir(chat_data)\n",
        "\n",
        "#empirically known bad files (such as missing signals)\n",
        "badFiles = [\"chat-baseline-300567.edf\",\"chat-baseline-300554.edf\",\"chat-baseline-300452.edf\",\"chat-baseline-300013.edf\",\"chat-baseline-300108.edf\",\"chat-baseline-300051.edf\",\"chat-baseline-300078.edf\",\"chat-baseline-300037.edf\",\"chat-baseline-300195.edf\",\"chat-baseline-300206.edf\",\"chat-baseline-300310.edf\",\"chat-baseline-300203.edf\",\"chat-baseline-300277.edf\",\"chat-baseline-300260.edf\",\"chat-baseline-300189.edf\",\"chat-baseline-300379.edf\"]\n",
        "\n",
        "#Do not need any more raw data - all data we can fit in instance is already processed.\n",
        "#Commented out below.\n",
        "\n",
        "# folder_raw = client.folder(folder_id='257515840362').get_items(fields=fields)\n",
        "# folder_annot = client.folder(folder_id='257513450272').get_items(fields=fields)\n",
        "filenames = curr_downloaded\n",
        "\n",
        "# i = 0\n",
        "# for item in folder_raw:\n",
        "#   if i>=60:\n",
        "#     break\n",
        "#   if not any(processed.startswith(item.name.split('.')[0]) for processed in processed_data) and item.name not in curr_downloaded and item.name not in badFiles:\n",
        "#     print(f'download \"{item.name}\"')\n",
        "#     file_content = client.file(item.id).content()\n",
        "#     downloadFromBox(chat_data + item.name, file_content)\n",
        "#     filenames.append(item.name)\n",
        "#     i = i + 1\n",
        "# print(filenames)\n",
        "# for item in folder_annot:\n",
        "#   if (item.name.split('-nsrr')[0] + '.edf') in filenames and item.name not in curr_downloaded:\n",
        "#     print(f'download \"{item.name}\"')\n",
        "#     file_content = client.file(item.id).content()\n",
        "#     downloadFromBox(chat_data + item.name, file_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msTebL2k6DvA"
      },
      "source": [
        "### Data Descriptions\n",
        "\n",
        "Below is a screeenshot showing the data columns from one of the CHAT dataset's annotation -nssr.xml file. As you can see, there is a signal value recorded for a given start time and duration.\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1bjYVAm0lduaG1F227PZHmPt0uH3x9HNZ\" width=\"400\" height=\"350\"/>\n",
        "</div>\n",
        "\n",
        "\n",
        "Additionally, the below code prints out snippet of what the raw .edf file data looks like.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9i4-ihAY59r",
        "outputId": "bb29fdc1-d3cb-40e1-f8c7-1c8d9bc56648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /chatdata/chat-baseline-300008.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        }
      ],
      "source": [
        "# commenting out so it doesnt throw error \"file does not exist\"\n",
        "# --------------------\n",
        "# import mne\n",
        "# file = \"/chatdata/chat-baseline-300008.edf\"\n",
        "# data = mne.io.read_raw_edf(file)\n",
        "# raw_data = data.get_data()\n",
        "# # you can get the metadata included in the file and a list of all channels:\n",
        "# info = data.info\n",
        "# channels = data.ch_names"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Raw data signals"
      ],
      "metadata": {
        "id": "gwvKKEV11XVY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T72Ks0t-cMHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1147038-cff4-4857-ab69-6f6a88894030"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.50505837e-05, -4.86258624e-05, -4.24165772e-05, ...,\n",
              "        -5.09971622e-04, -5.09976474e-04, -5.09981432e-04],\n",
              "       [-5.30242466e-05, -6.03679164e-05, -6.27936028e-05, ...,\n",
              "        -5.11971445e-04, -5.11976290e-04, -5.11981293e-04],\n",
              "       [-4.56335088e-05, -5.31779551e-05, -5.48853706e-05, ...,\n",
              "        -5.11971510e-04, -5.11976382e-04, -5.11981359e-04],\n",
              "       ...,\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
              "       [ 4.00000000e+01,  4.00000000e+01,  4.00000000e+01, ...,\n",
              "         4.00000000e+01,  4.00000000e+01,  4.00000000e+01]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# raw_data # this is raw signal data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Raw data shape -- 39 channels and each have 33256448 values, at least for this data file sample"
      ],
      "metadata": {
        "id": "xsRGTSy81Zvj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPipTwA-dGGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd017a3b-840a-49f0-cc85-f0214e981b1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39, 33256448)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# raw_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_kV9Japc6xn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "69bc2c9d-70bb-48b8-e554-2187a7008c8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Info | 7 non-empty values\n",
              " bads: []\n",
              " ch_names: Cchin, F3, F4, C3, C4, O1, O2, T3, T4, M1, M2, E1, E2, ECG1, ...\n",
              " chs: 39 EEG\n",
              " custom_ref_applied: False\n",
              " highpass: 0.0 Hz\n",
              " lowpass: 512.0 Hz\n",
              " meas_date: 1985-01-01 21:03:39 UTC\n",
              " nchan: 39\n",
              " projs: []\n",
              " sfreq: 1024.0 Hz\n",
              ">"
            ],
            "text/html": [
              "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
              "    <tr>\n",
              "        <th>Measurement date</th>\n",
              "        \n",
              "        <td>January 01, 1985  21:03:39 GMT</td>\n",
              "        \n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Experimenter</th>\n",
              "        \n",
              "        <td>Unknown</td>\n",
              "        \n",
              "    </tr>\n",
              "        <th>Participant</th>\n",
              "        \n",
              "        <td>Unknown</td>\n",
              "        \n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Digitized points</th>\n",
              "        \n",
              "        <td>0 points</td>\n",
              "        \n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Good channels</th>\n",
              "        <td>39 EEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Bad channels</th>\n",
              "        <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>EOG channels</th>\n",
              "        <td>Not available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>ECG channels</th>\n",
              "        <td>Not available</td>\n",
              "    \n",
              "    <tr>\n",
              "        <th>Sampling frequency</th>\n",
              "        <td>1024.00 Hz</td>\n",
              "    </tr>\n",
              "    \n",
              "    \n",
              "    <tr>\n",
              "        <th>Highpass</th>\n",
              "        <td>0.00 Hz</td>\n",
              "    </tr>\n",
              "    \n",
              "    \n",
              "    <tr>\n",
              "        <th>Lowpass</th>\n",
              "        <td>512.00 Hz</td>\n",
              "    </tr>\n",
              "    \n",
              "    \n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# info # metadata info"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###All \"channels\" in the given raw data file"
      ],
      "metadata": {
        "id": "2_DHWB571cDR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J88bQWPc9hQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432e5be1-dee5-42b5-c821-42b8886f27c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Cchin', 'F3', 'F4', 'C3', 'C4', 'O1', 'O2', 'T3', 'T4', 'M1', 'M2', 'E1', 'E2', 'ECG1', 'ECG2', 'ECG3', 'Lleg1', 'Lleg2', 'Rleg1', 'Rleg2', 'LChin', 'RChin', 'Airflow', 'ABD', 'Chest', 'Snore', 'Sum', 'Position', 'OxSTAT', 'Pulse', 'SAO2', 'CannulaFlow', 'Cap', 'C-Pres', 'EtCO2', 'Pleth', 'Light', 'ManPos', 'DHR']\n"
          ]
        }
      ],
      "source": [
        "# print(channels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhTUi_pRthQl"
      },
      "source": [
        "## Annotation file conversion + Pre-processing\n",
        "Annotation File is required to be in tsv format in the paper's provided code.\n",
        "Since the Sleep data site only had this in XML, we had to convert it and change column names as shown below.\n",
        "\n",
        "The Pre-processing code does the following:\n",
        "\n",
        "\n",
        "*   Loads study using raw \\*.edf and annotations \\*-nsrr.tsv file using mne library. Annoations file is read in as a dataframe. (pandas read_cdv)\n",
        "*   Checks if required channels are avaiable in the study. If not, it is discarded.\n",
        "*   Finds event ids of apnea and hypopnea events in annoations\n",
        "*   Select specific channels from raw file.\n",
        "*   Signals are divided into equal length epochs (authors chose **30 EPOCH_LENGTH**),\n",
        "*   Epochs are resampled to a **frequency of 128**.\n",
        "*   For each Epoch, the intersection between the apnea events and hypopnea events are found in seconds, and appended to a labels_apnea and labels_hypopnea array. Essentially, these labels contains seconds of apnea and hypopnea, respectively, for each epoch.\n",
        "*   The numpy array containing data, labels_apnea, and labels_hypopnea are saved.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqb5Jwsyh5P8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import xml.etree.ElementTree as ET\n",
        "import csv\n",
        "\n",
        "def convert_xml_to_tsv(xml_file):\n",
        "\n",
        "  # parse the xml file\n",
        "  tree = ET.parse(xml_file)\n",
        "  root = tree.getroot()\n",
        "\n",
        "  # grab the relevant fields from the xml - Start (onset) , Duration (Duration), EventType (Description)\n",
        "  fields = ['onset', 'duration', 'description']\n",
        "\n",
        "  # create new tsv file\n",
        "  tsv_file_name = xml_file.replace(\".xml\", \".tsv\")\n",
        "\n",
        "  # create csv writer object\n",
        "  csv_writer = csv.writer(open(tsv_file_name, 'w'), delimiter='\\t')\n",
        "\n",
        "  # write the header row\n",
        "  csv_writer.writerow(fields)\n",
        "\n",
        "  # iterate over the xml elements and extract the data we want\n",
        "  for element in root:\n",
        "\n",
        "      if element.tag == \"ScoredEvents\":\n",
        "\n",
        "        # this is all events\n",
        "        for event in element:\n",
        "\n",
        "          # this is single event\n",
        "          for attr in event:\n",
        "\n",
        "            if attr.tag == \"Start\":\n",
        "              onset = attr.text\n",
        "\n",
        "            if attr.tag == \"Duration\":\n",
        "              duration = attr.text\n",
        "\n",
        "            if attr.tag == \"EventConcept\":\n",
        "              description = attr.text.split(\"|\")[0]\n",
        "\n",
        "          # for field in fields\n",
        "          row = [onset, duration, description]\n",
        "\n",
        "          # write row to csv file\n",
        "          csv_writer.writerow(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eh5QH6ynXXc0"
      },
      "outputs": [],
      "source": [
        "#Commented to allow rest of notebook to run. (No Data processing/loading/training for Submission)\n",
        "#No more files need to be processed: commenting this out.\n",
        "# import glob\n",
        "# import mne\n",
        "# from PediatricApneaDetection.data.chat import preprocessing\n",
        "\n",
        "# root = \"/chatdata/\"\n",
        "# OUT_FOLDER = ''\n",
        "\n",
        "# for edf_file in glob.glob(root + \"*.edf\"):\n",
        "#     filename = edf_file.replace('/chatdata/','')\n",
        "#     if not any(processed.startswith(filename.split('.')[0]) for processed in processed_data):\n",
        "#         print(\"preprocessing \" + edf_file)\n",
        "\n",
        "#         annot_file = edf_file.replace(\".edf\", \"-nsrr.xml\")\n",
        "#         convert_xml_to_tsv(annot_file)\n",
        "#         annot_file_tsv = edf_file.replace(\".edf\", \"-nsrr.tsv\")\n",
        "\n",
        "#         # preprocess data\n",
        "#         shape = preprocessing.preprocess((edf_file, annot_file_tsv), preprocessing.identity, OUT_FOLDER)\n",
        "\n",
        "#         print(f\"final preprocessing shape: {shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F4GqitU8661"
      },
      "source": [
        "preprocessing 10 files took ~15min\n",
        "\n",
        "preprocessing 30 files took ~37 min\n",
        "\n",
        "preprocessing 50 files took ~57min\n",
        "\n",
        "preprocessing 60 files took 1hr+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNftpb3V3yt8",
        "outputId": "63224a03-5a65-4389-d31c-2f3ef0a67e20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/\\chat-baseline-300575.edf_221_164.npz\n",
            "/content/chatprocessed/chat-baseline-300575.edf_221_164.npz\n",
            "/content/\\chat-baseline-300555.edf_1125_1336.npz\n",
            "/content/chatprocessed/chat-baseline-300555.edf_1125_1336.npz\n",
            "/content/\\chat-baseline-300585.edf_320_899.npz\n",
            "/content/chatprocessed/chat-baseline-300585.edf_320_899.npz\n",
            "/content/\\chat-baseline-300571.edf_500_885.npz\n",
            "/content/chatprocessed/chat-baseline-300571.edf_500_885.npz\n",
            "/content/\\chat-baseline-300496.edf_931_791.npz\n",
            "/content/chatprocessed/chat-baseline-300496.edf_931_791.npz\n",
            "/content/\\chat-baseline-300594.edf_74_30.npz\n",
            "/content/chatprocessed/chat-baseline-300594.edf_74_30.npz\n",
            "/content/\\chat-baseline-300563.edf_31_184.npz\n",
            "/content/chatprocessed/chat-baseline-300563.edf_31_184.npz\n",
            "/content/\\chat-baseline-300566.edf_91_146.npz\n",
            "/content/chatprocessed/chat-baseline-300566.edf_91_146.npz\n",
            "/content/\\chat-baseline-300579.edf_134_87.npz\n",
            "/content/chatprocessed/chat-baseline-300579.edf_134_87.npz\n",
            "/content/\\chat-baseline-300573.edf_18_178.npz\n",
            "/content/chatprocessed/chat-baseline-300573.edf_18_178.npz\n",
            "/content/\\chat-baseline-300561.edf_52_236.npz\n",
            "/content/chatprocessed/chat-baseline-300561.edf_52_236.npz\n",
            "/content/\\chat-baseline-300560.edf_1085_819.npz\n",
            "/content/chatprocessed/chat-baseline-300560.edf_1085_819.npz\n",
            "/content/\\chat-baseline-300590.edf_81_9.npz\n",
            "/content/chatprocessed/chat-baseline-300590.edf_81_9.npz\n"
          ]
        }
      ],
      "source": [
        "# Commented to allow rest of notebook to run. (No Data processing/loading/training for Submission)\n",
        "# moves npz files to processed folder\n",
        "\n",
        "# root = '/content/'\n",
        "# chat_out = '/content/chatprocessed/'\n",
        "# os.makedirs(os.path.dirname(chat_out), exist_ok=True)\n",
        "\n",
        "# for npz_file in glob.glob(root + \"*.npz\"):\n",
        "\n",
        "#   print(npz_file)\n",
        "\n",
        "#   dest = chat_out + npz_file.replace(\"/content/\",\"\").replace(\"\\\\\",\"\")\n",
        "\n",
        "#   print(dest)\n",
        "\n",
        "#   os.rename(npz_file, dest)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7PJFlFeGk7M",
        "outputId": "3c0d083c-0842-48f0-9598-ad7b96d818dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chat-baseline-300573\n",
            "uploaded /content/chatprocessed/chat-baseline-300573.edf_18_178.npz\n",
            "chat-baseline-300563\n",
            "uploaded /content/chatprocessed/chat-baseline-300563.edf_31_184.npz\n",
            "chat-baseline-300575\n",
            "uploaded /content/chatprocessed/chat-baseline-300575.edf_221_164.npz\n",
            "chat-baseline-300555\n",
            "uploaded /content/chatprocessed/chat-baseline-300555.edf_1125_1336.npz\n",
            "chat-baseline-300561\n",
            "uploaded /content/chatprocessed/chat-baseline-300561.edf_52_236.npz\n",
            "chat-baseline-300566\n",
            "uploaded /content/chatprocessed/chat-baseline-300566.edf_91_146.npz\n",
            "chat-baseline-300579\n",
            "uploaded /content/chatprocessed/chat-baseline-300579.edf_134_87.npz\n",
            "chat-baseline-300496\n",
            "uploaded /content/chatprocessed/chat-baseline-300496.edf_931_791.npz\n",
            "chat-baseline-300585\n",
            "uploaded /content/chatprocessed/chat-baseline-300585.edf_320_899.npz\n",
            "chat-baseline-300571\n",
            "uploaded /content/chatprocessed/chat-baseline-300571.edf_500_885.npz\n",
            "chat-baseline-300560\n",
            "uploaded /content/chatprocessed/chat-baseline-300560.edf_1085_819.npz\n",
            "chat-baseline-300590\n",
            "uploaded /content/chatprocessed/chat-baseline-300590.edf_81_9.npz\n",
            "chat-baseline-300594\n",
            "uploaded /content/chatprocessed/chat-baseline-300594.edf_74_30.npz\n"
          ]
        }
      ],
      "source": [
        "#upload pre-processed to box for reusability.\n",
        "\n",
        "# for npz_file in glob.glob(chat_out + \"*.npz\"):\n",
        "#   #if not already uploaded\n",
        "#   filename = npz_file.replace('/content/chatprocessed/','')\n",
        "#   print(filename.split('.')[0])\n",
        "#   if not any(processed.startswith(filename.split('.')[0]) for processed in processed_data):\n",
        "#     client.folder(folder_id='261105873173').upload(npz_file)\n",
        "#     processed_data.append(filename)\n",
        "#     print(\"uploaded \" + npz_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWQj8JjAvafM"
      },
      "source": [
        "## CHAT Data Loading\n",
        "Chat Data Loading is done as dollowed:\n",
        "\n",
        "*   Path is provided containing processed \\*.npz files (from previous steps)\n",
        "*   Divide studies into folds (5 folds used here). For example, if 10 processed files are in the folder, each fold will have data from 2 processed files.\n",
        "*   For each study in each fold, the signals, apnea labels, and hypopnea labels are loaded.\n",
        "*   Then, the apnea labels and hypopnea labels are combined to y_c.\n",
        "*   To reduce the size of the data and improve model training performance, negative sampling is conducted. This is done by getting indexes for where y_c == 0 (negative samples) and where y_c>0 (positive samples). Then, a ratio between number of positive_samples and negative_samples is used to determine how many negative samples should be kept. The index of the kept negative_samples is stored in negative_survived as shown below. Only the indexes in negative_survived and positive_samples are kept in the data. This was done to ensure data quantity similarity between the positive and negative classes since there were more records associated with the negative class (no hypopnea).\n",
        "*   Extract_rri is used to ensure ECG signal has equal length data points to other signals (EPOCH_LENGTH * FREQ). This is 30\\*128=3840, which can be found in the model input size shown later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yz6fikII_F2p"
      },
      "outputs": [],
      "source": [
        "# due to hardcoded values, we had to copy the dataloader code and change it slightly to be able to run it\n",
        "# from - https://github.com/healthylaife/Pediatric-Apnea-Detection/blob/main/data/chat/dataloader.py\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.signal import resample\n",
        "from biosppy.signals.ecg import hamilton_segmenter, correct_rpeaks\n",
        "from biosppy.signals import tools as st\n",
        "from scipy.interpolate import splev, splrep\n",
        "\n",
        "from PediatricApneaDetection.data.chat import dataloader\n",
        "\n",
        "SIGS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
        "s_count = len(SIGS)\n",
        "\n",
        "FREQ = 128\n",
        "EPOCH_LENGTH = 30\n",
        "ECG_SIG = 8\n",
        "\n",
        "def load_data(path):\n",
        "    # demo = pd.read_csv(\"../misc/result.csv\")\n",
        "    # ahi = pd.read_csv(r\"C:\\Data\\AHI.csv\")\n",
        "    # ahi_dict = dict(zip(ahi.Study, ahi.AHI))\n",
        "    root_dir = os.path.expanduser(path)\n",
        "    file_list = os.listdir(root_dir)\n",
        "    print(file_list)\n",
        "    length = len(file_list)\n",
        "\n",
        "    ################################### Fold the data based on number of respiratory events #########################\n",
        "    study_event_counts = [i for i in range(0, length)]\n",
        "    folds = []\n",
        "    for i in range(5):\n",
        "        folds.append(study_event_counts[i::5])\n",
        "\n",
        "    x = []\n",
        "    y_apnea = []\n",
        "    y_hypopnea = []\n",
        "    counter = 0\n",
        "    for idx, fold in enumerate(folds):\n",
        "        first = True\n",
        "        for patient in fold:\n",
        "            rri_succ_counter = 0\n",
        "            rri_fail_counter = 0\n",
        "            counter += 1\n",
        "            print(counter)\n",
        "            # for study in glob.glob(PATH + patient[0] + \"_*\"):\n",
        "            study_data = np.load(path + file_list[patient - 1])\n",
        "            signals = study_data['data']\n",
        "            labels_apnea = study_data['labels_apnea']\n",
        "            labels_hypopnea = study_data['labels_hypopnea']\n",
        "\n",
        "            # identifier = study.split('\\\\')[-1].split('_')[0] + \"_\" + study.split('\\\\')[-1].split('_')[1]\n",
        "            # demo_arr = demo[demo['id'] == identifier].drop(columns=['id']).to_numpy().squeeze()\n",
        "\n",
        "            y_c = labels_apnea + labels_hypopnea\n",
        "            neg_samples = np.where(y_c == 0)[0]\n",
        "            pos_samples = list(np.where(y_c > 0)[0])\n",
        "            ratio = len(pos_samples) / len(neg_samples)\n",
        "            neg_survived = []\n",
        "            for s in range(len(neg_samples)):\n",
        "                if random.random() < ratio:\n",
        "                    neg_survived.append(neg_samples[s])\n",
        "            samples = neg_survived + pos_samples\n",
        "            signals = signals[samples, :, :]\n",
        "            labels_apnea = labels_apnea[samples]\n",
        "            labels_hypopnea = labels_hypopnea[samples]\n",
        "\n",
        "            data = np.zeros((signals.shape[0], EPOCH_LENGTH * FREQ, s_count + 2))\n",
        "            for i in range(signals.shape[0]):  # for each epoch\n",
        "                # data[i, :len(demo_arr), -3] = demo_arr\n",
        "                data[i, :, -1], data[i, :, -2], status = dataloader.extract_rri(signals[i, ECG_SIG, :], FREQ,\n",
        "                                                                     float(EPOCH_LENGTH))\n",
        "\n",
        "                if status:\n",
        "                    rri_succ_counter += 1\n",
        "                else:\n",
        "                    rri_fail_counter += 1\n",
        "\n",
        "                for j in range(s_count):  # for each signal\n",
        "                    data[i, :, j] = signals[i, SIGS[j], :]\n",
        "\n",
        "            if first:\n",
        "                aggregated_data = data\n",
        "                aggregated_label_apnea = labels_apnea\n",
        "                aggregated_label_hypopnea = labels_hypopnea\n",
        "                first = False\n",
        "            else:\n",
        "                aggregated_data = np.concatenate((aggregated_data, data), axis=0)\n",
        "                aggregated_label_apnea = np.concatenate((aggregated_label_apnea, labels_apnea), axis=0)\n",
        "                aggregated_label_hypopnea = np.concatenate((aggregated_label_hypopnea, labels_hypopnea), axis=0)\n",
        "            print(rri_succ_counter, rri_fail_counter)\n",
        "\n",
        "        x.append(aggregated_data)\n",
        "        y_apnea.append(aggregated_label_apnea)\n",
        "        y_hypopnea.append(aggregated_label_hypopnea)\n",
        "\n",
        "    return x, y_apnea, y_hypopnea\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW3u5Qi6ZOte",
        "outputId": "e21b5fd3-db62-43f0-8859-14a8eaf27d2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rmdir: failed to remove '/content/chatprocessed/.ipynb_checkpoints': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# remove file to avoid issues in dataload\n",
        "%rmdir /content/chatprocessed/.ipynb_checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiQ3LfV49mCN",
        "outputId": "3d9cb427-7879-43f4-a07b-aa5893a9af8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['chat-baseline-300315.edf_18_968.npz', 'chat-baseline-300295.edf_91_210.npz', 'chat-baseline-300242.edf_737_1500.npz', 'chat-baseline-300008.edf_186_103.npz', 'chat-baseline-300264.edf_132_275.npz', 'chat-baseline-300352.edf_52_167.npz', 'chat-baseline-300282.edf_99_661.npz', 'chat-baseline-300312.edf_113_83.npz', 'chat-baseline-300343.edf_210_160.npz', 'chat-baseline-300271.edf_220_815.npz', 'chat-baseline-300215.edf_1022_2853.npz', 'chat-baseline-300026.edf_305_783.npz', 'chat-baseline-300176.edf_170_885.npz', 'chat-baseline-300058.edf_23_180.npz', 'chat-baseline-300041.edf_300_264.npz', 'chat-baseline-300133.edf_89_256.npz', 'chat-baseline-300186.edf_310_355.npz', 'chat-baseline-300066.edf_169_135.npz', 'chat-baseline-300038.edf_77_305.npz', 'chat-baseline-300036.edf_486_607.npz', 'chat-baseline-300349.edf_172_429.npz', 'chat-baseline-300072.edf_240_345.npz', 'chat-baseline-300224.edf_639_1994.npz', 'chat-baseline-300019.edf_196_337.npz', 'chat-baseline-300052.edf_189_360.npz', 'chat-baseline-300185.edf_123_304.npz', 'chat-baseline-300194.edf_392_1326.npz', 'chat-baseline-300336.edf_348_255.npz', 'chat-baseline-300335.edf_112_205.npz', 'chat-baseline-300244.edf_331_71.npz', 'chat-baseline-300307.edf_39_440.npz', 'chat-baseline-300221.edf_267_527.npz', 'chat-baseline-300311.edf_447_390.npz', 'chat-baseline-300326.edf_644_718.npz', 'chat-baseline-300025.edf_57_189.npz', 'chat-baseline-300220.edf_113_164.npz', 'chat-baseline-300024.edf_7_843.npz', 'chat-baseline-300345.edf_168_354.npz', 'chat-baseline-300285.edf_235_357.npz', 'chat-baseline-300062.edf_0_312.npz', 'chat-baseline-300122.edf_77_367.npz', 'chat-baseline-300314.edf_256_351.npz', 'chat-baseline-300063.edf_192_737.npz', 'chat-baseline-300187.edf_138_1116.npz', 'chat-baseline-300331.edf_134_254.npz', 'chat-baseline-300238.edf_151_1022.npz', 'chat-baseline-300255.edf_591_90.npz', 'chat-baseline-300234.edf_68_434.npz', 'chat-baseline-300043.edf_35_965.npz', 'chat-baseline-300033.edf_37_669.npz', 'chat-baseline-300004.edf_212_370.npz', 'chat-baseline-300235.edf_569_439.npz', 'chat-baseline-300199.edf_259_697.npz', 'chat-baseline-300178.edf_89_1049.npz', 'chat-baseline-300297.edf_139_178.npz', 'chat-baseline-300243.edf_162_73.npz', 'chat-baseline-300002.edf_243_207.npz', 'chat-baseline-300069.edf_235_126.npz', 'chat-baseline-300039.edf_281_2336.npz', 'chat-baseline-300117.edf_155_154.npz', 'chat-baseline-300197.edf_72_358.npz', 'chat-baseline-300196.edf_311_1825.npz', 'chat-baseline-300081.edf_115_130.npz', 'chat-baseline-300308.edf_252_271.npz', 'chat-baseline-300251.edf_361_699.npz', 'chat-baseline-300098.edf_208_380.npz', 'chat-baseline-300233.edf_291_103.npz', 'chat-baseline-300198.edf_103_416.npz', 'chat-baseline-300031.edf_339_499.npz', 'chat-baseline-300350.edf_131_0.npz', 'chat-baseline-300071.edf_7_826.npz', 'chat-baseline-300192.edf_821_917.npz', 'chat-baseline-300014.edf_1069_763.npz', 'chat-baseline-300265.edf_325_68.npz', 'chat-baseline-300252.edf_158_429.npz', 'chat-baseline-300179.edf_135_353.npz', 'chat-baseline-300218.edf_116_626.npz', 'chat-baseline-300132.edf_1780_986.npz', 'chat-baseline-300144.edf_79_217.npz', 'chat-baseline-300175.edf_340_524.npz', 'chat-baseline-300129.edf_387_109.npz', 'chat-baseline-300254.edf_30_366.npz', 'chat-baseline-300007.edf_16_160.npz', 'chat-baseline-300130.edf_56_207.npz', 'chat-baseline-300134.edf_509_395.npz', 'chat-baseline-300166.edf_116_260.npz', 'chat-baseline-300274.edf_32_227.npz', 'chat-baseline-300139.edf_100_178.npz', 'chat-baseline-300111.edf_73_624.npz', 'chat-baseline-300257.edf_250_441.npz', 'chat-baseline-300158.edf_247_497.npz', 'chat-baseline-300153.edf_217_831.npz', 'chat-baseline-300303.edf_217_2046.npz', 'chat-baseline-300167.edf_145_417.npz', 'chat-baseline-300021.edf_35_191.npz', 'chat-baseline-300001.edf_160_104.npz', 'chat-baseline-300073.edf_205_1220.npz', 'chat-baseline-300262.edf_112_366.npz', 'chat-baseline-300209.edf_1238_1760.npz', 'chat-baseline-300202.edf_27_173.npz', 'chat-baseline-300141.edf_202_197.npz', 'chat-baseline-300320.edf_155_23.npz', 'chat-baseline-300102.edf_306_627.npz', 'chat-baseline-300150.edf_1368_715.npz', 'chat-baseline-300183.edf_64_228.npz', 'chat-baseline-300157.edf_191_930.npz', 'chat-baseline-300042.edf_644_1237.npz', 'chat-baseline-300333.edf_753_1638.npz', 'chat-baseline-300351.edf_831_1318.npz', 'chat-baseline-300160.edf_170_242.npz', 'chat-baseline-300216.edf_237_785.npz', 'chat-baseline-300077.edf_273_164.npz', 'chat-baseline-300182.edf_1218_970.npz', 'chat-baseline-300169.edf_8_231.npz', 'chat-baseline-300245.edf_100_249.npz', 'chat-baseline-300214.edf_1770_100.npz', 'chat-baseline-300055.edf_126_153.npz', 'chat-baseline-300015.edf_108_12.npz', 'chat-baseline-300284.edf_164_1253.npz']\n",
            "1\n",
            "273 0\n",
            "2\n",
            "89 0\n",
            "3\n",
            "181 0\n",
            "4\n",
            "101 0\n",
            "5\n",
            "221 0\n",
            "6\n",
            "99 0\n",
            "7\n",
            "67 0\n",
            "8\n",
            "54 0\n",
            "9\n",
            "60 0\n",
            "10\n",
            "60 0\n",
            "11\n",
            "87 0\n",
            "12\n",
            "65 0\n",
            "13\n",
            "70 0\n",
            "14\n",
            "179 0\n",
            "15\n",
            "39 0\n",
            "16\n",
            "124 0\n",
            "17\n",
            "162 0\n",
            "18\n",
            "138 0\n",
            "19\n",
            "120 0\n",
            "20\n",
            "40 0\n",
            "21\n",
            "52 0\n",
            "22\n",
            "62 0\n",
            "23\n",
            "64 0\n",
            "24\n",
            "67 0\n",
            "25\n",
            "147 0\n",
            "26\n",
            "54 0\n",
            "27\n",
            "572 0\n",
            "28\n",
            "67 0\n",
            "29\n",
            "104 0\n",
            "30\n",
            "94 0\n",
            "31\n",
            "97 0\n",
            "32\n",
            "50 0\n",
            "33\n",
            "66 0\n",
            "34\n",
            "176 0\n",
            "35\n",
            "100 0\n",
            "36\n",
            "63 0\n",
            "37\n",
            "80 0\n",
            "38\n",
            "91 0\n",
            "39\n",
            "126 0\n",
            "40\n",
            "123 0\n",
            "41\n",
            "87 0\n",
            "42\n",
            "75 0\n",
            "43\n",
            "116 0\n",
            "44\n",
            "61 0\n",
            "45\n",
            "73 0\n",
            "46\n",
            "174 0\n",
            "47\n",
            "172 0\n",
            "48\n",
            "266 0\n",
            "49\n",
            "50 0\n",
            "50\n",
            "101 0\n",
            "51\n",
            "184 0\n",
            "52\n",
            "106 0\n",
            "53\n",
            "88 0\n",
            "54\n",
            "328 0\n",
            "55\n",
            "158 0\n",
            "56\n",
            "154 0\n",
            "57\n",
            "105 0\n",
            "58\n",
            "112 0\n",
            "59\n",
            "185 0\n",
            "60\n",
            "73 0\n",
            "61\n",
            "362 0\n",
            "62\n",
            "52 0\n",
            "63\n",
            "330 0\n",
            "64\n",
            "132 0\n",
            "65\n",
            "67 0\n",
            "66\n",
            "47 0\n",
            "67\n",
            "212 0\n",
            "68\n",
            "212 0\n",
            "69\n",
            "49 0\n",
            "70\n",
            "295 0\n",
            "71\n",
            "77 0\n",
            "72\n",
            "62 0\n",
            "73\n",
            "302 0\n",
            "74\n",
            "43 0\n",
            "75\n",
            "192 0\n",
            "76\n",
            "51 0\n",
            "77\n",
            "377 0\n",
            "78\n",
            "115 0\n",
            "79\n",
            "104 0\n",
            "80\n",
            "86 0\n",
            "81\n",
            "188 0\n",
            "82\n",
            "108 0\n",
            "83\n",
            "180 0\n",
            "84\n",
            "86 0\n",
            "85\n",
            "52 0\n",
            "86\n",
            "100 0\n",
            "87\n",
            "267 0\n",
            "88\n",
            "411 0\n",
            "89\n",
            "41 0\n",
            "90\n",
            "42 0\n",
            "91\n",
            "332 0\n",
            "92\n",
            "70 0\n",
            "93\n",
            "154 0\n",
            "94\n",
            "370 0\n",
            "95\n",
            "259 0\n",
            "96\n",
            "22 0\n",
            "97\n",
            "63 0\n",
            "98\n",
            "72 0\n",
            "99\n",
            "29 0\n",
            "100\n",
            "56 0\n",
            "101\n",
            "103 0\n",
            "102\n",
            "55 0\n",
            "103\n",
            "235 0\n",
            "104\n",
            "110 0\n",
            "105\n",
            "208 0\n",
            "106\n",
            "137 0\n",
            "107\n",
            "242 0\n",
            "108\n",
            "389 0\n",
            "109\n",
            "91 0\n",
            "110\n",
            "141 0\n",
            "111\n",
            "75 0\n",
            "112\n",
            "61 0\n",
            "113\n",
            "48 0\n",
            "114\n",
            "152 0\n",
            "115\n",
            "102 0\n",
            "116\n",
            "483 0\n",
            "117\n",
            "266 0\n",
            "118\n",
            "354 0\n",
            "119\n",
            "34 0\n",
            "(2474, 3840, 17) (2474,) (2474,)\n",
            "(3034, 3840, 17) (3034,) (3034,)\n",
            "(3541, 3840, 17) (3541,) (3541,)\n",
            "(3952, 3840, 17) (3952,) (3952,)\n",
            "(3506, 3840, 17) (3506,) (3506,)\n"
          ]
        }
      ],
      "source": [
        "#Commented to allow rest of notebook to run (No Data processing/loading/training for Submission)\n",
        "\n",
        "# PATH = chat_out\n",
        "# OUT_PATH = '/content/chatloader/'\n",
        "# os.makedirs(os.path.dirname(OUT_PATH), exist_ok=True)\n",
        "\n",
        "# load data\n",
        "# x, y_apnea, y_hypopnea = load_data(PATH)\n",
        "# # save data into .npz file\n",
        "# for i in range(5):\n",
        "#       print(x[i].shape, y_apnea[i].shape, y_hypopnea[i].shape)\n",
        "#       np.savez_compressed(OUT_PATH + \"chat_\" + str(i), x=x[i], y_apnea=y_apnea[i], y_hypopnea=y_hypopnea[i])\n",
        "\n",
        "# np.savez_compressed(OUT_PATH + \"chat_1\", x=x, y_apnea=y_apnea, y_hypopnea=y_hypopnea) #doesn't work because of mismatching shapes after first dimension\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igPZzqKAPu59",
        "outputId": "3fb3bc24-1c24-4f93-fa57-32c24ce737d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: chatloader/ (stored 0%)\n",
            "  adding: chatloader/chat_4.npz (deflated 0%)\n",
            "  adding: chatloader/chat_3.npz (deflated 0%)\n",
            "  adding: chatloader/chat_0.npz (deflated 0%)\n",
            "  adding: chatloader/chat_2.npz (deflated 0%)\n",
            "  adding: chatloader/chat_1.npz (deflated 0%)\n"
          ]
        }
      ],
      "source": [
        "# !zip -r chatprocessed.zip chatprocessed/\n",
        "# %rm -r chatprocessed/\n",
        "# !zip -r chatloader.zip chatloader/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nrYq2A-cKfp",
        "outputId": "35372806-f9cd-43e6-df4a-5aae122b55d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Box File - 1516312798979 (chatloader.zip)>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# client.folder(folder_id='261223530618').upload(\"chatloader.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing **command** to download data from Box to local Colab Drive storage to get the data for further use in the notebook."
      ],
      "metadata": {
        "id": "GxWzMcX3laU6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WnsTgYOfZ6A",
        "outputId": "e34d8abf-d591-4a32-8084-3751e0618077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1CAtL7c4q1VpSUMeadIwyJIuL2_6aSiz9\n",
            "From (redirected): https://drive.google.com/uc?id=1CAtL7c4q1VpSUMeadIwyJIuL2_6aSiz9&confirm=t&uuid=53498735-794f-429b-820a-d9bb913c14ba\n",
            "To: /content/chatloader.zip\n",
            "100% 457M/457M [00:12<00:00, 35.6MB/s]\n",
            "Archive:  chatloader.zip\n",
            "   creating: chatloader/\n",
            "  inflating: chatloader/chat_2.npz   \n",
            "  inflating: chatloader/chat_1.npz   \n",
            "  inflating: chatloader/chat_4.npz   \n",
            "  inflating: chatloader/chat_3.npz   \n",
            "  inflating: chatloader/chat_0.npz   \n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=196ZMPkv8Q0RKy4N0KwSB1i0WGoHSX6_0\n",
            "From (redirected): https://drive.google.com/uc?id=196ZMPkv8Q0RKy4N0KwSB1i0WGoHSX6_0&confirm=t&uuid=6bf30f08-4976-40fb-b358-29c71999e593\n",
            "To: /content/model_final.zip\n",
            "100% 112M/112M [00:03<00:00, 34.3MB/s]\n",
            "Archive:  model_final.zip\n",
            "   creating: model/\n",
            "   creating: model/model_5dropout_ECGSPO21/\n",
            "   creating: model/model_5dropout_ECGSPO21/assets/\n",
            " extracting: model/model_5dropout_ECGSPO21/fingerprint.pb  \n",
            "  inflating: model/model_5dropout_ECGSPO21/keras_metadata.pb  \n",
            "  inflating: model/model_5dropout_ECGSPO21/saved_model.pb  \n",
            "   creating: model/model_5dropout_ECGSPO21/variables/\n",
            "  inflating: model/model_5dropout_ECGSPO21/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_5dropout_ECGSPO21/variables/variables.index  \n",
            "   creating: model/model_0lrs_ECGSPO21/\n",
            "   creating: model/model_0lrs_ECGSPO21/assets/\n",
            " extracting: model/model_0lrs_ECGSPO21/fingerprint.pb  \n",
            "  inflating: model/model_0lrs_ECGSPO21/keras_metadata.pb  \n",
            "  inflating: model/model_0lrs_ECGSPO21/saved_model.pb  \n",
            "   creating: model/model_0lrs_ECGSPO21/variables/\n",
            "  inflating: model/model_0lrs_ECGSPO21/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_0lrs_ECGSPO21/variables/variables.index  \n",
            "   creating: model/model_nochanges_EOGEEGECGRespSPO2CO20/\n",
            "   creating: model/model_nochanges_EOGEEGECGRespSPO2CO20/assets/\n",
            " extracting: model/model_nochanges_EOGEEGECGRespSPO2CO20/fingerprint.pb  \n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO20/keras_metadata.pb  \n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO20/saved_model.pb  \n",
            "   creating: model/model_nochanges_EOGEEGECGRespSPO2CO20/variables/\n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO20/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO20/variables/variables.index  \n",
            "   creating: model/model_5dropout_ECGSPO20/\n",
            "   creating: model/model_5dropout_ECGSPO20/assets/\n",
            " extracting: model/model_5dropout_ECGSPO20/fingerprint.pb  \n",
            "  inflating: model/model_5dropout_ECGSPO20/keras_metadata.pb  \n",
            "  inflating: model/model_5dropout_ECGSPO20/saved_model.pb  \n",
            "   creating: model/model_5dropout_ECGSPO20/variables/\n",
            "  inflating: model/model_5dropout_ECGSPO20/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_5dropout_ECGSPO20/variables/variables.index  \n",
            "   creating: model/model_400epochs_ECGSPO22/\n",
            "   creating: model/model_400epochs_ECGSPO22/assets/\n",
            " extracting: model/model_400epochs_ECGSPO22/fingerprint.pb  \n",
            "  inflating: model/model_400epochs_ECGSPO22/keras_metadata.pb  \n",
            "  inflating: model/model_400epochs_ECGSPO22/saved_model.pb  \n",
            "   creating: model/model_400epochs_ECGSPO22/variables/\n",
            "  inflating: model/model_400epochs_ECGSPO22/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_400epochs_ECGSPO22/variables/variables.index  \n",
            "   creating: model/model_nochanges_EOGEEGECGRespSPO2CO21/\n",
            "   creating: model/model_nochanges_EOGEEGECGRespSPO2CO21/assets/\n",
            " extracting: model/model_nochanges_EOGEEGECGRespSPO2CO21/fingerprint.pb  \n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO21/keras_metadata.pb  \n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO21/saved_model.pb  \n",
            "   creating: model/model_nochanges_EOGEEGECGRespSPO2CO21/variables/\n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO21/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO21/variables/variables.index  \n",
            "   creating: model/model_nochanges_ECGSPO20/\n",
            "   creating: model/model_nochanges_ECGSPO20/assets/\n",
            " extracting: model/model_nochanges_ECGSPO20/fingerprint.pb  \n",
            "  inflating: model/model_nochanges_ECGSPO20/keras_metadata.pb  \n",
            "  inflating: model/model_nochanges_ECGSPO20/saved_model.pb  \n",
            "   creating: model/model_nochanges_ECGSPO20/variables/\n",
            "  inflating: model/model_nochanges_ECGSPO20/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_nochanges_ECGSPO20/variables/variables.index  \n",
            "   creating: model/model_0dropout_ECGSPO23/\n",
            "   creating: model/model_0dropout_ECGSPO23/assets/\n",
            " extracting: model/model_0dropout_ECGSPO23/fingerprint.pb  \n",
            "  inflating: model/model_0dropout_ECGSPO23/keras_metadata.pb  \n",
            "  inflating: model/model_0dropout_ECGSPO23/saved_model.pb  \n",
            "   creating: model/model_0dropout_ECGSPO23/variables/\n",
            "  inflating: model/model_0dropout_ECGSPO23/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_0dropout_ECGSPO23/variables/variables.index  \n",
            "   creating: model/model_400epochs_ECGSPO23/\n",
            "   creating: model/model_400epochs_ECGSPO23/assets/\n",
            " extracting: model/model_400epochs_ECGSPO23/fingerprint.pb  \n",
            "  inflating: model/model_400epochs_ECGSPO23/keras_metadata.pb  \n",
            "  inflating: model/model_400epochs_ECGSPO23/saved_model.pb  \n",
            "   creating: model/model_400epochs_ECGSPO23/variables/\n",
            "  inflating: model/model_400epochs_ECGSPO23/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_400epochs_ECGSPO23/variables/variables.index  \n",
            "   creating: model/model_200epochs_ECGSPO21/\n",
            "   creating: model/model_200epochs_ECGSPO21/assets/\n",
            " extracting: model/model_200epochs_ECGSPO21/fingerprint.pb  \n",
            "  inflating: model/model_200epochs_ECGSPO21/keras_metadata.pb  \n",
            "  inflating: model/model_200epochs_ECGSPO21/saved_model.pb  \n",
            "   creating: model/model_200epochs_ECGSPO21/variables/\n",
            "  inflating: model/model_200epochs_ECGSPO21/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_200epochs_ECGSPO21/variables/variables.index  \n",
            "   creating: model/model_400epochs_ECGSPO24/\n",
            "   creating: model/model_400epochs_ECGSPO24/assets/\n",
            " extracting: model/model_400epochs_ECGSPO24/fingerprint.pb  \n",
            "  inflating: model/model_400epochs_ECGSPO24/keras_metadata.pb  \n",
            "  inflating: model/model_400epochs_ECGSPO24/saved_model.pb  \n",
            "   creating: model/model_400epochs_ECGSPO24/variables/\n",
            "  inflating: model/model_400epochs_ECGSPO24/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_400epochs_ECGSPO24/variables/variables.index  \n",
            "   creating: model/model_0dropout_ECGSPO22/\n",
            "   creating: model/model_0dropout_ECGSPO22/assets/\n",
            " extracting: model/model_0dropout_ECGSPO22/fingerprint.pb  \n",
            "  inflating: model/model_0dropout_ECGSPO22/keras_metadata.pb  \n",
            "  inflating: model/model_0dropout_ECGSPO22/saved_model.pb  \n",
            "   creating: model/model_0dropout_ECGSPO22/variables/\n",
            "  inflating: model/model_0dropout_ECGSPO22/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_0dropout_ECGSPO22/variables/variables.index  \n",
            "   creating: model/model_nochanges_EOGEEGECGRespSPO2CO22/\n",
            "   creating: model/model_nochanges_EOGEEGECGRespSPO2CO22/assets/\n",
            " extracting: model/model_nochanges_EOGEEGECGRespSPO2CO22/fingerprint.pb  \n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO22/keras_metadata.pb  \n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO22/saved_model.pb  \n",
            "   creating: model/model_nochanges_EOGEEGECGRespSPO2CO22/variables/\n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO22/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO22/variables/variables.index  \n",
            "   creating: model/model_200epochs_ECGSPO20/\n",
            "   creating: model/model_200epochs_ECGSPO20/assets/\n",
            " extracting: model/model_200epochs_ECGSPO20/fingerprint.pb  \n",
            "  inflating: model/model_200epochs_ECGSPO20/keras_metadata.pb  \n",
            "  inflating: model/model_200epochs_ECGSPO20/saved_model.pb  \n",
            "   creating: model/model_200epochs_ECGSPO20/variables/\n",
            "  inflating: model/model_200epochs_ECGSPO20/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_200epochs_ECGSPO20/variables/variables.index  \n",
            "   creating: model/model_200epochs_ECGSPO24/\n",
            "   creating: model/model_200epochs_ECGSPO24/assets/\n",
            " extracting: model/model_200epochs_ECGSPO24/fingerprint.pb  \n",
            "  inflating: model/model_200epochs_ECGSPO24/keras_metadata.pb  \n",
            "  inflating: model/model_200epochs_ECGSPO24/saved_model.pb  \n",
            "   creating: model/model_200epochs_ECGSPO24/variables/\n",
            "  inflating: model/model_200epochs_ECGSPO24/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_200epochs_ECGSPO24/variables/variables.index  \n",
            "   creating: model/model_0lrs_ECGSPO23/\n",
            "   creating: model/model_0lrs_ECGSPO23/assets/\n",
            " extracting: model/model_0lrs_ECGSPO23/fingerprint.pb  \n",
            "  inflating: model/model_0lrs_ECGSPO23/keras_metadata.pb  \n",
            "  inflating: model/model_0lrs_ECGSPO23/saved_model.pb  \n",
            "   creating: model/model_0lrs_ECGSPO23/variables/\n",
            "  inflating: model/model_0lrs_ECGSPO23/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_0lrs_ECGSPO23/variables/variables.index  \n",
            "   creating: model/model_0lrs_ECGSPO22/\n",
            "   creating: model/model_0lrs_ECGSPO22/assets/\n",
            " extracting: model/model_0lrs_ECGSPO22/fingerprint.pb  \n",
            "  inflating: model/model_0lrs_ECGSPO22/keras_metadata.pb  \n",
            "  inflating: model/model_0lrs_ECGSPO22/saved_model.pb  \n",
            "   creating: model/model_0lrs_ECGSPO22/variables/\n",
            "  inflating: model/model_0lrs_ECGSPO22/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_0lrs_ECGSPO22/variables/variables.index  \n",
            "   creating: model/model_25lrs_ECGSPO24/\n",
            "   creating: model/model_25lrs_ECGSPO24/assets/\n",
            " extracting: model/model_25lrs_ECGSPO24/fingerprint.pb  \n",
            "  inflating: model/model_25lrs_ECGSPO24/keras_metadata.pb  \n",
            "  inflating: model/model_25lrs_ECGSPO24/saved_model.pb  \n",
            "   creating: model/model_25lrs_ECGSPO24/variables/\n",
            "  inflating: model/model_25lrs_ECGSPO24/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_25lrs_ECGSPO24/variables/variables.index  \n",
            "   creating: model/model_nochanges_ECGSPO21/\n",
            "   creating: model/model_nochanges_ECGSPO21/assets/\n",
            " extracting: model/model_nochanges_ECGSPO21/fingerprint.pb  \n",
            "  inflating: model/model_nochanges_ECGSPO21/keras_metadata.pb  \n",
            "  inflating: model/model_nochanges_ECGSPO21/saved_model.pb  \n",
            "   creating: model/model_nochanges_ECGSPO21/variables/\n",
            "  inflating: model/model_nochanges_ECGSPO21/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_nochanges_ECGSPO21/variables/variables.index  \n",
            "   creating: model/model_5dropout_ECGSPO22/\n",
            "   creating: model/model_5dropout_ECGSPO22/assets/\n",
            " extracting: model/model_5dropout_ECGSPO22/fingerprint.pb  \n",
            "  inflating: model/model_5dropout_ECGSPO22/keras_metadata.pb  \n",
            "  inflating: model/model_5dropout_ECGSPO22/saved_model.pb  \n",
            "   creating: model/model_5dropout_ECGSPO22/variables/\n",
            "  inflating: model/model_5dropout_ECGSPO22/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_5dropout_ECGSPO22/variables/variables.index  \n",
            "   creating: model/model_25lrs_ECGSPO23/\n",
            "   creating: model/model_25lrs_ECGSPO23/assets/\n",
            " extracting: model/model_25lrs_ECGSPO23/fingerprint.pb  \n",
            "  inflating: model/model_25lrs_ECGSPO23/keras_metadata.pb  \n",
            "  inflating: model/model_25lrs_ECGSPO23/saved_model.pb  \n",
            "   creating: model/model_25lrs_ECGSPO23/variables/\n",
            "  inflating: model/model_25lrs_ECGSPO23/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_25lrs_ECGSPO23/variables/variables.index  \n",
            "   creating: model/model_400epochs_ECGSPO21/\n",
            "   creating: model/model_400epochs_ECGSPO21/assets/\n",
            " extracting: model/model_400epochs_ECGSPO21/fingerprint.pb  \n",
            "  inflating: model/model_400epochs_ECGSPO21/keras_metadata.pb  \n",
            "  inflating: model/model_400epochs_ECGSPO21/saved_model.pb  \n",
            "   creating: model/model_400epochs_ECGSPO21/variables/\n",
            "  inflating: model/model_400epochs_ECGSPO21/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_400epochs_ECGSPO21/variables/variables.index  \n",
            "   creating: model/model_200epochs_ECGSPO23/\n",
            "   creating: model/model_200epochs_ECGSPO23/assets/\n",
            " extracting: model/model_200epochs_ECGSPO23/fingerprint.pb  \n",
            "  inflating: model/model_200epochs_ECGSPO23/keras_metadata.pb  \n",
            "  inflating: model/model_200epochs_ECGSPO23/saved_model.pb  \n",
            "   creating: model/model_200epochs_ECGSPO23/variables/\n",
            "  inflating: model/model_200epochs_ECGSPO23/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_200epochs_ECGSPO23/variables/variables.index  \n",
            "   creating: model/model_5dropout_ECGSPO24/\n",
            "   creating: model/model_5dropout_ECGSPO24/assets/\n",
            " extracting: model/model_5dropout_ECGSPO24/fingerprint.pb  \n",
            "  inflating: model/model_5dropout_ECGSPO24/keras_metadata.pb  \n",
            "  inflating: model/model_5dropout_ECGSPO24/saved_model.pb  \n",
            "   creating: model/model_5dropout_ECGSPO24/variables/\n",
            "  inflating: model/model_5dropout_ECGSPO24/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_5dropout_ECGSPO24/variables/variables.index  \n",
            "   creating: model/model_nochanges_ECGSPO23/\n",
            "   creating: model/model_nochanges_ECGSPO23/assets/\n",
            " extracting: model/model_nochanges_ECGSPO23/fingerprint.pb  \n",
            "  inflating: model/model_nochanges_ECGSPO23/keras_metadata.pb  \n",
            "  inflating: model/model_nochanges_ECGSPO23/saved_model.pb  \n",
            "   creating: model/model_nochanges_ECGSPO23/variables/\n",
            "  inflating: model/model_nochanges_ECGSPO23/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_nochanges_ECGSPO23/variables/variables.index  \n",
            "   creating: model/model_200epochs_ECGSPO22/\n",
            "   creating: model/model_200epochs_ECGSPO22/assets/\n",
            " extracting: model/model_200epochs_ECGSPO22/fingerprint.pb  \n",
            "  inflating: model/model_200epochs_ECGSPO22/keras_metadata.pb  \n",
            "  inflating: model/model_200epochs_ECGSPO22/saved_model.pb  \n",
            "   creating: model/model_200epochs_ECGSPO22/variables/\n",
            "  inflating: model/model_200epochs_ECGSPO22/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_200epochs_ECGSPO22/variables/variables.index  \n",
            "   creating: model/model_25lrs_ECGSPO20/\n",
            "   creating: model/model_25lrs_ECGSPO20/assets/\n",
            " extracting: model/model_25lrs_ECGSPO20/fingerprint.pb  \n",
            "  inflating: model/model_25lrs_ECGSPO20/keras_metadata.pb  \n",
            "  inflating: model/model_25lrs_ECGSPO20/saved_model.pb  \n",
            "   creating: model/model_25lrs_ECGSPO20/variables/\n",
            "  inflating: model/model_25lrs_ECGSPO20/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_25lrs_ECGSPO20/variables/variables.index  \n",
            "   creating: model/model_nochanges_ECGSPO24/\n",
            "   creating: model/model_nochanges_ECGSPO24/assets/\n",
            " extracting: model/model_nochanges_ECGSPO24/fingerprint.pb  \n",
            "  inflating: model/model_nochanges_ECGSPO24/keras_metadata.pb  \n",
            "  inflating: model/model_nochanges_ECGSPO24/saved_model.pb  \n",
            "   creating: model/model_nochanges_ECGSPO24/variables/\n",
            "  inflating: model/model_nochanges_ECGSPO24/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_nochanges_ECGSPO24/variables/variables.index  \n",
            "   creating: model/model_400epochs_ECGSPO20/\n",
            "   creating: model/model_400epochs_ECGSPO20/assets/\n",
            " extracting: model/model_400epochs_ECGSPO20/fingerprint.pb  \n",
            "  inflating: model/model_400epochs_ECGSPO20/keras_metadata.pb  \n",
            "  inflating: model/model_400epochs_ECGSPO20/saved_model.pb  \n",
            "   creating: model/model_400epochs_ECGSPO20/variables/\n",
            "  inflating: model/model_400epochs_ECGSPO20/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_400epochs_ECGSPO20/variables/variables.index  \n",
            "   creating: model/model_nochanges_ECGSPO22/\n",
            "   creating: model/model_nochanges_ECGSPO22/assets/\n",
            " extracting: model/model_nochanges_ECGSPO22/fingerprint.pb  \n",
            "  inflating: model/model_nochanges_ECGSPO22/keras_metadata.pb  \n",
            "  inflating: model/model_nochanges_ECGSPO22/saved_model.pb  \n",
            "   creating: model/model_nochanges_ECGSPO22/variables/\n",
            "  inflating: model/model_nochanges_ECGSPO22/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_nochanges_ECGSPO22/variables/variables.index  \n",
            "   creating: model/model_nochanges_EOGEEGECGRespSPO2CO23/\n",
            "   creating: model/model_nochanges_EOGEEGECGRespSPO2CO23/assets/\n",
            " extracting: model/model_nochanges_EOGEEGECGRespSPO2CO23/fingerprint.pb  \n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO23/keras_metadata.pb  \n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO23/saved_model.pb  \n",
            "   creating: model/model_nochanges_EOGEEGECGRespSPO2CO23/variables/\n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO23/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO23/variables/variables.index  \n",
            "   creating: model/model_0dropout_ECGSPO21/\n",
            "   creating: model/model_0dropout_ECGSPO21/assets/\n",
            " extracting: model/model_0dropout_ECGSPO21/fingerprint.pb  \n",
            "  inflating: model/model_0dropout_ECGSPO21/keras_metadata.pb  \n",
            "  inflating: model/model_0dropout_ECGSPO21/saved_model.pb  \n",
            "   creating: model/model_0dropout_ECGSPO21/variables/\n",
            "  inflating: model/model_0dropout_ECGSPO21/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_0dropout_ECGSPO21/variables/variables.index  \n",
            "   creating: model/model_0lrs_ECGSPO20/\n",
            "   creating: model/model_0lrs_ECGSPO20/assets/\n",
            " extracting: model/model_0lrs_ECGSPO20/fingerprint.pb  \n",
            "  inflating: model/model_0lrs_ECGSPO20/keras_metadata.pb  \n",
            "  inflating: model/model_0lrs_ECGSPO20/saved_model.pb  \n",
            "   creating: model/model_0lrs_ECGSPO20/variables/\n",
            "  inflating: model/model_0lrs_ECGSPO20/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_0lrs_ECGSPO20/variables/variables.index  \n",
            "   creating: model/model_5dropout_ECGSPO23/\n",
            "   creating: model/model_5dropout_ECGSPO23/assets/\n",
            " extracting: model/model_5dropout_ECGSPO23/fingerprint.pb  \n",
            "  inflating: model/model_5dropout_ECGSPO23/keras_metadata.pb  \n",
            "  inflating: model/model_5dropout_ECGSPO23/saved_model.pb  \n",
            "   creating: model/model_5dropout_ECGSPO23/variables/\n",
            "  inflating: model/model_5dropout_ECGSPO23/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_5dropout_ECGSPO23/variables/variables.index  \n",
            "   creating: model/.ipynb_checkpoints/\n",
            "   creating: model/model_0lrs_ECGSPO24/\n",
            "   creating: model/model_0lrs_ECGSPO24/assets/\n",
            " extracting: model/model_0lrs_ECGSPO24/fingerprint.pb  \n",
            "  inflating: model/model_0lrs_ECGSPO24/keras_metadata.pb  \n",
            "  inflating: model/model_0lrs_ECGSPO24/saved_model.pb  \n",
            "   creating: model/model_0lrs_ECGSPO24/variables/\n",
            "  inflating: model/model_0lrs_ECGSPO24/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_0lrs_ECGSPO24/variables/variables.index  \n",
            "   creating: model/model_0dropout_ECGSPO20/\n",
            "   creating: model/model_0dropout_ECGSPO20/assets/\n",
            " extracting: model/model_0dropout_ECGSPO20/fingerprint.pb  \n",
            "  inflating: model/model_0dropout_ECGSPO20/keras_metadata.pb  \n",
            "  inflating: model/model_0dropout_ECGSPO20/saved_model.pb  \n",
            "   creating: model/model_0dropout_ECGSPO20/variables/\n",
            "  inflating: model/model_0dropout_ECGSPO20/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_0dropout_ECGSPO20/variables/variables.index  \n",
            "   creating: model/model_0dropout_ECGSPO24/\n",
            "   creating: model/model_0dropout_ECGSPO24/assets/\n",
            " extracting: model/model_0dropout_ECGSPO24/fingerprint.pb  \n",
            "  inflating: model/model_0dropout_ECGSPO24/keras_metadata.pb  \n",
            "  inflating: model/model_0dropout_ECGSPO24/saved_model.pb  \n",
            "   creating: model/model_0dropout_ECGSPO24/variables/\n",
            "  inflating: model/model_0dropout_ECGSPO24/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_0dropout_ECGSPO24/variables/variables.index  \n",
            "   creating: model/model_25lrs_ECGSPO21/\n",
            "   creating: model/model_25lrs_ECGSPO21/assets/\n",
            " extracting: model/model_25lrs_ECGSPO21/fingerprint.pb  \n",
            "  inflating: model/model_25lrs_ECGSPO21/keras_metadata.pb  \n",
            "  inflating: model/model_25lrs_ECGSPO21/saved_model.pb  \n",
            "   creating: model/model_25lrs_ECGSPO21/variables/\n",
            "  inflating: model/model_25lrs_ECGSPO21/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_25lrs_ECGSPO21/variables/variables.index  \n",
            "   creating: model/model_nochanges_EOGEEGECGRespSPO2CO24/\n",
            "   creating: model/model_nochanges_EOGEEGECGRespSPO2CO24/assets/\n",
            " extracting: model/model_nochanges_EOGEEGECGRespSPO2CO24/fingerprint.pb  \n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO24/keras_metadata.pb  \n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO24/saved_model.pb  \n",
            "   creating: model/model_nochanges_EOGEEGECGRespSPO2CO24/variables/\n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO24/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_nochanges_EOGEEGECGRespSPO2CO24/variables/variables.index  \n",
            "   creating: model/model_25lrs_ECGSPO22/\n",
            "   creating: model/model_25lrs_ECGSPO22/assets/\n",
            " extracting: model/model_25lrs_ECGSPO22/fingerprint.pb  \n",
            "  inflating: model/model_25lrs_ECGSPO22/keras_metadata.pb  \n",
            "  inflating: model/model_25lrs_ECGSPO22/saved_model.pb  \n",
            "   creating: model/model_25lrs_ECGSPO22/variables/\n",
            "  inflating: model/model_25lrs_ECGSPO22/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_25lrs_ECGSPO22/variables/variables.index  \n",
            "   creating: model/model_10trasformerlayer_ECGSPO20/assets/\n",
            " extracting: model/model_10trasformerlayer_ECGSPO20/fingerprint.pb  \n",
            "  inflating: model/model_10trasformerlayer_ECGSPO20/keras_metadata.pb  \n",
            "  inflating: model/model_10trasformerlayer_ECGSPO20/saved_model.pb  \n",
            "   creating: model/model_10trasformerlayer_ECGSPO20/variables/\n",
            "  inflating: model/model_10trasformerlayer_ECGSPO20/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_10trasformerlayer_ECGSPO20/variables/variables.index  \n",
            "   creating: model/model_10trasformerlayer_ECGSPO21/assets/\n",
            " extracting: model/model_10trasformerlayer_ECGSPO21/fingerprint.pb  \n",
            "  inflating: model/model_10trasformerlayer_ECGSPO21/keras_metadata.pb  \n",
            "  inflating: model/model_10trasformerlayer_ECGSPO21/saved_model.pb  \n",
            "   creating: model/model_10trasformerlayer_ECGSPO21/variables/\n",
            "  inflating: model/model_10trasformerlayer_ECGSPO21/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_10trasformerlayer_ECGSPO21/variables/variables.index  \n",
            "   creating: model/model_10trasformerlayer_ECGSPO22/assets/\n",
            " extracting: model/model_10trasformerlayer_ECGSPO22/fingerprint.pb  \n",
            "  inflating: model/model_10trasformerlayer_ECGSPO22/keras_metadata.pb  \n",
            "  inflating: model/model_10trasformerlayer_ECGSPO22/saved_model.pb  \n",
            "   creating: model/model_10trasformerlayer_ECGSPO22/variables/\n",
            "  inflating: model/model_10trasformerlayer_ECGSPO22/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_10trasformerlayer_ECGSPO22/variables/variables.index  \n",
            "   creating: model/model_10trasformerlayer_ECGSPO23/assets/\n",
            " extracting: model/model_10trasformerlayer_ECGSPO23/fingerprint.pb  \n",
            "  inflating: model/model_10trasformerlayer_ECGSPO23/keras_metadata.pb  \n",
            "  inflating: model/model_10trasformerlayer_ECGSPO23/saved_model.pb  \n",
            "   creating: model/model_10trasformerlayer_ECGSPO23/variables/\n",
            "  inflating: model/model_10trasformerlayer_ECGSPO23/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_10trasformerlayer_ECGSPO23/variables/variables.index  \n",
            "   creating: model/model_10trasformerlayer_ECGSPO24/assets/\n",
            " extracting: model/model_10trasformerlayer_ECGSPO24/fingerprint.pb  \n",
            "  inflating: model/model_10trasformerlayer_ECGSPO24/keras_metadata.pb  \n",
            "  inflating: model/model_10trasformerlayer_ECGSPO24/saved_model.pb  \n",
            "   creating: model/model_10trasformerlayer_ECGSPO24/variables/\n",
            "  inflating: model/model_10trasformerlayer_ECGSPO24/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_10trasformerlayer_ECGSPO24/variables/variables.index  \n",
            "   creating: model/model_1trasformerlayer_ECGSPO20/assets/\n",
            " extracting: model/model_1trasformerlayer_ECGSPO20/fingerprint.pb  \n",
            "  inflating: model/model_1trasformerlayer_ECGSPO20/keras_metadata.pb  \n",
            "  inflating: model/model_1trasformerlayer_ECGSPO20/saved_model.pb  \n",
            "   creating: model/model_1trasformerlayer_ECGSPO20/variables/\n",
            "  inflating: model/model_1trasformerlayer_ECGSPO20/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_1trasformerlayer_ECGSPO20/variables/variables.index  \n",
            "   creating: model/model_1trasformerlayer_ECGSPO21/assets/\n",
            " extracting: model/model_1trasformerlayer_ECGSPO21/fingerprint.pb  \n",
            "  inflating: model/model_1trasformerlayer_ECGSPO21/keras_metadata.pb  \n",
            "  inflating: model/model_1trasformerlayer_ECGSPO21/saved_model.pb  \n",
            "   creating: model/model_1trasformerlayer_ECGSPO21/variables/\n",
            "  inflating: model/model_1trasformerlayer_ECGSPO21/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_1trasformerlayer_ECGSPO21/variables/variables.index  \n",
            "   creating: model/model_1trasformerlayer_ECGSPO22/assets/\n",
            " extracting: model/model_1trasformerlayer_ECGSPO22/fingerprint.pb  \n",
            "  inflating: model/model_1trasformerlayer_ECGSPO22/keras_metadata.pb  \n",
            "  inflating: model/model_1trasformerlayer_ECGSPO22/saved_model.pb  \n",
            "   creating: model/model_1trasformerlayer_ECGSPO22/variables/\n",
            "  inflating: model/model_1trasformerlayer_ECGSPO22/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_1trasformerlayer_ECGSPO22/variables/variables.index  \n",
            "   creating: model/model_1trasformerlayer_ECGSPO23/assets/\n",
            " extracting: model/model_1trasformerlayer_ECGSPO23/fingerprint.pb  \n",
            "  inflating: model/model_1trasformerlayer_ECGSPO23/keras_metadata.pb  \n",
            "  inflating: model/model_1trasformerlayer_ECGSPO23/saved_model.pb  \n",
            "   creating: model/model_1trasformerlayer_ECGSPO23/variables/\n",
            "  inflating: model/model_1trasformerlayer_ECGSPO23/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_1trasformerlayer_ECGSPO23/variables/variables.index  \n",
            "   creating: model/model_1trasformerlayer_ECGSPO24/assets/\n",
            " extracting: model/model_1trasformerlayer_ECGSPO24/fingerprint.pb  \n",
            "  inflating: model/model_1trasformerlayer_ECGSPO24/keras_metadata.pb  \n",
            "  inflating: model/model_1trasformerlayer_ECGSPO24/saved_model.pb  \n",
            "   creating: model/model_1trasformerlayer_ECGSPO24/variables/\n",
            "  inflating: model/model_1trasformerlayer_ECGSPO24/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_1trasformerlayer_ECGSPO24/variables/variables.index  \n",
            "   creating: model/model_3trasformerlayer_ECGSPO20/assets/\n",
            " extracting: model/model_3trasformerlayer_ECGSPO20/fingerprint.pb  \n",
            "  inflating: model/model_3trasformerlayer_ECGSPO20/keras_metadata.pb  \n",
            "  inflating: model/model_3trasformerlayer_ECGSPO20/saved_model.pb  \n",
            "   creating: model/model_3trasformerlayer_ECGSPO20/variables/\n",
            "  inflating: model/model_3trasformerlayer_ECGSPO20/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_3trasformerlayer_ECGSPO20/variables/variables.index  \n",
            "   creating: model/model_3trasformerlayer_ECGSPO21/assets/\n",
            " extracting: model/model_3trasformerlayer_ECGSPO21/fingerprint.pb  \n",
            "  inflating: model/model_3trasformerlayer_ECGSPO21/keras_metadata.pb  \n",
            "  inflating: model/model_3trasformerlayer_ECGSPO21/saved_model.pb  \n",
            "   creating: model/model_3trasformerlayer_ECGSPO21/variables/\n",
            "  inflating: model/model_3trasformerlayer_ECGSPO21/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_3trasformerlayer_ECGSPO21/variables/variables.index  \n",
            "   creating: model/model_3trasformerlayer_ECGSPO22/assets/\n",
            " extracting: model/model_3trasformerlayer_ECGSPO22/fingerprint.pb  \n",
            "  inflating: model/model_3trasformerlayer_ECGSPO22/keras_metadata.pb  \n",
            "  inflating: model/model_3trasformerlayer_ECGSPO22/saved_model.pb  \n",
            "   creating: model/model_3trasformerlayer_ECGSPO22/variables/\n",
            "  inflating: model/model_3trasformerlayer_ECGSPO22/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_3trasformerlayer_ECGSPO22/variables/variables.index  \n",
            "   creating: model/model_3trasformerlayer_ECGSPO23/assets/\n",
            " extracting: model/model_3trasformerlayer_ECGSPO23/fingerprint.pb  \n",
            "  inflating: model/model_3trasformerlayer_ECGSPO23/keras_metadata.pb  \n",
            "  inflating: model/model_3trasformerlayer_ECGSPO23/saved_model.pb  \n",
            "   creating: model/model_3trasformerlayer_ECGSPO23/variables/\n",
            "  inflating: model/model_3trasformerlayer_ECGSPO23/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_3trasformerlayer_ECGSPO23/variables/variables.index  \n",
            "   creating: model/model_3trasformerlayer_ECGSPO24/assets/\n",
            " extracting: model/model_3trasformerlayer_ECGSPO24/fingerprint.pb  \n",
            "  inflating: model/model_3trasformerlayer_ECGSPO24/keras_metadata.pb  \n",
            "  inflating: model/model_3trasformerlayer_ECGSPO24/saved_model.pb  \n",
            "   creating: model/model_3trasformerlayer_ECGSPO24/variables/\n",
            "  inflating: model/model_3trasformerlayer_ECGSPO24/variables/variables.data-00000-of-00001  \n",
            "  inflating: model/model_3trasformerlayer_ECGSPO24/variables/variables.index  \n"
          ]
        }
      ],
      "source": [
        "#Download pre-made chatloader to avoid recreating it.\n",
        "# file_content = client.file(\"1516312798979\").content()\n",
        "# downloadFromBox(\"chatloader.zip\", file_content)\n",
        "\n",
        "#This is a subset of the data used so that graders can run the model tests. Also included pre-trained models. Dataset is significantly smaller than what we used to test.\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1CAtL7c4q1VpSUMeadIwyJIuL2_6aSiz9/view?usp=sharing\n",
        "!unzip chatloader.zip\n",
        "!gdown --fuzzy https://drive.google.com/file/d/196ZMPkv8Q0RKy4N0KwSB1i0WGoHSX6_0/view?usp=sharing\n",
        "!unzip model_final.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3muyDPFPbozY"
      },
      "source": [
        "##   Model\n",
        "\n",
        "For reference, the model is described in the author's original paper -- It is published by National Institutes of Health. The citation is provided again below:\n",
        "\n",
        "Fayyaz H, Strang A, Beheshti R. Bringing At-home Pediatric Sleep Apnea Testing Closer to Reality: A Multi-modal Transformer Approach. Proc Mach Learn Res. 2023 Aug;219:167-185. PMID: 38344396; PMCID: PMC10854997.\n",
        "https://github.com/healthylaife/Pediatric-Apnea-Detection/tree/main\n",
        "\n",
        "---\n",
        "\n",
        "The model includes the model definition which usually is a class, model training, and other necessary parts.\n",
        "  * Model architecture: layer number/size/type, activation function, etc\n",
        "  * Training objectives: loss function, optimizer, weight of each loss term, etc\n",
        "  * Others: whether the model is pretrained, Monte Carlo simulation for uncertainty analysis, etc\n",
        "  * The code of model should have classes of the model, functions of model training, model validation, etc.\n",
        "  * If your model training is done outside of this notebook, please upload the trained model here and develop a function to load and test it.\n",
        "\n",
        "---\n",
        "\n",
        "Similar to what’s documented in the original paper, we will be implementing a model consisting of four components: segmentor, tokenizer, transformer, and multi-layer perceptron.\n",
        "\n",
        "The segmentor will divide signals into equal-length epochs and forward them to the tokenizer. (This is done through pre-processing/dataloading steps shown previously.)\n",
        "\n",
        "The tokenizer will construct tokenized representations of the segmentor’s output. Once these tokens have been generated, they will be passed to the transformer.\n",
        "*   The tokenizer will handle regular and irregular time series data as well as data in tabular format. For consistency, data from all three formats will be resampled using a desired frequency (shown in pre-processing/dataloading).\n",
        "*   Tokenizing can be seen in the model code below, between Input(...) and before looping through transformer layers. Note that the Input shape is (Freq*Epoch_length, Num_signals). This input shapes needs to match what was created in preprocessing + dataloading steps.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The transformer will be constructed using five encoder modules. Each encoder module will consist of multi-head attention and a position-wise feed-forward network, supplemented by residual and normalization layers. The inspiration for each encoder module came from already established transformer architecture (Vaswani et al. 2017a); note that the decoder component from this architecture is not used as it is typically used for generative tasks and thus is not needed for our model. The multi-head attention will consist of concatenated attention heads and a final fully connected layer to facilitate the model’s ability to focus on information across various representation sub-spaces. In terms of the position-wise feed- forward network, it will be comprised of one fully connected layer followed by a ReLU activation unit and then another fully connected layer. Output from the transformer unit will be forwarded to the multi-layer perceptron for analysis and prediction.\n",
        "\n",
        "The multi-layer perceptron will be a two-layer fully connected network for forecasting the likelihood of an apnea-hypopnea event happening within a given epoch. The initial and subsequent layers of this network will consist of 256 and 128 neurons, respectively. Our model will use binary cross-entropy to determine loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWVkGmOlR3uf"
      },
      "outputs": [],
      "source": [
        "# this function is provided in the paper's github repo but we included it here for\n",
        "# clarity/describing key components\n",
        "# from create_transformer_model - https://github.com/healthylaife/Pediatric-Apnea-Detection/blob/main/models/transformer.py\n",
        "\n",
        "class Patches(Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, input):\n",
        "        input = input[:, tf.newaxis, :, :]\n",
        "        batch_size = tf.shape(input)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=input,\n",
        "            sizes=[1, 1, self.patch_size, 1],\n",
        "            strides=[1, 1, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches,\n",
        "                             [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "\n",
        "class PatchEncoder(Layer):\n",
        "    def __init__(self, num_patches, projection_dim, l2_weight):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.projection_dim = projection_dim\n",
        "        self.l2_weight = l2_weight\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = Dense(units=projection_dim, kernel_regularizer=L2(l2_weight),\n",
        "                                bias_regularizer=L2(l2_weight))\n",
        "        self.position_embedding = tf.keras.layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim)\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch)# + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "def mlp(x, hidden_units, dropout_rate, l2_weight):\n",
        "    for _, units in enumerate(hidden_units):\n",
        "        x = Dense(units, activation=None, kernel_regularizer=L2(l2_weight), bias_regularizer=L2(l2_weight))(x)\n",
        "        x = tf.nn.gelu(x)\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "def create_transformer_model(input_shape, num_patches,\n",
        "                             projection_dim, transformer_layers,\n",
        "                             num_heads, transformer_units, mlp_head_units,\n",
        "                             num_classes, drop_out, reg, l2_weight, demographic=False):\n",
        "    #not sure if we need to bother with regresion.\n",
        "    if reg:\n",
        "        activation = None\n",
        "    else:\n",
        "        activation = 'sigmoid'\n",
        "    inputs = Input(shape=input_shape)\n",
        "    patch_size = input_shape[0] / num_patches\n",
        "    normalized_inputs = tfa.layers.InstanceNormalization(axis=-1, epsilon=1e-6, center=False, scale=False,\n",
        "                                                             beta_initializer=\"glorot_uniform\",\n",
        "                                                             gamma_initializer=\"glorot_uniform\")(inputs)\n",
        "    patches = Patches(patch_size=patch_size)(normalized_inputs)\n",
        "    encoded_patches = PatchEncoder(num_patches=num_patches, projection_dim=projection_dim, l2_weight=l2_weight)(patches)\n",
        "    for i in range(transformer_layers):\n",
        "        x1 = encoded_patches # LayerNormalization(epsilon=1e-6)(encoded_patches) # TODO\n",
        "        attention_output = MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=drop_out, kernel_regularizer=L2(l2_weight),  # i *\n",
        "            bias_regularizer=L2(l2_weight))(x1, x1)\n",
        "        x2 = Add()([attention_output, encoded_patches])\n",
        "        x3 = LayerNormalization(epsilon=1e-6)(x2)\n",
        "        x3 = mlp(x3, transformer_units, drop_out, l2_weight)  # i *\n",
        "        encoded_patches = Add()([x3, x2])\n",
        "    x = LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    #x = Concatenate()([x, demo])\n",
        "    features = mlp(x, mlp_head_units, 0.0, l2_weight)\n",
        "\n",
        "    logits = Dense(num_classes, kernel_regularizer=L2(l2_weight), bias_regularizer=L2(l2_weight),\n",
        "                   activation=activation)(features)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ld8EHtnrZ_X"
      },
      "outputs": [],
      "source": [
        "# model + training code is similar to https://github.com/healthylaife/Pediatric-Apnea-Detection/blob/main/train.py with slight adjustments and documentation\n",
        "\n",
        "# Commented to let rest of model to run. (No Data processing/loading/training for Submission). We will be loading model from drive.\n",
        "# model = create_model((128 * 30, 3)) #draft mistake\n",
        "# model = create_transformer_model(input_shape, num_patches,\n",
        "#                              projection_dim, transformer_layers,\n",
        "#                              num_heads, transformer_units, mlp_head_units,\n",
        "#                              num_classes, drop_out, reg, l2_weight, demographic=False):\n",
        "\n",
        "#Our first model we are only using 3 channels.\n",
        "input_shape = (128 * 30, 3)\n",
        "num_patches = 30\n",
        "\n",
        "transformer_layers = 5\n",
        "num_heads = 4\n",
        "transformer_units = 32\n",
        "reg = False\n",
        "drop_out = 0.25\n",
        "l2_weight = 0.001\n",
        "\n",
        "model = create_transformer_model(input_shape, num_patches,\n",
        "                                projection_dim=transformer_units, transformer_layers=transformer_layers,\n",
        "                                num_heads=num_heads,\n",
        "                                transformer_units = [transformer_units*2, transformer_units],\n",
        "                                mlp_head_units=[256, 128],\n",
        "                                num_classes=1, drop_out=drop_out, reg=reg, l2_weight=l2_weight, demographic=False)\n",
        "loss_func = BinaryCrossentropy()\n",
        "optimizer = \"adam\"\n",
        "\n",
        "#Prevent over-fitting on same fold.\n",
        "def lr_schedule(epoch, lr):\n",
        "\n",
        "    if epoch > 50 and (epoch - 1) % 5 == 0:\n",
        "        lr *= 0.5\n",
        "\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSSZ38_J_ig7"
      },
      "source": [
        "#Training\n",
        "\n",
        "The training procedure contains the following steps:\n",
        "*   Load data from each fold and append to list.\n",
        "*   For each fold, set y = 1 for any seconds of apnea/hypopnea events and adjust x to only contain required signals (currently only [\"ECG\", \"SPO2\"])\n",
        "*   For each fold, we generate x_train and y_train based on data from all other folds. Then, the model is trainined on this set for 100 epochs. The epochs can be stopped early from early_stopper if loss isn't improving. lr_scheduler is used to reduce learning rate after 50 epochs to avoid over-fitting in the fold.\n",
        "*   A model for each fold is created and saved.\n",
        "\n",
        "We will start by training and testing a model using 2 signals only (3 channels): ECG, and SPO2.\n",
        "\n",
        "####Some Hyperparameters\n",
        "- Number of transformer layers = 5\n",
        "- Dropout = 0.25\n",
        "- Cross validation fold size = 5\n",
        "\n",
        "####Computation requirements\n",
        "The training and testing code was run on the T4 GPU provided by the Colab environment.\n",
        "\n",
        "Each epoch's average runtime was just a bit over 1 second and the total number of training epochs was 100.\n",
        "\n",
        "Total number of trials -- in the draft, we used a smaller datasize, but in the final we performed training and testing on more data. We trained the model a few times each time increasing the number of input files, making sure the GPU was able to handle it.\n",
        "\n",
        "The training code is found right in the cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBdVZoTvsSFV"
      },
      "outputs": [],
      "source": [
        "# training function for model\n",
        "\n",
        "def train(config, fold):\n",
        "  FOLD = fold\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(FOLD):\n",
        "    data = np.load(config[\"data_path\"] + str(i) + \".npz\", allow_pickle=True)\n",
        "    x.append(data['x'])\n",
        "    y.append(data['y_apnea'] + data['y_hypopnea'])\n",
        "\n",
        "  #x for specific channels\n",
        "  # print(x.shape)\n",
        "  x_chan = []\n",
        "  #  np.zeros( (x.shape[0],x.shape[1],x.shape[2], len(config[\"channels\"])))\n",
        "\n",
        "  print(len(x))\n",
        "  for i in range(FOLD):\n",
        "    x[i], y[i] = shuffle(x[i], y[i])\n",
        "    x[i] = np.nan_to_num(x[i], nan=-1)\n",
        "    y[i] = np.where(y[i] >= 1, 1, 0)\n",
        "    print(x[i].shape)\n",
        "    #Select specific channels from data.\n",
        "    x_chan.append(x[i][:, :, config[\"channels\"]])\n",
        "    print(x_chan[i].shape)\n",
        "\n",
        "  print(\"training\")\n",
        "  for fold in range(FOLD):\n",
        "    x_train, y_train = None, None\n",
        "    for i in range(FOLD):\n",
        "      if i != fold:\n",
        "        if isinstance(x_train, np.ndarray):\n",
        "          # x_train = x[i]\n",
        "          # y_train = y[i]\n",
        "          x_train = np.concatenate((x_train, x_chan[i]))\n",
        "          y_train = np.concatenate((y_train, y[i]))\n",
        "        else:\n",
        "          # x_train = np.concatenate((x_train, x[i]))\n",
        "          # y_train = np.concatenate((y_train, y[i]))\n",
        "          x_train = x_chan[i]\n",
        "          y_train = y[i]\n",
        "    print(x_train.shape)\n",
        "    print(y_train.shape)\n",
        "    model.compile(optimizer=optimizer, loss=loss_func,metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "\n",
        "    # Early stopping stops training when\n",
        "    # the training loss is no longer going down by much, so it's not worth it to continue training\n",
        "    early_stopper = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "    model.fit(x=x_train, y=y_train, batch_size=512, epochs=config[\"epochs\"], validation_split=0.1,\n",
        "                    callbacks=[early_stopper, lr_scheduler])\n",
        "    model.save(config[\"model_path\"] + config[\"model_name\"] + str(fold))\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "  print(\"training complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejuN22r34oWR"
      },
      "source": [
        "###Train Model for ECG and SPO2 (2 Signals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EobMyiMGSDQ",
        "outputId": "fb9a3e9f-aa41-434e-f97c-80637418d7d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "5\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n",
            "(3506, 3840, 3)\n",
            "training\n",
            "(14033, 3840, 3)\n",
            "(14033,)\n",
            "Epoch 1/100\n",
            "25/25 [==============================] - 17s 112ms/step - loss: 1.4524 - precision: 0.6316 - recall: 0.7559 - val_loss: 1.2858 - val_precision: 0.6501 - val_recall: 0.8597 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 1.1903 - precision: 0.6792 - recall: 0.7836 - val_loss: 1.0863 - val_precision: 0.6945 - val_recall: 0.8513 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 1.0253 - precision: 0.7138 - recall: 0.8002 - val_loss: 0.9813 - val_precision: 0.7706 - val_recall: 0.7069 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.9290 - precision: 0.7295 - recall: 0.8151 - val_loss: 0.8803 - val_precision: 0.7645 - val_recall: 0.7924 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.8486 - precision: 0.7628 - recall: 0.8142 - val_loss: 0.8129 - val_precision: 0.7550 - val_recall: 0.8471 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.7880 - precision: 0.7721 - recall: 0.8188 - val_loss: 0.7698 - val_precision: 0.7944 - val_recall: 0.8022 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.7470 - precision: 0.7818 - recall: 0.8233 - val_loss: 0.7384 - val_precision: 0.8009 - val_recall: 0.7896 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.7109 - precision: 0.7968 - recall: 0.8155 - val_loss: 0.7135 - val_precision: 0.7947 - val_recall: 0.8036 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.6818 - precision: 0.7939 - recall: 0.8233 - val_loss: 0.6821 - val_precision: 0.7959 - val_recall: 0.8149 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.6606 - precision: 0.7980 - recall: 0.8259 - val_loss: 0.6714 - val_precision: 0.7956 - val_recall: 0.8079 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.6525 - precision: 0.7905 - recall: 0.8158 - val_loss: 0.6527 - val_precision: 0.7964 - val_recall: 0.8121 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.6288 - precision: 0.8046 - recall: 0.8142 - val_loss: 0.6308 - val_precision: 0.7796 - val_recall: 0.8583 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.6141 - precision: 0.7953 - recall: 0.8350 - val_loss: 0.6380 - val_precision: 0.8227 - val_recall: 0.7616 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5999 - precision: 0.8102 - recall: 0.8257 - val_loss: 0.6090 - val_precision: 0.7906 - val_recall: 0.8471 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5880 - precision: 0.8055 - recall: 0.8336 - val_loss: 0.6087 - val_precision: 0.7743 - val_recall: 0.8612 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.5824 - precision: 0.8091 - recall: 0.8277 - val_loss: 0.5827 - val_precision: 0.7848 - val_recall: 0.8541 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.5701 - precision: 0.8070 - recall: 0.8373 - val_loss: 0.5681 - val_precision: 0.8106 - val_recall: 0.8345 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.5598 - precision: 0.8060 - recall: 0.8323 - val_loss: 0.5957 - val_precision: 0.8224 - val_recall: 0.7728 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.5577 - precision: 0.8087 - recall: 0.8309 - val_loss: 0.5642 - val_precision: 0.8297 - val_recall: 0.8065 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5410 - precision: 0.8140 - recall: 0.8378 - val_loss: 0.5697 - val_precision: 0.8065 - val_recall: 0.8415 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5405 - precision: 0.8114 - recall: 0.8307 - val_loss: 0.5788 - val_precision: 0.8272 - val_recall: 0.7854 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5353 - precision: 0.8129 - recall: 0.8305 - val_loss: 0.5470 - val_precision: 0.7931 - val_recall: 0.8654 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.5253 - precision: 0.8120 - recall: 0.8407 - val_loss: 0.5354 - val_precision: 0.8230 - val_recall: 0.8415 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5238 - precision: 0.8114 - recall: 0.8381 - val_loss: 0.5478 - val_precision: 0.8240 - val_recall: 0.8079 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5229 - precision: 0.8114 - recall: 0.8402 - val_loss: 0.5357 - val_precision: 0.7972 - val_recall: 0.8766 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5169 - precision: 0.8117 - recall: 0.8400 - val_loss: 0.5249 - val_precision: 0.8263 - val_recall: 0.8275 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5101 - precision: 0.8172 - recall: 0.8386 - val_loss: 0.5399 - val_precision: 0.7822 - val_recall: 0.8864 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.5145 - precision: 0.8052 - recall: 0.8378 - val_loss: 0.5172 - val_precision: 0.8252 - val_recall: 0.8275 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.5107 - precision: 0.8140 - recall: 0.8379 - val_loss: 0.5149 - val_precision: 0.8173 - val_recall: 0.8345 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.5008 - precision: 0.8168 - recall: 0.8349 - val_loss: 0.5134 - val_precision: 0.8178 - val_recall: 0.8373 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4993 - precision: 0.8179 - recall: 0.8339 - val_loss: 0.5069 - val_precision: 0.7970 - val_recall: 0.8864 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5012 - precision: 0.8105 - recall: 0.8395 - val_loss: 0.5206 - val_precision: 0.7831 - val_recall: 0.8864 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.5011 - precision: 0.8139 - recall: 0.8347 - val_loss: 0.5158 - val_precision: 0.7969 - val_recall: 0.8752 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4944 - precision: 0.8125 - recall: 0.8429 - val_loss: 0.5133 - val_precision: 0.8259 - val_recall: 0.8317 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4849 - precision: 0.8152 - recall: 0.8468 - val_loss: 0.5066 - val_precision: 0.8021 - val_recall: 0.8640 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4889 - precision: 0.8179 - recall: 0.8373 - val_loss: 0.4998 - val_precision: 0.7851 - val_recall: 0.8864 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4851 - precision: 0.8181 - recall: 0.8418 - val_loss: 0.5096 - val_precision: 0.8336 - val_recall: 0.8149 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4805 - precision: 0.8171 - recall: 0.8439 - val_loss: 0.4901 - val_precision: 0.8308 - val_recall: 0.8401 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4809 - precision: 0.8169 - recall: 0.8384 - val_loss: 0.5021 - val_precision: 0.7841 - val_recall: 0.8864 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4814 - precision: 0.8159 - recall: 0.8408 - val_loss: 0.4857 - val_precision: 0.8209 - val_recall: 0.8612 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4758 - precision: 0.8184 - recall: 0.8418 - val_loss: 0.5037 - val_precision: 0.8112 - val_recall: 0.8555 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4724 - precision: 0.8202 - recall: 0.8428 - val_loss: 0.4914 - val_precision: 0.8271 - val_recall: 0.8387 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4682 - precision: 0.8192 - recall: 0.8456 - val_loss: 0.4863 - val_precision: 0.8071 - val_recall: 0.8626 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4745 - precision: 0.8148 - recall: 0.8429 - val_loss: 0.4947 - val_precision: 0.7874 - val_recall: 0.8780 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4720 - precision: 0.8213 - recall: 0.8363 - val_loss: 0.4937 - val_precision: 0.8087 - val_recall: 0.8654 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4651 - precision: 0.8223 - recall: 0.8471 - val_loss: 0.5024 - val_precision: 0.8422 - val_recall: 0.7784 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.4618 - precision: 0.8251 - recall: 0.8391 - val_loss: 0.4809 - val_precision: 0.8137 - val_recall: 0.8640 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.4658 - precision: 0.8220 - recall: 0.8455 - val_loss: 0.4839 - val_precision: 0.8261 - val_recall: 0.8527 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4630 - precision: 0.8239 - recall: 0.8384 - val_loss: 0.4915 - val_precision: 0.7917 - val_recall: 0.8794 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4643 - precision: 0.8182 - recall: 0.8421 - val_loss: 0.5006 - val_precision: 0.8319 - val_recall: 0.8050 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.4703 - precision: 0.8146 - recall: 0.8363 - val_loss: 0.4967 - val_precision: 0.8388 - val_recall: 0.8177 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4563 - precision: 0.8219 - recall: 0.8429 - val_loss: 0.4856 - val_precision: 0.8150 - val_recall: 0.8710 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4563 - precision: 0.8211 - recall: 0.8479 - val_loss: 0.4785 - val_precision: 0.8267 - val_recall: 0.8429 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4526 - precision: 0.8306 - recall: 0.8442 - val_loss: 0.4850 - val_precision: 0.8248 - val_recall: 0.8317 - lr: 5.0000e-04\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.4518 - precision: 0.8214 - recall: 0.8532 - val_loss: 0.4755 - val_precision: 0.8354 - val_recall: 0.8401 - lr: 5.0000e-04\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.4475 - precision: 0.8245 - recall: 0.8524 - val_loss: 0.4852 - val_precision: 0.8272 - val_recall: 0.8261 - lr: 5.0000e-04\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.4441 - precision: 0.8305 - recall: 0.8469 - val_loss: 0.4742 - val_precision: 0.8185 - val_recall: 0.8668 - lr: 2.5000e-04\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4455 - precision: 0.8299 - recall: 0.8527 - val_loss: 0.4725 - val_precision: 0.8211 - val_recall: 0.8626 - lr: 2.5000e-04\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4444 - precision: 0.8219 - recall: 0.8545 - val_loss: 0.4754 - val_precision: 0.8381 - val_recall: 0.8205 - lr: 2.5000e-04\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4464 - precision: 0.8258 - recall: 0.8498 - val_loss: 0.4776 - val_precision: 0.8292 - val_recall: 0.8513 - lr: 2.5000e-04\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.4441 - precision: 0.8280 - recall: 0.8503 - val_loss: 0.4652 - val_precision: 0.8286 - val_recall: 0.8541 - lr: 2.5000e-04\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4412 - precision: 0.8280 - recall: 0.8546 - val_loss: 0.4674 - val_precision: 0.8206 - val_recall: 0.8597 - lr: 1.2500e-04\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4387 - precision: 0.8308 - recall: 0.8534 - val_loss: 0.4692 - val_precision: 0.8228 - val_recall: 0.8597 - lr: 1.2500e-04\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.4414 - precision: 0.8300 - recall: 0.8516 - val_loss: 0.4695 - val_precision: 0.8250 - val_recall: 0.8597 - lr: 1.2500e-04\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4375 - precision: 0.8300 - recall: 0.8518 - val_loss: 0.4702 - val_precision: 0.8263 - val_recall: 0.8541 - lr: 1.2500e-04\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4394 - precision: 0.8295 - recall: 0.8543 - val_loss: 0.4699 - val_precision: 0.8181 - val_recall: 0.8640 - lr: 1.2500e-04\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.4368 - precision: 0.8284 - recall: 0.8571 - val_loss: 0.4690 - val_precision: 0.8190 - val_recall: 0.8696 - lr: 6.2500e-05\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4403 - precision: 0.8239 - recall: 0.8514 - val_loss: 0.4677 - val_precision: 0.8226 - val_recall: 0.8583 - lr: 6.2500e-05\n",
            "Epoch 69/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4356 - precision: 0.8321 - recall: 0.8564 - val_loss: 0.4700 - val_precision: 0.8279 - val_recall: 0.8499 - lr: 6.2500e-05\n",
            "Epoch 70/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4378 - precision: 0.8281 - recall: 0.8545 - val_loss: 0.4716 - val_precision: 0.8287 - val_recall: 0.8415 - lr: 6.2500e-05\n",
            "Epoch 71/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.4387 - precision: 0.8313 - recall: 0.8556 - val_loss: 0.4722 - val_precision: 0.8319 - val_recall: 0.8401 - lr: 6.2500e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e94e747e680>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13473, 3840, 3)\n",
            "(13473,)\n",
            "Epoch 1/100\n",
            "24/24 [==============================] - 22s 121ms/step - loss: 0.4920 - precision: 0.8002 - recall: 0.8313 - val_loss: 0.4794 - val_precision: 0.8149 - val_recall: 0.8664 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 1s 56ms/step - loss: 0.4652 - precision: 0.8128 - recall: 0.8423 - val_loss: 0.4656 - val_precision: 0.8182 - val_recall: 0.8590 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4612 - precision: 0.8157 - recall: 0.8376 - val_loss: 0.4723 - val_precision: 0.8038 - val_recall: 0.8722 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4563 - precision: 0.8124 - recall: 0.8496 - val_loss: 0.4675 - val_precision: 0.8182 - val_recall: 0.8590 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4558 - precision: 0.8197 - recall: 0.8428 - val_loss: 0.4669 - val_precision: 0.8336 - val_recall: 0.8238 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4538 - precision: 0.8155 - recall: 0.8435 - val_loss: 0.4691 - val_precision: 0.8162 - val_recall: 0.8605 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4514 - precision: 0.8161 - recall: 0.8450 - val_loss: 0.4657 - val_precision: 0.8270 - val_recall: 0.8561 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4500 - precision: 0.8216 - recall: 0.8436 - val_loss: 0.4687 - val_precision: 0.8024 - val_recall: 0.8708 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4522 - precision: 0.8189 - recall: 0.8441 - val_loss: 0.4756 - val_precision: 0.8087 - val_recall: 0.8693 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.4552 - precision: 0.8167 - recall: 0.8421 - val_loss: 0.4662 - val_precision: 0.8048 - val_recall: 0.8840 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.4518 - precision: 0.8187 - recall: 0.8418 - val_loss: 0.4882 - val_precision: 0.7762 - val_recall: 0.8913 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.4491 - precision: 0.8181 - recall: 0.8495 - val_loss: 0.4708 - val_precision: 0.8360 - val_recall: 0.8311 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e94e747e680>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12966, 3840, 3)\n",
            "(12966,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 17s 119ms/step - loss: 0.4769 - precision: 0.8129 - recall: 0.8330 - val_loss: 0.4768 - val_precision: 0.7992 - val_recall: 0.8748 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4377 - precision: 0.8317 - recall: 0.8616 - val_loss: 0.4576 - val_precision: 0.8175 - val_recall: 0.8550 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4332 - precision: 0.8338 - recall: 0.8544 - val_loss: 0.4641 - val_precision: 0.8062 - val_recall: 0.8763 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4306 - precision: 0.8298 - recall: 0.8586 - val_loss: 0.4756 - val_precision: 0.8292 - val_recall: 0.8229 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4271 - precision: 0.8342 - recall: 0.8576 - val_loss: 0.4630 - val_precision: 0.8199 - val_recall: 0.8412 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4276 - precision: 0.8316 - recall: 0.8612 - val_loss: 0.4688 - val_precision: 0.8086 - val_recall: 0.8580 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4301 - precision: 0.8300 - recall: 0.8605 - val_loss: 0.4825 - val_precision: 0.8225 - val_recall: 0.8275 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4321 - precision: 0.8331 - recall: 0.8544 - val_loss: 0.4615 - val_precision: 0.8057 - val_recall: 0.8672 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4209 - precision: 0.8353 - recall: 0.8570 - val_loss: 0.4680 - val_precision: 0.8000 - val_recall: 0.8672 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4230 - precision: 0.8358 - recall: 0.8609 - val_loss: 0.4692 - val_precision: 0.7845 - val_recall: 0.8947 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4228 - precision: 0.8297 - recall: 0.8644 - val_loss: 0.4601 - val_precision: 0.8194 - val_recall: 0.8519 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.4222 - precision: 0.8344 - recall: 0.8584 - val_loss: 0.4521 - val_precision: 0.8224 - val_recall: 0.8626 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.4186 - precision: 0.8367 - recall: 0.8583 - val_loss: 0.4662 - val_precision: 0.8328 - val_recall: 0.8290 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4212 - precision: 0.8292 - recall: 0.8609 - val_loss: 0.4504 - val_precision: 0.8161 - val_recall: 0.8672 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4168 - precision: 0.8374 - recall: 0.8576 - val_loss: 0.4599 - val_precision: 0.8148 - val_recall: 0.8397 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4193 - precision: 0.8352 - recall: 0.8551 - val_loss: 0.4577 - val_precision: 0.7989 - val_recall: 0.8855 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4181 - precision: 0.8337 - recall: 0.8694 - val_loss: 0.4723 - val_precision: 0.8058 - val_recall: 0.8489 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4198 - precision: 0.8342 - recall: 0.8570 - val_loss: 0.4680 - val_precision: 0.7920 - val_recall: 0.8779 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4199 - precision: 0.8343 - recall: 0.8602 - val_loss: 0.4588 - val_precision: 0.8124 - val_recall: 0.8595 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.4185 - precision: 0.8327 - recall: 0.8563 - val_loss: 0.4459 - val_precision: 0.8214 - val_recall: 0.8565 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4193 - precision: 0.8335 - recall: 0.8537 - val_loss: 0.4799 - val_precision: 0.8374 - val_recall: 0.7939 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4165 - precision: 0.8401 - recall: 0.8548 - val_loss: 0.4591 - val_precision: 0.8083 - val_recall: 0.8626 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4109 - precision: 0.8381 - recall: 0.8672 - val_loss: 0.4536 - val_precision: 0.8132 - val_recall: 0.8641 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4088 - precision: 0.8372 - recall: 0.8633 - val_loss: 0.4555 - val_precision: 0.8141 - val_recall: 0.8489 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4132 - precision: 0.8355 - recall: 0.8668 - val_loss: 0.4488 - val_precision: 0.8108 - val_recall: 0.8702 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4078 - precision: 0.8401 - recall: 0.8665 - val_loss: 0.4551 - val_precision: 0.8238 - val_recall: 0.8565 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4083 - precision: 0.8381 - recall: 0.8628 - val_loss: 0.4503 - val_precision: 0.8114 - val_recall: 0.8672 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4092 - precision: 0.8402 - recall: 0.8637 - val_loss: 0.4490 - val_precision: 0.8236 - val_recall: 0.8412 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4153 - precision: 0.8378 - recall: 0.8576 - val_loss: 0.4601 - val_precision: 0.8052 - val_recall: 0.8580 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.4137 - precision: 0.8414 - recall: 0.8586 - val_loss: 0.4673 - val_precision: 0.7857 - val_recall: 0.8901 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e94e747e680>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12555, 3840, 3)\n",
            "(12555,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 17s 120ms/step - loss: 0.4627 - precision: 0.8079 - recall: 0.8313 - val_loss: 0.4497 - val_precision: 0.8041 - val_recall: 0.8758 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4562 - precision: 0.8081 - recall: 0.8429 - val_loss: 0.4491 - val_precision: 0.8363 - val_recall: 0.8296 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4512 - precision: 0.8155 - recall: 0.8357 - val_loss: 0.4702 - val_precision: 0.7735 - val_recall: 0.9188 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4564 - precision: 0.8100 - recall: 0.8411 - val_loss: 0.4374 - val_precision: 0.8262 - val_recall: 0.8551 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4502 - precision: 0.8138 - recall: 0.8445 - val_loss: 0.4413 - val_precision: 0.8208 - val_recall: 0.8535 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4512 - precision: 0.8162 - recall: 0.8365 - val_loss: 0.4641 - val_precision: 0.7725 - val_recall: 0.9029 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4528 - precision: 0.8077 - recall: 0.8399 - val_loss: 0.4352 - val_precision: 0.8076 - val_recall: 0.8822 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4534 - precision: 0.8069 - recall: 0.8463 - val_loss: 0.4684 - val_precision: 0.8559 - val_recall: 0.7946 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4529 - precision: 0.8179 - recall: 0.8343 - val_loss: 0.4493 - val_precision: 0.8455 - val_recall: 0.8105 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4467 - precision: 0.8190 - recall: 0.8404 - val_loss: 0.4384 - val_precision: 0.8410 - val_recall: 0.8424 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4457 - precision: 0.8235 - recall: 0.8349 - val_loss: 0.4400 - val_precision: 0.8127 - val_recall: 0.8774 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4470 - precision: 0.8149 - recall: 0.8483 - val_loss: 0.4630 - val_precision: 0.7679 - val_recall: 0.9061 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4470 - precision: 0.8129 - recall: 0.8447 - val_loss: 0.4680 - val_precision: 0.8493 - val_recall: 0.7898 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4512 - precision: 0.8164 - recall: 0.8295 - val_loss: 0.4533 - val_precision: 0.8283 - val_recall: 0.8376 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4450 - precision: 0.8184 - recall: 0.8450 - val_loss: 0.4362 - val_precision: 0.8189 - val_recall: 0.8710 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4384 - precision: 0.8163 - recall: 0.8488 - val_loss: 0.4401 - val_precision: 0.8088 - val_recall: 0.8822 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.4455 - precision: 0.8146 - recall: 0.8374 - val_loss: 0.4382 - val_precision: 0.8482 - val_recall: 0.8185 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e94e747e680>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13001, 3840, 3)\n",
            "(13001,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 17s 119ms/step - loss: 0.4582 - precision: 0.8149 - recall: 0.8335 - val_loss: 0.4000 - val_precision: 0.8385 - val_recall: 0.8889 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4378 - precision: 0.8212 - recall: 0.8472 - val_loss: 0.3881 - val_precision: 0.8496 - val_recall: 0.8904 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4388 - precision: 0.8210 - recall: 0.8503 - val_loss: 0.3926 - val_precision: 0.8691 - val_recall: 0.8574 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4396 - precision: 0.8194 - recall: 0.8467 - val_loss: 0.3958 - val_precision: 0.8457 - val_recall: 0.8724 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4402 - precision: 0.8209 - recall: 0.8441 - val_loss: 0.3900 - val_precision: 0.8466 - val_recall: 0.8784 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4388 - precision: 0.8173 - recall: 0.8502 - val_loss: 0.4010 - val_precision: 0.8658 - val_recall: 0.8333 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4393 - precision: 0.8197 - recall: 0.8424 - val_loss: 0.4220 - val_precision: 0.8756 - val_recall: 0.8033 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4344 - precision: 0.8232 - recall: 0.8427 - val_loss: 0.3936 - val_precision: 0.8663 - val_recall: 0.8559 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4310 - precision: 0.8227 - recall: 0.8528 - val_loss: 0.3938 - val_precision: 0.8640 - val_recall: 0.8679 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.4313 - precision: 0.8229 - recall: 0.8514 - val_loss: 0.3887 - val_precision: 0.8538 - val_recall: 0.8769 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4310 - precision: 0.8211 - recall: 0.8509 - val_loss: 0.3902 - val_precision: 0.8542 - val_recall: 0.8709 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 57ms/step - loss: 0.4326 - precision: 0.8188 - recall: 0.8448 - val_loss: 0.4015 - val_precision: 0.8364 - val_recall: 0.8904 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e94e747e680>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training complete\n"
          ]
        }
      ],
      "source": [
        "# from - https://github.com/healthylaife/Pediatric-Apnea-Detection/blob/main/main_chat.py with slight modifications\n",
        "# Commented to allow for rest of notebook to run. (No Data processing/loading/training for Submission)\n",
        "\n",
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "# sig_dict_chat = {\n",
        "#     \"EOG\": [0, 1],\n",
        "#     \"EEG\": [4, 5],\n",
        "#     \"ECG\": [15,16],\n",
        "#     \"Resp\": [9, 10],\n",
        "#     \"SPO2\": [13],\n",
        "#     \"CO2\": [14],\n",
        "# }\n",
        "\n",
        "# channel_list_chat = [\n",
        "#     [\"ECG\", \"SPO2\"],\n",
        "#     # [\"EOG\",\"EEG\",\"ECG\",\"Resp\",\"SPO2\",\"CO2\"]\n",
        "# ]\n",
        "\n",
        "# for ch in channel_list_chat:\n",
        "#     chs = []\n",
        "#     chstr = \"\"\n",
        "#     for name in ch:\n",
        "#         chstr += name\n",
        "#         chs = chs + sig_dict_chat[name]\n",
        "#     print(chstr, chs)\n",
        "#     config = {\n",
        "#         \"data_path\": data_path + 'chat_',\n",
        "#         \"model_path\": model_path,\n",
        "#         \"model_name\": \"model_nochanges_\"+ chstr,\n",
        "#         \"regression\": False,\n",
        "#         \"epochs\": 100,\n",
        "#         \"channels\": chs,\n",
        "#     }\n",
        "#     train(config, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8Hyk1jvu0D-"
      },
      "source": [
        "###Testing 2 signal model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw2KniQbYzpN"
      },
      "outputs": [],
      "source": [
        "#Similar to https://github.com/healthylaife/Pediatric-Apnea-Detection/blob/main/test.py with some modications + comments\n",
        "from PediatricApneaDetection.metrics import Result\n",
        "\n",
        "def test(config, fold):\n",
        "  FOLD = fold\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(FOLD):\n",
        "    data = np.load(config[\"data_path\"] + str(i) + \".npz\", allow_pickle=True)\n",
        "    x.append(data['x'])\n",
        "    y.append(data['y_apnea'] + data['y_hypopnea'])\n",
        "\n",
        "  #x for specific channels\n",
        "  x_chan = []\n",
        "\n",
        "  for i in range(FOLD):\n",
        "    x[i], y[i] = shuffle(x[i], y[i])\n",
        "    x[i] = np.nan_to_num(x[i], nan=-1)\n",
        "    y[i] = np.where(y[i] >= 1, 1, 0)\n",
        "    print(x[i].shape)\n",
        "    #Select specific channels from data.\n",
        "    x_chan.append(x[i][:, :, config[\"channels\"]])\n",
        "    print(x_chan[i].shape)\n",
        "\n",
        "  print(\"test starting\")\n",
        "  result = Result()\n",
        "  for i in range(FOLD):\n",
        "    x_test = x_chan[i]\n",
        "    y_test = y[i]\n",
        "    model = tf.keras.models.load_model(config[\"model_path\"] + config[\"model_name\"] + str(i), compile=False)\n",
        "\n",
        "    predict = model.predict(x_test)\n",
        "    y_score = predict\n",
        "    y_predict = np.where(predict > 0.5, 1, 0)\n",
        "\n",
        "    result.add(y_test, y_predict, y_score)\n",
        "\n",
        "  result.print()\n",
        "  result.save(config[\"model_name\"] + \".txt\", config)\n",
        "\n",
        "  del data, x_test, y_test, model, predict, y_score, y_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKgPpZSVe940",
        "outputId": "774155e5-0899-4fcd-85cd-d35a9e2df783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3506, 3840, 3)\n",
            "test starting\n",
            "78/78 [==============================] - 1s 9ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95/95 [==============================] - 2s 9ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 2s 9ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124/124 [==============================] - 2s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 2s 8ms/step\n",
            "=========================================================================== \n",
            "[83.67016976556184, 85.33289386947924, 79.63852019203614, 85.3997975708502, 83.37136337706788] \n",
            "[84.06275805119736, 85.02350570852921, 77.87750791974656, 83.49657198824681, 79.75077881619937] \n",
            "[82.83157038242473, 85.08064516129032, 83.00506471581318, 87.66066838046272, 88.83747831116253] \n",
            "[84.49799196787149, 85.57567917205692, 76.24716553287982, 83.208769307424, 78.05289814293754] \n",
            "[83.44262295081968, 85.05206583809203, 80.35957504767093, 85.52796588913971, 84.04924760601915] \n",
            "[91.66795742775822, 91.98799538176911, 87.12880762884782, 91.951460377112, 90.44789585322121] \n",
            "[90.50532562601704, 91.08212051423195, 85.78370576284499, 91.15527727700152, 89.01497585364044] \n",
            "Accuracy: 83.48 -+ 2.094 \n",
            "Precision: 82.04 -+ 2.745 \n",
            "Recall: 85.48 -+ 2.422 \n",
            "Specifity: 81.52 -+ 3.688 \n",
            "F1: 83.69 -+ 1.817 \n",
            "AUROC: 90.64 -+ 1.842 \n",
            "AUPRC: 89.51 -+ 2.015 \n",
            "$ 83.5 \\pm 2.1$& $82.0 \\pm 2.7$& $85.5 \\pm 2.4$& $83.7 \\pm 1.8$& $90.6 \\pm 1.8$& \n"
          ]
        }
      ],
      "source": [
        "#Test chat data\n",
        "\n",
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "sig_dict_chat = {\n",
        "    \"EOG\": [0, 1],\n",
        "    \"EEG\": [4, 5],\n",
        "    \"ECG\": [15,16],\n",
        "    \"Resp\": [9, 10],\n",
        "    \"SPO2\": [13],\n",
        "    \"CO2\": [14],\n",
        "}\n",
        "\n",
        "channel_list_chat = [\n",
        "    [\"ECG\", \"SPO2\"],\n",
        "]\n",
        "\n",
        "for ch in channel_list_chat:\n",
        "    chs = []\n",
        "    chstr = \"\"\n",
        "    for name in ch:\n",
        "        chstr += name\n",
        "        chs = chs + sig_dict_chat[name]\n",
        "    print(chstr, chs)\n",
        "    config = {\n",
        "        \"data_path\": data_path + 'chat_',\n",
        "        \"model_path\": model_path,\n",
        "        \"model_name\": \"model_nochanges_\"+ chstr,\n",
        "        \"channels\": chs,\n",
        "    }\n",
        "    test(config, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation\n",
        "\n",
        "As seen in the cell's output above, a couple of metrics are outputted from the testing code; the evaluation code is adapted from the author's code. Namely, accuracy, precision, recall, specificity, F1, AUROC, and AUPRC are evaluated.\n",
        "\n",
        "A brief decription is given for each metric below:\n",
        "\n",
        "- Accuracy - percentage measuring how many classifications did the model get correct.\n",
        "- Precision - measures the accuracy of positive predictions made by the model. It calculates the ratio of true positive predictions to all positive predictions made by the model.\n",
        "- Recall - measures the ability of the model to capture all the positive instances in the dataset. It calculates the ratio of true positive predictions to all actual positive instances in the dataset.\n",
        "- Specificity - measures the accuracy of negative predictions made by the model. It calculates the ratio of true negative predictions to all negative predictions made by the model.\n",
        "- F1 - harmonic mean of precision and recall to give a single score.\n",
        "- AUROC - stands for area under the receiver-operating characteristic. The true positive rate (sensitivity) is plotted against the false positive rate (1 - specificity). The higher the value the better.\n",
        "- AUPRC - stands for area under the precision recall curve. Precision is plotted against recall. The higher the value the better.\n",
        "\n",
        "**These metrics will similarly be outputted for the experiments below and be compared to the 2 signal model's output above.**"
      ],
      "metadata": {
        "id": "2loaD7t1wwGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results and Experiments Below"
      ],
      "metadata": {
        "id": "ByNQqkJJrqnx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb3XCvIWvCks"
      },
      "source": [
        "###Experiment: Training 6 Signals Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqPkjmKw-1ye"
      },
      "outputs": [],
      "source": [
        "#10 Channels used for the 6 signals (EOG, EEG, ECG, Resp, SPO2, and CO2).\n",
        "#Adjust Input Accordingly, (3 -> 10) from previous 2 signal model.\n",
        "input_shape = (128 * 30, 10)\n",
        "num_patches = 30\n",
        "\n",
        "transformer_layers = 5\n",
        "num_heads = 4\n",
        "transformer_units = 32\n",
        "reg = False\n",
        "drop_out = 0.25\n",
        "l2_weight = 0.001\n",
        "\n",
        "model = create_transformer_model(input_shape, num_patches,\n",
        "                                projection_dim=transformer_units, transformer_layers=transformer_layers,\n",
        "                                num_heads=num_heads,\n",
        "                                transformer_units = [transformer_units*2, transformer_units],\n",
        "                                mlp_head_units=[256, 128],\n",
        "                                num_classes=1, drop_out=drop_out, reg=reg, l2_weight=l2_weight, demographic=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59gZgznj6yyW",
        "outputId": "eb89c27e-ba27-494a-8ac2-24d08e80dee6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EOGEEGECGRespSPO2CO2 [0, 1, 4, 5, 15, 16, 9, 10, 13, 14]\n",
            "5\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 10)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 10)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 10)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 10)\n",
            "(3506, 3840, 17)\n",
            "(3506, 3840, 10)\n",
            "training\n",
            "(14033, 3840, 10)\n",
            "(14033,)\n",
            "Epoch 1/100\n",
            "25/25 [==============================] - 19s 158ms/step - loss: 1.4420 - precision: 0.6574 - recall: 0.7687 - val_loss: 1.3054 - val_precision: 0.6488 - val_recall: 0.8949 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 1.1624 - precision: 0.7130 - recall: 0.8375 - val_loss: 1.0908 - val_precision: 0.6882 - val_recall: 0.8466 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 1.0073 - precision: 0.7252 - recall: 0.8306 - val_loss: 0.9831 - val_precision: 0.7075 - val_recall: 0.7798 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 2s 80ms/step - loss: 0.8808 - precision: 0.7532 - recall: 0.8354 - val_loss: 0.8775 - val_precision: 0.7304 - val_recall: 0.7926 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.7984 - precision: 0.7739 - recall: 0.8225 - val_loss: 0.8081 - val_precision: 0.7103 - val_recall: 0.8707 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.7372 - precision: 0.7821 - recall: 0.8261 - val_loss: 0.7661 - val_precision: 0.7130 - val_recall: 0.8892 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.6932 - precision: 0.7901 - recall: 0.8269 - val_loss: 0.7289 - val_precision: 0.7453 - val_recall: 0.8395 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.6534 - precision: 0.7955 - recall: 0.8324 - val_loss: 0.6958 - val_precision: 0.7372 - val_recall: 0.8764 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.6260 - precision: 0.7965 - recall: 0.8374 - val_loss: 0.6631 - val_precision: 0.7479 - val_recall: 0.8679 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.6056 - precision: 0.7988 - recall: 0.8420 - val_loss: 0.6596 - val_precision: 0.7761 - val_recall: 0.8125 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.5843 - precision: 0.8049 - recall: 0.8404 - val_loss: 0.6466 - val_precision: 0.7609 - val_recall: 0.7955 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.5625 - precision: 0.8086 - recall: 0.8499 - val_loss: 0.6434 - val_precision: 0.7933 - val_recall: 0.7741 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.5594 - precision: 0.8050 - recall: 0.8467 - val_loss: 0.6110 - val_precision: 0.7882 - val_recall: 0.8139 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.5351 - precision: 0.8169 - recall: 0.8505 - val_loss: 0.6107 - val_precision: 0.7382 - val_recall: 0.9091 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.5323 - precision: 0.8054 - recall: 0.8638 - val_loss: 0.6012 - val_precision: 0.8174 - val_recall: 0.7628 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.5218 - precision: 0.8203 - recall: 0.8510 - val_loss: 0.5877 - val_precision: 0.7649 - val_recall: 0.8366 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.5099 - precision: 0.8123 - recall: 0.8669 - val_loss: 0.5759 - val_precision: 0.7989 - val_recall: 0.8068 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 2s 77ms/step - loss: 0.5047 - precision: 0.8125 - recall: 0.8678 - val_loss: 0.5689 - val_precision: 0.7977 - val_recall: 0.7898 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4998 - precision: 0.8138 - recall: 0.8659 - val_loss: 0.5524 - val_precision: 0.7848 - val_recall: 0.8494 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 2s 76ms/step - loss: 0.4904 - precision: 0.8173 - recall: 0.8719 - val_loss: 0.5587 - val_precision: 0.8019 - val_recall: 0.8281 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4813 - precision: 0.8208 - recall: 0.8693 - val_loss: 0.5664 - val_precision: 0.7404 - val_recall: 0.9318 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 2s 80ms/step - loss: 0.4897 - precision: 0.8154 - recall: 0.8699 - val_loss: 0.5707 - val_precision: 0.7594 - val_recall: 0.8920 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4742 - precision: 0.8202 - recall: 0.8714 - val_loss: 0.5547 - val_precision: 0.7914 - val_recall: 0.8409 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4674 - precision: 0.8242 - recall: 0.8807 - val_loss: 0.5487 - val_precision: 0.7876 - val_recall: 0.8324 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 2s 77ms/step - loss: 0.4633 - precision: 0.8242 - recall: 0.8804 - val_loss: 0.5495 - val_precision: 0.8118 - val_recall: 0.8026 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4724 - precision: 0.8179 - recall: 0.8760 - val_loss: 0.5535 - val_precision: 0.8174 - val_recall: 0.7884 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.4554 - precision: 0.8275 - recall: 0.8797 - val_loss: 0.5250 - val_precision: 0.7909 - val_recall: 0.8651 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.4547 - precision: 0.8268 - recall: 0.8821 - val_loss: 0.5195 - val_precision: 0.7921 - val_recall: 0.8551 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 2s 76ms/step - loss: 0.4464 - precision: 0.8277 - recall: 0.8847 - val_loss: 0.5634 - val_precision: 0.8242 - val_recall: 0.7457 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 2s 77ms/step - loss: 0.4497 - precision: 0.8269 - recall: 0.8778 - val_loss: 0.5476 - val_precision: 0.7556 - val_recall: 0.9091 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 2s 77ms/step - loss: 0.4410 - precision: 0.8259 - recall: 0.8863 - val_loss: 0.5259 - val_precision: 0.7833 - val_recall: 0.8679 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 2s 77ms/step - loss: 0.4407 - precision: 0.8296 - recall: 0.8826 - val_loss: 0.5280 - val_precision: 0.7702 - val_recall: 0.8523 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 2s 77ms/step - loss: 0.4419 - precision: 0.8279 - recall: 0.8826 - val_loss: 0.5276 - val_precision: 0.7927 - val_recall: 0.8580 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.4308 - precision: 0.8342 - recall: 0.8892 - val_loss: 0.5267 - val_precision: 0.7815 - val_recall: 0.8892 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4306 - precision: 0.8342 - recall: 0.8916 - val_loss: 0.5204 - val_precision: 0.7823 - val_recall: 0.8679 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4297 - precision: 0.8352 - recall: 0.8879 - val_loss: 0.5324 - val_precision: 0.7701 - val_recall: 0.8849 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.4295 - precision: 0.8329 - recall: 0.8898 - val_loss: 0.5139 - val_precision: 0.8123 - val_recall: 0.8054 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4272 - precision: 0.8333 - recall: 0.8937 - val_loss: 0.5166 - val_precision: 0.7872 - val_recall: 0.8565 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 2s 77ms/step - loss: 0.4339 - precision: 0.8336 - recall: 0.8805 - val_loss: 0.5165 - val_precision: 0.7621 - val_recall: 0.8920 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.4267 - precision: 0.8315 - recall: 0.8929 - val_loss: 0.5213 - val_precision: 0.8008 - val_recall: 0.8395 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4280 - precision: 0.8360 - recall: 0.8879 - val_loss: 0.5169 - val_precision: 0.7792 - val_recall: 0.8622 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 2s 77ms/step - loss: 0.4183 - precision: 0.8372 - recall: 0.8941 - val_loss: 0.5211 - val_precision: 0.7559 - val_recall: 0.9105 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4192 - precision: 0.8369 - recall: 0.8916 - val_loss: 0.5085 - val_precision: 0.7816 - val_recall: 0.8793 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4113 - precision: 0.8389 - recall: 0.8953 - val_loss: 0.5151 - val_precision: 0.7597 - val_recall: 0.8935 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4120 - precision: 0.8435 - recall: 0.8962 - val_loss: 0.5459 - val_precision: 0.7815 - val_recall: 0.8636 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.4123 - precision: 0.8417 - recall: 0.8863 - val_loss: 0.5273 - val_precision: 0.7601 - val_recall: 0.8821 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4182 - precision: 0.8390 - recall: 0.8940 - val_loss: 0.5386 - val_precision: 0.7552 - val_recall: 0.8764 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4131 - precision: 0.8372 - recall: 0.8956 - val_loss: 0.5146 - val_precision: 0.7775 - val_recall: 0.8835 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 0.4152 - precision: 0.8412 - recall: 0.8893 - val_loss: 0.5209 - val_precision: 0.8039 - val_recall: 0.8153 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4153 - precision: 0.8416 - recall: 0.8905 - val_loss: 0.5121 - val_precision: 0.7968 - val_recall: 0.8466 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.4021 - precision: 0.8446 - recall: 0.8994 - val_loss: 0.5139 - val_precision: 0.7824 - val_recall: 0.8580 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 0.3911 - precision: 0.8447 - recall: 0.9108 - val_loss: 0.5475 - val_precision: 0.7811 - val_recall: 0.8565 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 2s 80ms/step - loss: 0.3923 - precision: 0.8496 - recall: 0.9033 - val_loss: 0.5390 - val_precision: 0.8028 - val_recall: 0.8210 - lr: 5.0000e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e94e747e0b0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13473, 3840, 10)\n",
            "(13473,)\n",
            "Epoch 1/100\n",
            "24/24 [==============================] - 24s 160ms/step - loss: 0.4749 - precision: 0.8088 - recall: 0.8675 - val_loss: 0.5114 - val_precision: 0.8074 - val_recall: 0.8086 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.4392 - precision: 0.8250 - recall: 0.8896 - val_loss: 0.4984 - val_precision: 0.8020 - val_recall: 0.8531 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 2s 78ms/step - loss: 0.4333 - precision: 0.8260 - recall: 0.8923 - val_loss: 0.5077 - val_precision: 0.7983 - val_recall: 0.8398 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.4288 - precision: 0.8292 - recall: 0.8889 - val_loss: 0.5119 - val_precision: 0.7992 - val_recall: 0.8442 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.4252 - precision: 0.8279 - recall: 0.8921 - val_loss: 0.5322 - val_precision: 0.8124 - val_recall: 0.8160 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 2s 79ms/step - loss: 0.4245 - precision: 0.8299 - recall: 0.8853 - val_loss: 0.5208 - val_precision: 0.8079 - val_recall: 0.8234 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 2s 78ms/step - loss: 0.4229 - precision: 0.8295 - recall: 0.8928 - val_loss: 0.5079 - val_precision: 0.8132 - val_recall: 0.8205 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 2s 78ms/step - loss: 0.4177 - precision: 0.8336 - recall: 0.8944 - val_loss: 0.5108 - val_precision: 0.8072 - val_recall: 0.8264 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 2s 78ms/step - loss: 0.4199 - precision: 0.8309 - recall: 0.8908 - val_loss: 0.5067 - val_precision: 0.7918 - val_recall: 0.8576 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 2s 79ms/step - loss: 0.4136 - precision: 0.8355 - recall: 0.9026 - val_loss: 0.5141 - val_precision: 0.7802 - val_recall: 0.8635 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 2s 79ms/step - loss: 0.4126 - precision: 0.8345 - recall: 0.8968 - val_loss: 0.4924 - val_precision: 0.7932 - val_recall: 0.8650 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.4078 - precision: 0.8385 - recall: 0.8984 - val_loss: 0.5090 - val_precision: 0.7963 - val_recall: 0.8412 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 2s 78ms/step - loss: 0.4146 - precision: 0.8360 - recall: 0.8919 - val_loss: 0.5064 - val_precision: 0.7581 - val_recall: 0.9021 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 2s 80ms/step - loss: 0.4088 - precision: 0.8369 - recall: 0.8981 - val_loss: 0.5305 - val_precision: 0.8202 - val_recall: 0.8056 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 2s 79ms/step - loss: 0.4081 - precision: 0.8393 - recall: 0.8948 - val_loss: 0.5206 - val_precision: 0.8093 - val_recall: 0.8249 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 2s 79ms/step - loss: 0.4007 - precision: 0.8379 - recall: 0.9023 - val_loss: 0.5313 - val_precision: 0.8000 - val_recall: 0.8309 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 2s 79ms/step - loss: 0.3995 - precision: 0.8429 - recall: 0.9014 - val_loss: 0.5180 - val_precision: 0.7960 - val_recall: 0.8338 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 2s 82ms/step - loss: 0.3991 - precision: 0.8464 - recall: 0.8993 - val_loss: 0.5422 - val_precision: 0.7186 - val_recall: 0.9436 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 2s 79ms/step - loss: 0.4166 - precision: 0.8274 - recall: 0.8978 - val_loss: 0.5217 - val_precision: 0.8076 - val_recall: 0.8160 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 2s 78ms/step - loss: 0.4104 - precision: 0.8389 - recall: 0.8904 - val_loss: 0.5233 - val_precision: 0.8088 - val_recall: 0.8160 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 2s 81ms/step - loss: 0.3956 - precision: 0.8442 - recall: 0.9058 - val_loss: 0.5488 - val_precision: 0.7997 - val_recall: 0.8353 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e94e747e0b0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12966, 3840, 10)\n",
            "(12966,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 18s 159ms/step - loss: 0.5000 - precision: 0.7910 - recall: 0.8426 - val_loss: 0.5160 - val_precision: 0.8075 - val_recall: 0.8012 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.4509 - precision: 0.8186 - recall: 0.8588 - val_loss: 0.5128 - val_precision: 0.7971 - val_recall: 0.8351 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.4253 - precision: 0.8291 - recall: 0.8779 - val_loss: 0.5031 - val_precision: 0.7772 - val_recall: 0.8706 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.4153 - precision: 0.8336 - recall: 0.8875 - val_loss: 0.5134 - val_precision: 0.8216 - val_recall: 0.8089 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.4162 - precision: 0.8341 - recall: 0.8851 - val_loss: 0.5108 - val_precision: 0.8134 - val_recall: 0.8059 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.4144 - precision: 0.8346 - recall: 0.8840 - val_loss: 0.5150 - val_precision: 0.7545 - val_recall: 0.8952 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.4094 - precision: 0.8372 - recall: 0.8896 - val_loss: 0.5047 - val_precision: 0.7755 - val_recall: 0.8891 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.4054 - precision: 0.8398 - recall: 0.8936 - val_loss: 0.5158 - val_precision: 0.8123 - val_recall: 0.8336 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.4080 - precision: 0.8405 - recall: 0.8903 - val_loss: 0.5019 - val_precision: 0.7843 - val_recall: 0.8629 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.4023 - precision: 0.8421 - recall: 0.8929 - val_loss: 0.5051 - val_precision: 0.8071 - val_recall: 0.8444 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 2s 76ms/step - loss: 0.3961 - precision: 0.8431 - recall: 0.8955 - val_loss: 0.5110 - val_precision: 0.7621 - val_recall: 0.8983 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.4069 - precision: 0.8353 - recall: 0.8887 - val_loss: 0.5179 - val_precision: 0.8099 - val_recall: 0.8336 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.3972 - precision: 0.8463 - recall: 0.8969 - val_loss: 0.5115 - val_precision: 0.7877 - val_recall: 0.8690 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.4013 - precision: 0.8411 - recall: 0.8905 - val_loss: 0.5167 - val_precision: 0.7927 - val_recall: 0.8659 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.3967 - precision: 0.8435 - recall: 0.8967 - val_loss: 0.5118 - val_precision: 0.8076 - val_recall: 0.8475 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.3932 - precision: 0.8467 - recall: 0.8955 - val_loss: 0.5217 - val_precision: 0.7526 - val_recall: 0.8998 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.3929 - precision: 0.8431 - recall: 0.8976 - val_loss: 0.5384 - val_precision: 0.8045 - val_recall: 0.8182 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.3923 - precision: 0.8475 - recall: 0.8964 - val_loss: 0.5305 - val_precision: 0.8196 - val_recall: 0.7843 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.3889 - precision: 0.8472 - recall: 0.8992 - val_loss: 0.5314 - val_precision: 0.7951 - val_recall: 0.8428 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e94e747e0b0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12555, 3840, 10)\n",
            "(12555,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 18s 156ms/step - loss: 0.4772 - precision: 0.8032 - recall: 0.8544 - val_loss: 0.5208 - val_precision: 0.7739 - val_recall: 0.8914 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.4336 - precision: 0.8291 - recall: 0.8728 - val_loss: 0.5089 - val_precision: 0.7731 - val_recall: 0.8818 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.4127 - precision: 0.8403 - recall: 0.8876 - val_loss: 0.5393 - val_precision: 0.7265 - val_recall: 0.9505 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.4262 - precision: 0.8233 - recall: 0.8901 - val_loss: 0.5302 - val_precision: 0.8285 - val_recall: 0.7796 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.4226 - precision: 0.8373 - recall: 0.8783 - val_loss: 0.5086 - val_precision: 0.8073 - val_recall: 0.8163 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.4073 - precision: 0.8407 - recall: 0.8819 - val_loss: 0.5075 - val_precision: 0.8287 - val_recall: 0.8035 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 2s 76ms/step - loss: 0.4052 - precision: 0.8423 - recall: 0.8915 - val_loss: 0.5293 - val_precision: 0.8253 - val_recall: 0.7923 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 2s 75ms/step - loss: 0.4149 - precision: 0.8355 - recall: 0.8828 - val_loss: 0.5181 - val_precision: 0.7772 - val_recall: 0.8802 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 2s 76ms/step - loss: 0.3976 - precision: 0.8468 - recall: 0.8939 - val_loss: 0.5012 - val_precision: 0.7725 - val_recall: 0.8898 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.4013 - precision: 0.8435 - recall: 0.8890 - val_loss: 0.5181 - val_precision: 0.8009 - val_recall: 0.8355 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.4027 - precision: 0.8451 - recall: 0.8880 - val_loss: 0.5466 - val_precision: 0.8386 - val_recall: 0.7636 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 2s 76ms/step - loss: 0.4134 - precision: 0.8383 - recall: 0.8798 - val_loss: 0.5173 - val_precision: 0.7857 - val_recall: 0.8610 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 2s 76ms/step - loss: 0.3964 - precision: 0.8479 - recall: 0.8937 - val_loss: 0.5060 - val_precision: 0.7712 - val_recall: 0.8722 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.3926 - precision: 0.8478 - recall: 0.8948 - val_loss: 0.5081 - val_precision: 0.7947 - val_recall: 0.8594 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.3968 - precision: 0.8489 - recall: 0.8873 - val_loss: 0.5092 - val_precision: 0.7686 - val_recall: 0.9073 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.4064 - precision: 0.8413 - recall: 0.8885 - val_loss: 0.4978 - val_precision: 0.7912 - val_recall: 0.8658 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 2s 76ms/step - loss: 0.3959 - precision: 0.8503 - recall: 0.8899 - val_loss: 0.5148 - val_precision: 0.8027 - val_recall: 0.8514 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.3938 - precision: 0.8469 - recall: 0.8912 - val_loss: 0.5358 - val_precision: 0.7381 - val_recall: 0.9137 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 2s 77ms/step - loss: 0.3920 - precision: 0.8460 - recall: 0.9032 - val_loss: 0.5211 - val_precision: 0.7571 - val_recall: 0.8962 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 2s 76ms/step - loss: 0.3984 - precision: 0.8432 - recall: 0.8964 - val_loss: 0.5168 - val_precision: 0.7841 - val_recall: 0.8530 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 2s 76ms/step - loss: 0.3916 - precision: 0.8498 - recall: 0.8967 - val_loss: 0.5307 - val_precision: 0.8333 - val_recall: 0.7748 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 2s 76ms/step - loss: 0.3992 - precision: 0.8474 - recall: 0.8833 - val_loss: 0.5260 - val_precision: 0.7461 - val_recall: 0.9201 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 2s 76ms/step - loss: 0.3914 - precision: 0.8521 - recall: 0.8967 - val_loss: 0.5275 - val_precision: 0.8288 - val_recall: 0.8195 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 2s 76ms/step - loss: 0.4009 - precision: 0.8492 - recall: 0.8873 - val_loss: 0.5509 - val_precision: 0.7543 - val_recall: 0.9169 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 2s 76ms/step - loss: 0.4001 - precision: 0.8422 - recall: 0.8951 - val_loss: 0.5098 - val_precision: 0.8018 - val_recall: 0.8594 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.3835 - precision: 0.8541 - recall: 0.8941 - val_loss: 0.5075 - val_precision: 0.8067 - val_recall: 0.8466 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e94e747e0b0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13001, 3840, 10)\n",
            "(13001,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 18s 160ms/step - loss: 0.4243 - precision: 0.8337 - recall: 0.8835 - val_loss: 0.4234 - val_precision: 0.8363 - val_recall: 0.8854 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.4020 - precision: 0.8435 - recall: 0.8938 - val_loss: 0.4392 - val_precision: 0.7913 - val_recall: 0.9567 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.3987 - precision: 0.8431 - recall: 0.8995 - val_loss: 0.4134 - val_precision: 0.8388 - val_recall: 0.8777 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.3947 - precision: 0.8477 - recall: 0.8918 - val_loss: 0.4231 - val_precision: 0.8380 - val_recall: 0.8885 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 0.3909 - precision: 0.8464 - recall: 0.9033 - val_loss: 0.4114 - val_precision: 0.8178 - val_recall: 0.9241 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.3903 - precision: 0.8495 - recall: 0.8942 - val_loss: 0.4148 - val_precision: 0.8234 - val_recall: 0.9025 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 0.3926 - precision: 0.8454 - recall: 0.9021 - val_loss: 0.4218 - val_precision: 0.8422 - val_recall: 0.8591 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.3948 - precision: 0.8466 - recall: 0.8985 - val_loss: 0.4215 - val_precision: 0.8213 - val_recall: 0.9180 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.3880 - precision: 0.8483 - recall: 0.9037 - val_loss: 0.4205 - val_precision: 0.8329 - val_recall: 0.9025 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.3809 - precision: 0.8503 - recall: 0.9052 - val_loss: 0.4262 - val_precision: 0.8206 - val_recall: 0.9133 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.3843 - precision: 0.8498 - recall: 0.9044 - val_loss: 0.4201 - val_precision: 0.8353 - val_recall: 0.8870 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 2s 78ms/step - loss: 0.3797 - precision: 0.8518 - recall: 0.9049 - val_loss: 0.4317 - val_precision: 0.8403 - val_recall: 0.8715 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 0.3870 - precision: 0.8452 - recall: 0.9020 - val_loss: 0.4167 - val_precision: 0.8357 - val_recall: 0.8978 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 2s 79ms/step - loss: 0.3839 - precision: 0.8482 - recall: 0.9078 - val_loss: 0.4348 - val_precision: 0.8379 - val_recall: 0.8560 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 2s 80ms/step - loss: 0.3807 - precision: 0.8590 - recall: 0.9037 - val_loss: 0.4178 - val_precision: 0.8225 - val_recall: 0.9040 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e94e747e0b0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training complete\n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "# sig_dict_chat = {\n",
        "#     \"EOG\": [0, 1],\n",
        "#     \"EEG\": [4, 5],\n",
        "#     \"ECG\": [15,16],\n",
        "#     \"Resp\": [9, 10],\n",
        "#     \"SPO2\": [13],\n",
        "#     \"CO2\": [14],\n",
        "# }\n",
        "\n",
        "# channel_list_chat = [\n",
        "#     [\"EOG\",\"EEG\",\"ECG\",\"Resp\",\"SPO2\",\"CO2\"]\n",
        "# ]\n",
        "\n",
        "# for ch in channel_list_chat:\n",
        "#     chs = []\n",
        "#     chstr = \"\"\n",
        "#     for name in ch:\n",
        "#         chstr += name\n",
        "#         chs = chs + sig_dict_chat[name]\n",
        "#     print(chstr, chs)\n",
        "#     config = {\n",
        "#         \"data_path\": data_path + 'chat_',\n",
        "#         \"model_path\": model_path,\n",
        "#         \"model_name\": \"model_nochanges_\"+ chstr,\n",
        "#         \"regression\": False,\n",
        "#         \"epochs\": 100,\n",
        "#         \"channels\": chs,\n",
        "#     }\n",
        "#     train(config, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeadu3MvCRjJ",
        "outputId": "89e136e5-f7be-4a93-e4bc-eb0f8ab7a40e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EOGEEGECGRespSPO2CO2 [0, 1, 4, 5, 15, 16, 9, 10, 13, 14]\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 10)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 10)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 10)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 10)\n",
            "(3506, 3840, 17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3506, 3840, 10)\n",
            "test starting\n",
            "78/78 [==============================] - 3s 11ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95/95 [==============================] - 2s 11ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 2s 10ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124/124 [==============================] - 2s 11ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 2s 10ms/step\n",
            "=========================================================================== \n",
            "[79.66855295068714, 84.27818061964403, 84.66534877153347, 85.32388663967612, 84.56930975470623] \n",
            "[76.15273775216139, 82.76085547634479, 81.13017154389506, 82.39202657807309, 80.52415210688592] \n",
            "[86.00488201790073, 85.81989247311827, 90.48958919527294, 89.25449871465295, 90.63042220936957] \n",
            "[73.4136546184739, 82.79430789133248, 78.79818594104309, 81.5146985550573, 78.67191896454699] \n",
            "[80.779518532671, 84.26261959749257, 85.55466879489227, 85.68608094768015, 85.27891156462584] \n",
            "[87.55719378735446, 91.78481756596975, 91.82828074017077, 91.57224777545942, 91.0882027370491] \n",
            "[85.26341794049439, 90.42547665950818, 89.23613177535422, 88.13724284150621, 87.73540429889051] \n",
            "Accuracy: 83.70 -+ 2.045 \n",
            "Precision: 80.59 -+ 2.364 \n",
            "Recall: 88.44 -+ 2.119 \n",
            "Specifity: 79.04 -+ 3.227 \n",
            "F1: 84.31 -+ 1.836 \n",
            "AUROC: 90.77 -+ 1.626 \n",
            "AUPRC: 88.16 -+ 1.724 \n",
            "$ 83.7 \\pm 2.0$& $80.6 \\pm 2.4$& $88.4 \\pm 2.1$& $84.3 \\pm 1.8$& $90.8 \\pm 1.6$& \n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "sig_dict_chat = {\n",
        "    \"EOG\": [0, 1],\n",
        "    \"EEG\": [4, 5],\n",
        "    \"ECG\": [15,16],\n",
        "    \"Resp\": [9, 10],\n",
        "    \"SPO2\": [13],\n",
        "    \"CO2\": [14],\n",
        "}\n",
        "\n",
        "channel_list_chat = [\n",
        "    [\"EOG\",\"EEG\",\"ECG\",\"Resp\",\"SPO2\",\"CO2\"]\n",
        "]\n",
        "\n",
        "for ch in channel_list_chat:\n",
        "    chs = []\n",
        "    chstr = \"\"\n",
        "    for name in ch:\n",
        "        chstr += name\n",
        "        chs = chs + sig_dict_chat[name]\n",
        "    print(chstr, chs)\n",
        "    config = {\n",
        "        \"data_path\": data_path + 'chat_',\n",
        "        \"model_path\": model_path,\n",
        "        \"model_name\": \"model_nochanges_\"+ chstr,\n",
        "        \"channels\": chs,\n",
        "    }\n",
        "    test(config, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcKOLqCV_lc1"
      },
      "source": [
        "## Discussion of experiment - Comparing the 2 and 6 signal models:\n",
        "\n",
        "ECG, SPO2 Model:\n",
        "*   F1: 83.69 -+ 1.817\n",
        "*   AUROC: 90.64 -+ 1.842\n",
        "\n",
        "EOG, EEG, ECG, Resp, SPO2, CO2 Model:\n",
        "*   F1: 84.31 -+ 1.836\n",
        "*   AUROC: 90.77 -+ 1.626\n",
        "\n",
        "As shown, the F1 and AUROC values is only 1-2% higher in the 6-signal model. This aligns with the original author's findings as discussed in results section. Since there is not much improvement using all 6 and it being more practical to collect ECG and SPO2 at home versus all signals, we will run hyperparameter and ablation experiments on the 2 signal model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxe1eH5TOOIg"
      },
      "source": [
        "###Train/Test Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT2DtJv0gmlZ"
      },
      "source": [
        "###Experiment - Dropout Test.\n",
        "\n",
        "Initially was 0.25. Running model with dropout of 0 and then .5\n",
        "\n",
        "Dropout: 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De_DmbGSgmzs"
      },
      "outputs": [],
      "source": [
        "input_shape = (128 * 30, 3) #input changed back to 3 channels.\n",
        "num_patches = 30\n",
        "\n",
        "transformer_layers = 5\n",
        "num_heads = 4\n",
        "transformer_units = 32\n",
        "reg = False\n",
        "drop_out = 0 #changed\n",
        "l2_weight = 0.001\n",
        "\n",
        "model = create_transformer_model(input_shape, num_patches,\n",
        "                                projection_dim=transformer_units, transformer_layers=transformer_layers,\n",
        "                                num_heads=num_heads,\n",
        "                                transformer_units = [transformer_units*2, transformer_units],\n",
        "                                mlp_head_units=[256, 128],\n",
        "                                num_classes=1, drop_out=drop_out, reg=reg, l2_weight=l2_weight, demographic=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhmyrUitnUij",
        "outputId": "f40e04f8-b2c0-414e-a171-5c5fbf10250d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "5\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n",
            "(3506, 3840, 3)\n",
            "training\n",
            "(14033, 3840, 3)\n",
            "(14033,)\n",
            "Epoch 1/100\n",
            "25/25 [==============================] - 18s 104ms/step - loss: 1.4772 - precision: 0.6265 - recall: 0.7516 - val_loss: 1.3124 - val_precision: 0.6861 - val_recall: 0.7568 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.2161 - precision: 0.6903 - recall: 0.8083 - val_loss: 1.1130 - val_precision: 0.6933 - val_recall: 0.8569 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.0606 - precision: 0.7166 - recall: 0.8133 - val_loss: 0.9883 - val_precision: 0.7212 - val_recall: 0.8584 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.9437 - precision: 0.7449 - recall: 0.8160 - val_loss: 0.8881 - val_precision: 0.8061 - val_recall: 0.7969 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.8702 - precision: 0.7689 - recall: 0.8157 - val_loss: 0.8198 - val_precision: 0.8000 - val_recall: 0.8240 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.8093 - precision: 0.7950 - recall: 0.8026 - val_loss: 0.7976 - val_precision: 0.7373 - val_recall: 0.8956 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.7733 - precision: 0.7913 - recall: 0.8128 - val_loss: 0.7415 - val_precision: 0.8446 - val_recall: 0.7854 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.7347 - precision: 0.8066 - recall: 0.8147 - val_loss: 0.7010 - val_precision: 0.7976 - val_recall: 0.8627 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.7031 - precision: 0.8065 - recall: 0.8252 - val_loss: 0.6730 - val_precision: 0.8221 - val_recall: 0.8398 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.6812 - precision: 0.8085 - recall: 0.8287 - val_loss: 0.6560 - val_precision: 0.8109 - val_recall: 0.8712 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.6579 - precision: 0.8142 - recall: 0.8309 - val_loss: 0.6462 - val_precision: 0.8214 - val_recall: 0.8226 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.6424 - precision: 0.8131 - recall: 0.8386 - val_loss: 0.6332 - val_precision: 0.8703 - val_recall: 0.7868 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.6399 - precision: 0.8111 - recall: 0.8260 - val_loss: 0.6210 - val_precision: 0.8171 - val_recall: 0.8498 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.6316 - precision: 0.8084 - recall: 0.8322 - val_loss: 0.6200 - val_precision: 0.7904 - val_recall: 0.8684 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.6155 - precision: 0.8128 - recall: 0.8314 - val_loss: 0.5971 - val_precision: 0.8138 - val_recall: 0.8627 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.5940 - precision: 0.8237 - recall: 0.8413 - val_loss: 0.5858 - val_precision: 0.8152 - val_recall: 0.8770 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.5970 - precision: 0.8152 - recall: 0.8345 - val_loss: 0.5903 - val_precision: 0.7908 - val_recall: 0.8870 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5866 - precision: 0.8180 - recall: 0.8389 - val_loss: 0.5658 - val_precision: 0.8503 - val_recall: 0.8369 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5880 - precision: 0.8128 - recall: 0.8272 - val_loss: 0.5611 - val_precision: 0.8406 - val_recall: 0.8526 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.5810 - precision: 0.8137 - recall: 0.8391 - val_loss: 0.5679 - val_precision: 0.8549 - val_recall: 0.7926 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5660 - precision: 0.8203 - recall: 0.8313 - val_loss: 0.5604 - val_precision: 0.8463 - val_recall: 0.8269 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5609 - precision: 0.8196 - recall: 0.8415 - val_loss: 0.5510 - val_precision: 0.8481 - val_recall: 0.8069 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.5597 - precision: 0.8136 - recall: 0.8372 - val_loss: 0.5641 - val_precision: 0.8386 - val_recall: 0.7954 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.5526 - precision: 0.8252 - recall: 0.8370 - val_loss: 0.5341 - val_precision: 0.8365 - val_recall: 0.8712 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5430 - precision: 0.8268 - recall: 0.8401 - val_loss: 0.5382 - val_precision: 0.8274 - val_recall: 0.8641 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5459 - precision: 0.8155 - recall: 0.8365 - val_loss: 0.5381 - val_precision: 0.8121 - val_recall: 0.8655 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5361 - precision: 0.8251 - recall: 0.8359 - val_loss: 0.5368 - val_precision: 0.8026 - val_recall: 0.8784 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5329 - precision: 0.8234 - recall: 0.8426 - val_loss: 0.5364 - val_precision: 0.8120 - val_recall: 0.8712 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5288 - precision: 0.8244 - recall: 0.8396 - val_loss: 0.5252 - val_precision: 0.8369 - val_recall: 0.8369 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 0.5275 - precision: 0.8251 - recall: 0.8386 - val_loss: 0.5275 - val_precision: 0.8202 - val_recall: 0.8484 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5265 - precision: 0.8195 - recall: 0.8373 - val_loss: 0.5177 - val_precision: 0.8168 - val_recall: 0.8741 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 0.5221 - precision: 0.8261 - recall: 0.8357 - val_loss: 0.5282 - val_precision: 0.8112 - val_recall: 0.8484 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.5222 - precision: 0.8248 - recall: 0.8380 - val_loss: 0.5252 - val_precision: 0.7901 - val_recall: 0.8884 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.5242 - precision: 0.8191 - recall: 0.8345 - val_loss: 0.5244 - val_precision: 0.7816 - val_recall: 0.8856 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5132 - precision: 0.8272 - recall: 0.8399 - val_loss: 0.5118 - val_precision: 0.8118 - val_recall: 0.8884 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 0.5091 - precision: 0.8222 - recall: 0.8494 - val_loss: 0.5160 - val_precision: 0.8449 - val_recall: 0.8183 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5186 - precision: 0.8202 - recall: 0.8322 - val_loss: 0.5075 - val_precision: 0.8388 - val_recall: 0.8412 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.5064 - precision: 0.8282 - recall: 0.8373 - val_loss: 0.5168 - val_precision: 0.7847 - val_recall: 0.8970 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.5048 - precision: 0.8265 - recall: 0.8452 - val_loss: 0.5063 - val_precision: 0.8611 - val_recall: 0.8069 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.5020 - precision: 0.8261 - recall: 0.8365 - val_loss: 0.4987 - val_precision: 0.8434 - val_recall: 0.8169 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 0.5025 - precision: 0.8205 - recall: 0.8466 - val_loss: 0.5039 - val_precision: 0.8487 - val_recall: 0.8026 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 0.5044 - precision: 0.8255 - recall: 0.8378 - val_loss: 0.5093 - val_precision: 0.8281 - val_recall: 0.8269 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.5025 - precision: 0.8259 - recall: 0.8330 - val_loss: 0.5007 - val_precision: 0.8107 - val_recall: 0.8698 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4868 - precision: 0.8349 - recall: 0.8458 - val_loss: 0.4903 - val_precision: 0.8264 - val_recall: 0.8512 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4906 - precision: 0.8289 - recall: 0.8476 - val_loss: 0.4882 - val_precision: 0.8209 - val_recall: 0.8784 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4845 - precision: 0.8299 - recall: 0.8465 - val_loss: 0.4835 - val_precision: 0.8242 - val_recall: 0.8856 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.4871 - precision: 0.8293 - recall: 0.8468 - val_loss: 0.4797 - val_precision: 0.8547 - val_recall: 0.8498 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4853 - precision: 0.8295 - recall: 0.8449 - val_loss: 0.4909 - val_precision: 0.8065 - val_recall: 0.8827 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4796 - precision: 0.8314 - recall: 0.8487 - val_loss: 0.4928 - val_precision: 0.8164 - val_recall: 0.8841 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 0.4799 - precision: 0.8315 - recall: 0.8486 - val_loss: 0.4918 - val_precision: 0.8008 - val_recall: 0.8798 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 0.4792 - precision: 0.8290 - recall: 0.8462 - val_loss: 0.4875 - val_precision: 0.8134 - val_recall: 0.8856 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4717 - precision: 0.8375 - recall: 0.8508 - val_loss: 0.4891 - val_precision: 0.8050 - val_recall: 0.8798 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 0.4680 - precision: 0.8353 - recall: 0.8526 - val_loss: 0.4810 - val_precision: 0.8154 - val_recall: 0.8784 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4635 - precision: 0.8383 - recall: 0.8514 - val_loss: 0.4828 - val_precision: 0.8352 - val_recall: 0.8484 - lr: 5.0000e-04\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4677 - precision: 0.8316 - recall: 0.8510 - val_loss: 0.4798 - val_precision: 0.8158 - val_recall: 0.8741 - lr: 5.0000e-04\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4663 - precision: 0.8342 - recall: 0.8530 - val_loss: 0.4741 - val_precision: 0.8295 - val_recall: 0.8770 - lr: 5.0000e-04\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4590 - precision: 0.8385 - recall: 0.8593 - val_loss: 0.4725 - val_precision: 0.8336 - val_recall: 0.8526 - lr: 2.5000e-04\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4587 - precision: 0.8390 - recall: 0.8587 - val_loss: 0.4683 - val_precision: 0.8420 - val_recall: 0.8541 - lr: 2.5000e-04\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4596 - precision: 0.8403 - recall: 0.8530 - val_loss: 0.4760 - val_precision: 0.8275 - val_recall: 0.8512 - lr: 2.5000e-04\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 0.4567 - precision: 0.8397 - recall: 0.8604 - val_loss: 0.4729 - val_precision: 0.8317 - val_recall: 0.8698 - lr: 2.5000e-04\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 0.4577 - precision: 0.8377 - recall: 0.8559 - val_loss: 0.4701 - val_precision: 0.8210 - val_recall: 0.8727 - lr: 2.5000e-04\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4536 - precision: 0.8394 - recall: 0.8588 - val_loss: 0.4693 - val_precision: 0.8373 - val_recall: 0.8541 - lr: 1.2500e-04\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4523 - precision: 0.8414 - recall: 0.8615 - val_loss: 0.4736 - val_precision: 0.8319 - val_recall: 0.8569 - lr: 1.2500e-04\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4521 - precision: 0.8444 - recall: 0.8546 - val_loss: 0.4803 - val_precision: 0.8123 - val_recall: 0.8913 - lr: 1.2500e-04\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4531 - precision: 0.8400 - recall: 0.8593 - val_loss: 0.4732 - val_precision: 0.8241 - val_recall: 0.8712 - lr: 1.2500e-04\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 0.4525 - precision: 0.8380 - recall: 0.8654 - val_loss: 0.4706 - val_precision: 0.8340 - val_recall: 0.8627 - lr: 1.2500e-04\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 0.4488 - precision: 0.8436 - recall: 0.8607 - val_loss: 0.4728 - val_precision: 0.8294 - val_recall: 0.8555 - lr: 6.2500e-05\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.4484 - precision: 0.8412 - recall: 0.8670 - val_loss: 0.4709 - val_precision: 0.8433 - val_recall: 0.8469 - lr: 6.2500e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e9590188ca0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13473, 3840, 3)\n",
            "(13473,)\n",
            "Epoch 1/100\n",
            "24/24 [==============================] - 15s 104ms/step - loss: 0.5504 - precision: 0.7857 - recall: 0.8291 - val_loss: 0.4908 - val_precision: 0.8056 - val_recall: 0.8644 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.4909 - precision: 0.8263 - recall: 0.8328 - val_loss: 0.4893 - val_precision: 0.8046 - val_recall: 0.8838 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 0.4823 - precision: 0.8225 - recall: 0.8497 - val_loss: 0.4686 - val_precision: 0.8436 - val_recall: 0.8599 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.4761 - precision: 0.8259 - recall: 0.8434 - val_loss: 0.4755 - val_precision: 0.8358 - val_recall: 0.8495 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.4774 - precision: 0.8234 - recall: 0.8464 - val_loss: 0.4801 - val_precision: 0.8321 - val_recall: 0.8644 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.4772 - precision: 0.8265 - recall: 0.8461 - val_loss: 0.4774 - val_precision: 0.8429 - val_recall: 0.8316 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 0.4739 - precision: 0.8243 - recall: 0.8477 - val_loss: 0.4626 - val_precision: 0.8477 - val_recall: 0.8629 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.4741 - precision: 0.8233 - recall: 0.8519 - val_loss: 0.4763 - val_precision: 0.8599 - val_recall: 0.8048 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.4671 - precision: 0.8303 - recall: 0.8492 - val_loss: 0.4633 - val_precision: 0.8382 - val_recall: 0.8569 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.4669 - precision: 0.8279 - recall: 0.8507 - val_loss: 0.4794 - val_precision: 0.7987 - val_recall: 0.8987 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.4683 - precision: 0.8236 - recall: 0.8572 - val_loss: 0.4699 - val_precision: 0.8474 - val_recall: 0.8525 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.4733 - precision: 0.8213 - recall: 0.8446 - val_loss: 0.4647 - val_precision: 0.8585 - val_recall: 0.8227 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.4661 - precision: 0.8284 - recall: 0.8467 - val_loss: 0.5018 - val_precision: 0.7891 - val_recall: 0.9091 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.4648 - precision: 0.8229 - recall: 0.8609 - val_loss: 0.4739 - val_precision: 0.8382 - val_recall: 0.8182 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.4649 - precision: 0.8305 - recall: 0.8497 - val_loss: 0.4681 - val_precision: 0.8226 - val_recall: 0.8569 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 0.4608 - precision: 0.8328 - recall: 0.8539 - val_loss: 0.4570 - val_precision: 0.8343 - val_recall: 0.8778 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 0.4723 - precision: 0.8210 - recall: 0.8457 - val_loss: 0.4645 - val_precision: 0.8558 - val_recall: 0.8405 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.4645 - precision: 0.8283 - recall: 0.8494 - val_loss: 0.4608 - val_precision: 0.8402 - val_recall: 0.8539 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.4561 - precision: 0.8318 - recall: 0.8517 - val_loss: 0.4606 - val_precision: 0.8326 - val_recall: 0.8599 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.4589 - precision: 0.8273 - recall: 0.8555 - val_loss: 0.4694 - val_precision: 0.8161 - val_recall: 0.8599 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.4557 - precision: 0.8316 - recall: 0.8554 - val_loss: 0.4594 - val_precision: 0.8270 - val_recall: 0.8689 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 1s 48ms/step - loss: 0.4592 - precision: 0.8272 - recall: 0.8519 - val_loss: 0.4696 - val_precision: 0.8709 - val_recall: 0.7839 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.4577 - precision: 0.8282 - recall: 0.8512 - val_loss: 0.4600 - val_precision: 0.8472 - val_recall: 0.8346 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 1s 49ms/step - loss: 0.4614 - precision: 0.8251 - recall: 0.8502 - val_loss: 0.4596 - val_precision: 0.8164 - val_recall: 0.8748 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 1s 50ms/step - loss: 0.4593 - precision: 0.8237 - recall: 0.8536 - val_loss: 0.4591 - val_precision: 0.8580 - val_recall: 0.8197 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 1s 51ms/step - loss: 0.4526 - precision: 0.8277 - recall: 0.8522 - val_loss: 0.4577 - val_precision: 0.8372 - val_recall: 0.8510 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e9590188ca0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12966, 3840, 3)\n",
            "(12966,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 15s 107ms/step - loss: 0.4666 - precision: 0.8317 - recall: 0.8494 - val_loss: 0.4732 - val_precision: 0.8039 - val_recall: 0.8920 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4452 - precision: 0.8379 - recall: 0.8553 - val_loss: 0.4538 - val_precision: 0.8545 - val_recall: 0.8611 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4445 - precision: 0.8396 - recall: 0.8586 - val_loss: 0.4694 - val_precision: 0.8152 - val_recall: 0.8781 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4366 - precision: 0.8467 - recall: 0.8616 - val_loss: 0.4571 - val_precision: 0.8055 - val_recall: 0.9012 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4406 - precision: 0.8404 - recall: 0.8598 - val_loss: 0.4558 - val_precision: 0.8371 - val_recall: 0.8642 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4364 - precision: 0.8425 - recall: 0.8624 - val_loss: 0.4510 - val_precision: 0.8589 - val_recall: 0.8457 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.4423 - precision: 0.8378 - recall: 0.8597 - val_loss: 0.4549 - val_precision: 0.8437 - val_recall: 0.8580 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4341 - precision: 0.8436 - recall: 0.8583 - val_loss: 0.4580 - val_precision: 0.8115 - val_recall: 0.8904 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4368 - precision: 0.8352 - recall: 0.8619 - val_loss: 0.4603 - val_precision: 0.8149 - val_recall: 0.8765 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4433 - precision: 0.8405 - recall: 0.8563 - val_loss: 0.4653 - val_precision: 0.8169 - val_recall: 0.8673 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4376 - precision: 0.8394 - recall: 0.8579 - val_loss: 0.4609 - val_precision: 0.8173 - val_recall: 0.8627 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4293 - precision: 0.8447 - recall: 0.8659 - val_loss: 0.4500 - val_precision: 0.8260 - val_recall: 0.8719 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4257 - precision: 0.8440 - recall: 0.8664 - val_loss: 0.4517 - val_precision: 0.8369 - val_recall: 0.8549 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4294 - precision: 0.8386 - recall: 0.8624 - val_loss: 0.4448 - val_precision: 0.8549 - val_recall: 0.8549 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4269 - precision: 0.8401 - recall: 0.8666 - val_loss: 0.4483 - val_precision: 0.8265 - val_recall: 0.8673 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4229 - precision: 0.8472 - recall: 0.8624 - val_loss: 0.4648 - val_precision: 0.8139 - val_recall: 0.8704 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4290 - precision: 0.8406 - recall: 0.8607 - val_loss: 0.4706 - val_precision: 0.7989 - val_recall: 0.8889 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4328 - precision: 0.8359 - recall: 0.8562 - val_loss: 0.4554 - val_precision: 0.8308 - val_recall: 0.8565 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.4264 - precision: 0.8434 - recall: 0.8654 - val_loss: 0.4653 - val_precision: 0.7978 - val_recall: 0.9074 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.4295 - precision: 0.8433 - recall: 0.8583 - val_loss: 0.4536 - val_precision: 0.8184 - val_recall: 0.8904 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.4252 - precision: 0.8438 - recall: 0.8645 - val_loss: 0.4501 - val_precision: 0.8150 - val_recall: 0.8904 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4289 - precision: 0.8429 - recall: 0.8560 - val_loss: 0.4491 - val_precision: 0.8253 - val_recall: 0.8750 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4206 - precision: 0.8433 - recall: 0.8649 - val_loss: 0.4454 - val_precision: 0.8273 - val_recall: 0.8873 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4162 - precision: 0.8487 - recall: 0.8647 - val_loss: 0.4466 - val_precision: 0.8543 - val_recall: 0.8503 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e9590188ca0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12555, 3840, 3)\n",
            "(12555,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 15s 107ms/step - loss: 0.5093 - precision: 0.7982 - recall: 0.8279 - val_loss: 0.4550 - val_precision: 0.8318 - val_recall: 0.8752 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.4593 - precision: 0.8268 - recall: 0.8422 - val_loss: 0.4607 - val_precision: 0.8682 - val_recall: 0.8120 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4590 - precision: 0.8214 - recall: 0.8449 - val_loss: 0.4535 - val_precision: 0.8163 - val_recall: 0.8847 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.4616 - precision: 0.8249 - recall: 0.8436 - val_loss: 0.4470 - val_precision: 0.8668 - val_recall: 0.8325 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.4639 - precision: 0.8243 - recall: 0.8408 - val_loss: 0.4478 - val_precision: 0.8676 - val_recall: 0.8073 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4566 - precision: 0.8272 - recall: 0.8385 - val_loss: 0.4391 - val_precision: 0.8442 - val_recall: 0.8562 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4517 - precision: 0.8281 - recall: 0.8463 - val_loss: 0.4585 - val_precision: 0.8774 - val_recall: 0.8025 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.4565 - precision: 0.8258 - recall: 0.8449 - val_loss: 0.4643 - val_precision: 0.8060 - val_recall: 0.8863 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4541 - precision: 0.8262 - recall: 0.8426 - val_loss: 0.4448 - val_precision: 0.8318 - val_recall: 0.8831 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.4528 - precision: 0.8252 - recall: 0.8504 - val_loss: 0.4475 - val_precision: 0.8620 - val_recall: 0.8389 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4626 - precision: 0.8212 - recall: 0.8447 - val_loss: 0.4588 - val_precision: 0.8450 - val_recall: 0.8357 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4528 - precision: 0.8289 - recall: 0.8424 - val_loss: 0.4921 - val_precision: 0.7677 - val_recall: 0.9084 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4602 - precision: 0.8185 - recall: 0.8463 - val_loss: 0.4427 - val_precision: 0.8284 - val_recall: 0.8847 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.4481 - precision: 0.8269 - recall: 0.8454 - val_loss: 0.4617 - val_precision: 0.8122 - val_recall: 0.8815 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.4479 - precision: 0.8277 - recall: 0.8499 - val_loss: 0.4651 - val_precision: 0.7851 - val_recall: 0.9179 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4551 - precision: 0.8153 - recall: 0.8528 - val_loss: 0.4899 - val_precision: 0.8897 - val_recall: 0.7393 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e9590188ca0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13001, 3840, 3)\n",
            "(13001,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 16s 108ms/step - loss: 0.5046 - precision: 0.8044 - recall: 0.8299 - val_loss: 0.4317 - val_precision: 0.8043 - val_recall: 0.9054 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 48ms/step - loss: 0.4602 - precision: 0.8276 - recall: 0.8443 - val_loss: 0.4317 - val_precision: 0.8011 - val_recall: 0.9201 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4451 - precision: 0.8336 - recall: 0.8548 - val_loss: 0.4084 - val_precision: 0.8458 - val_recall: 0.8858 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4497 - precision: 0.8272 - recall: 0.8510 - val_loss: 0.4188 - val_precision: 0.8117 - val_recall: 0.9070 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4505 - precision: 0.8279 - recall: 0.8532 - val_loss: 0.4050 - val_precision: 0.8639 - val_recall: 0.8385 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4483 - precision: 0.8309 - recall: 0.8474 - val_loss: 0.4251 - val_precision: 0.8038 - val_recall: 0.9086 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4433 - precision: 0.8343 - recall: 0.8539 - val_loss: 0.4000 - val_precision: 0.8338 - val_recall: 0.9005 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4391 - precision: 0.8349 - recall: 0.8610 - val_loss: 0.4058 - val_precision: 0.8336 - val_recall: 0.8825 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4392 - precision: 0.8367 - recall: 0.8577 - val_loss: 0.3986 - val_precision: 0.8469 - val_recall: 0.8842 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4354 - precision: 0.8404 - recall: 0.8603 - val_loss: 0.4426 - val_precision: 0.7859 - val_recall: 0.9282 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4426 - precision: 0.8321 - recall: 0.8551 - val_loss: 0.4066 - val_precision: 0.8318 - val_recall: 0.8793 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4376 - precision: 0.8345 - recall: 0.8527 - val_loss: 0.3987 - val_precision: 0.8481 - val_recall: 0.8744 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4341 - precision: 0.8396 - recall: 0.8508 - val_loss: 0.4260 - val_precision: 0.8028 - val_recall: 0.9233 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4361 - precision: 0.8326 - recall: 0.8563 - val_loss: 0.3895 - val_precision: 0.8382 - val_recall: 0.8874 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4432 - precision: 0.8306 - recall: 0.8515 - val_loss: 0.4085 - val_precision: 0.8690 - val_recall: 0.8336 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4379 - precision: 0.8357 - recall: 0.8553 - val_loss: 0.4240 - val_precision: 0.8069 - val_recall: 0.9201 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4351 - precision: 0.8321 - recall: 0.8556 - val_loss: 0.4000 - val_precision: 0.8346 - val_recall: 0.8891 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4363 - precision: 0.8364 - recall: 0.8529 - val_loss: 0.3950 - val_precision: 0.8555 - val_recall: 0.8695 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4305 - precision: 0.8375 - recall: 0.8608 - val_loss: 0.4044 - val_precision: 0.8401 - val_recall: 0.8825 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4382 - precision: 0.8355 - recall: 0.8558 - val_loss: 0.4082 - val_precision: 0.8392 - val_recall: 0.8515 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4358 - precision: 0.8351 - recall: 0.8520 - val_loss: 0.4073 - val_precision: 0.8280 - val_recall: 0.8874 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4343 - precision: 0.8356 - recall: 0.8560 - val_loss: 0.4153 - val_precision: 0.8550 - val_recall: 0.8564 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.4337 - precision: 0.8367 - recall: 0.8548 - val_loss: 0.4012 - val_precision: 0.8406 - val_recall: 0.8777 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4382 - precision: 0.8331 - recall: 0.8560 - val_loss: 0.4023 - val_precision: 0.8506 - val_recall: 0.8728 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e9590188ca0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training complete\n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "# sig_dict_chat = {\n",
        "#     \"EOG\": [0, 1],\n",
        "#     \"EEG\": [4, 5],\n",
        "#     \"ECG\": [15,16],\n",
        "#     \"Resp\": [9, 10],\n",
        "#     \"SPO2\": [13],\n",
        "#     \"CO2\": [14],\n",
        "# }\n",
        "\n",
        "# channel_list_chat = [\n",
        "#     [\"ECG\", \"SPO2\"],\n",
        "# ]\n",
        "\n",
        "# for ch in channel_list_chat:\n",
        "#     chs = []\n",
        "#     chstr = \"\"\n",
        "#     for name in ch:\n",
        "#         chstr += name\n",
        "#         chs = chs + sig_dict_chat[name]\n",
        "#     print(chstr, chs)\n",
        "#     config = {\n",
        "#         \"data_path\": data_path + 'chat_',\n",
        "#         \"model_path\": model_path,\n",
        "#         \"model_name\": \"model_0dropout_\"+ chstr,\n",
        "#         \"regression\": False,\n",
        "#         \"epochs\": 100,\n",
        "#         \"channels\": chs,\n",
        "#     }\n",
        "#     train(config, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIp5ontanTo2",
        "outputId": "a9d08212-5d99-478c-91ad-18fd88dc85b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3506, 3840, 3)\n",
            "test starting\n",
            "78/78 [==============================] - 1s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95/95 [==============================] - 1s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 2s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124/124 [==============================] - 2s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 2s 8ms/step\n",
            "=========================================================================== \n",
            "[83.54890864995957, 84.37705998681608, 80.45749788195425, 85.90587044534414, 84.16999429549344] \n",
            "[84.13621262458472, 85.15950069348128, 79.15099408919936, 85.62628336755647, 81.3568376068376] \n",
            "[82.42473555736372, 82.52688172043011, 82.89251547552054, 85.75835475578405, 88.0855986119144] \n",
            "[84.65863453815261, 86.15782664941786, 78.00453514739229, 86.04882909815646, 80.3601575689364] \n",
            "[83.27168105219894, 83.82252559726963, 80.97855964815832, 85.69226817364499, 84.58761455151347] \n",
            "[91.19622509566337, 91.49261361265285, 87.9512337668138, 91.9877600634284, 91.00261909698274] \n",
            "[89.86421604815239, 90.88401382921899, 87.05273866730381, 90.54911904518397, 89.74822417328838] \n",
            "Accuracy: 83.69 -+ 1.793 \n",
            "Precision: 83.09 -+ 2.463 \n",
            "Recall: 84.34 -+ 2.240 \n",
            "Specifity: 83.05 -+ 3.284 \n",
            "F1: 83.67 -+ 1.572 \n",
            "AUROC: 90.73 -+ 1.427 \n",
            "AUPRC: 89.62 -+ 1.351 \n",
            "$ 83.7 \\pm 1.8$& $83.1 \\pm 2.5$& $84.3 \\pm 2.2$& $83.7 \\pm 1.6$& $90.7 \\pm 1.4$& \n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "sig_dict_chat = {\n",
        "    \"EOG\": [0, 1],\n",
        "    \"EEG\": [4, 5],\n",
        "    \"ECG\": [15,16],\n",
        "    \"Resp\": [9, 10],\n",
        "    \"SPO2\": [13],\n",
        "    \"CO2\": [14],\n",
        "}\n",
        "\n",
        "channel_list_chat = [\n",
        "    [\"ECG\", \"SPO2\"],\n",
        "]\n",
        "\n",
        "for ch in channel_list_chat:\n",
        "    chs = []\n",
        "    chstr = \"\"\n",
        "    for name in ch:\n",
        "        chstr += name\n",
        "        chs = chs + sig_dict_chat[name]\n",
        "    print(chstr, chs)\n",
        "    config = {\n",
        "        \"data_path\": data_path + 'chat_',\n",
        "        \"model_path\": model_path,\n",
        "        \"model_name\": \"model_0dropout_\"+ chstr,\n",
        "        \"channels\": chs,\n",
        "    }\n",
        "    test(config, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liNjmU24Fr_Y"
      },
      "source": [
        "Dropout: 0.5. This will ablate twice as many nodes than in the first transformer model (with dropout 0.25) we tested, and hence serves as an important ablation study. Additional ablation study is conducted further down in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oil6ygx5FQpC"
      },
      "outputs": [],
      "source": [
        "input_shape = (128 * 30, 3) #input changed back to 3 channels.\n",
        "num_patches = 30\n",
        "\n",
        "transformer_layers = 5\n",
        "num_heads = 4\n",
        "transformer_units = 32\n",
        "reg = False\n",
        "drop_out = 0.5 #changed\n",
        "l2_weight = 0.001\n",
        "\n",
        "model = create_transformer_model(input_shape, num_patches,\n",
        "                                projection_dim=transformer_units, transformer_layers=transformer_layers,\n",
        "                                num_heads=num_heads,\n",
        "                                transformer_units = [transformer_units*2, transformer_units],\n",
        "                                mlp_head_units=[256, 128],\n",
        "                                num_classes=1, drop_out=drop_out, reg=reg, l2_weight=l2_weight, demographic=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG2LcMDmFTev",
        "outputId": "26753ffb-43d7-417d-9eec-3f8a91bda34e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "5\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n",
            "(3506, 3840, 3)\n",
            "training\n",
            "(14033, 3840, 3)\n",
            "(14033,)\n",
            "Epoch 1/100\n",
            "25/25 [==============================] - 16s 106ms/step - loss: 1.4558 - precision: 0.6156 - recall: 0.7662 - val_loss: 1.2692 - val_precision: 0.6451 - val_recall: 0.8634 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 1.1775 - precision: 0.6699 - recall: 0.7965 - val_loss: 1.0673 - val_precision: 0.6737 - val_recall: 0.8663 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 1.0095 - precision: 0.6958 - recall: 0.7983 - val_loss: 0.9232 - val_precision: 0.7326 - val_recall: 0.7795 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.8880 - precision: 0.7260 - recall: 0.8037 - val_loss: 0.8271 - val_precision: 0.7747 - val_recall: 0.7582 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.8107 - precision: 0.7352 - recall: 0.8036 - val_loss: 0.7650 - val_precision: 0.7987 - val_recall: 0.7055 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.7496 - precision: 0.7522 - recall: 0.8042 - val_loss: 0.7189 - val_precision: 0.7949 - val_recall: 0.7553 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.7093 - precision: 0.7585 - recall: 0.8013 - val_loss: 0.6633 - val_precision: 0.8138 - val_recall: 0.7710 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.6725 - precision: 0.7643 - recall: 0.8071 - val_loss: 0.6371 - val_precision: 0.7941 - val_recall: 0.8009 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.6468 - precision: 0.7707 - recall: 0.8133 - val_loss: 0.6320 - val_precision: 0.8433 - val_recall: 0.7198 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.6282 - precision: 0.7719 - recall: 0.8156 - val_loss: 0.6030 - val_precision: 0.8292 - val_recall: 0.7525 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.6084 - precision: 0.7856 - recall: 0.8085 - val_loss: 0.5888 - val_precision: 0.8143 - val_recall: 0.7923 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5911 - precision: 0.7828 - recall: 0.8116 - val_loss: 0.5603 - val_precision: 0.8017 - val_recall: 0.8279 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5795 - precision: 0.7796 - recall: 0.8207 - val_loss: 0.5525 - val_precision: 0.8196 - val_recall: 0.8080 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5676 - precision: 0.7895 - recall: 0.8138 - val_loss: 0.5460 - val_precision: 0.8179 - val_recall: 0.7923 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5579 - precision: 0.7938 - recall: 0.8222 - val_loss: 0.5329 - val_precision: 0.8272 - val_recall: 0.8037 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5488 - precision: 0.7963 - recall: 0.8217 - val_loss: 0.5286 - val_precision: 0.8195 - val_recall: 0.8137 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5392 - precision: 0.7960 - recall: 0.8226 - val_loss: 0.5302 - val_precision: 0.8235 - val_recall: 0.7966 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5428 - precision: 0.7944 - recall: 0.8183 - val_loss: 0.5280 - val_precision: 0.8188 - val_recall: 0.8037 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5312 - precision: 0.7989 - recall: 0.8225 - val_loss: 0.5121 - val_precision: 0.8094 - val_recall: 0.8336 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5249 - precision: 0.7990 - recall: 0.8286 - val_loss: 0.5062 - val_precision: 0.8301 - val_recall: 0.7994 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5253 - precision: 0.7962 - recall: 0.8268 - val_loss: 0.5185 - val_precision: 0.8234 - val_recall: 0.8023 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5188 - precision: 0.7985 - recall: 0.8242 - val_loss: 0.4948 - val_precision: 0.8197 - val_recall: 0.8407 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5191 - precision: 0.8039 - recall: 0.8292 - val_loss: 0.5027 - val_precision: 0.7926 - val_recall: 0.8478 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5204 - precision: 0.7978 - recall: 0.8270 - val_loss: 0.4911 - val_precision: 0.8295 - val_recall: 0.8165 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5083 - precision: 0.8108 - recall: 0.8218 - val_loss: 0.5008 - val_precision: 0.8160 - val_recall: 0.8265 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.5078 - precision: 0.8049 - recall: 0.8321 - val_loss: 0.4938 - val_precision: 0.8096 - val_recall: 0.8407 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.5020 - precision: 0.8087 - recall: 0.8283 - val_loss: 0.4957 - val_precision: 0.8399 - val_recall: 0.8137 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4987 - precision: 0.8110 - recall: 0.8299 - val_loss: 0.4950 - val_precision: 0.8128 - val_recall: 0.8279 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4955 - precision: 0.8089 - recall: 0.8352 - val_loss: 0.4904 - val_precision: 0.8240 - val_recall: 0.8122 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4969 - precision: 0.8128 - recall: 0.8286 - val_loss: 0.4779 - val_precision: 0.7943 - val_recall: 0.8677 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4955 - precision: 0.8100 - recall: 0.8297 - val_loss: 0.4782 - val_precision: 0.8205 - val_recall: 0.8321 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4896 - precision: 0.8062 - recall: 0.8396 - val_loss: 0.4818 - val_precision: 0.8472 - val_recall: 0.8122 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4875 - precision: 0.8146 - recall: 0.8347 - val_loss: 0.4730 - val_precision: 0.8166 - val_recall: 0.8421 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4908 - precision: 0.8128 - recall: 0.8335 - val_loss: 0.4677 - val_precision: 0.8147 - val_recall: 0.8378 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4837 - precision: 0.8164 - recall: 0.8271 - val_loss: 0.4847 - val_precision: 0.7824 - val_recall: 0.8848 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4912 - precision: 0.8079 - recall: 0.8358 - val_loss: 0.4852 - val_precision: 0.8304 - val_recall: 0.8151 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4796 - precision: 0.8159 - recall: 0.8339 - val_loss: 0.4878 - val_precision: 0.7882 - val_recall: 0.8578 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4820 - precision: 0.8115 - recall: 0.8303 - val_loss: 0.4705 - val_precision: 0.8433 - val_recall: 0.8037 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4835 - precision: 0.8083 - recall: 0.8326 - val_loss: 0.4624 - val_precision: 0.8171 - val_recall: 0.8578 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4849 - precision: 0.8138 - recall: 0.8347 - val_loss: 0.4641 - val_precision: 0.8362 - val_recall: 0.8350 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4745 - precision: 0.8114 - recall: 0.8364 - val_loss: 0.4719 - val_precision: 0.8488 - val_recall: 0.8065 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4742 - precision: 0.8181 - recall: 0.8379 - val_loss: 0.4592 - val_precision: 0.8186 - val_recall: 0.8535 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4755 - precision: 0.8177 - recall: 0.8364 - val_loss: 0.4644 - val_precision: 0.8152 - val_recall: 0.8407 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4702 - precision: 0.8187 - recall: 0.8417 - val_loss: 0.4632 - val_precision: 0.8333 - val_recall: 0.8321 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4713 - precision: 0.8166 - recall: 0.8376 - val_loss: 0.4702 - val_precision: 0.7826 - val_recall: 0.8962 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4706 - precision: 0.8154 - recall: 0.8393 - val_loss: 0.4765 - val_precision: 0.8590 - val_recall: 0.7710 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4686 - precision: 0.8169 - recall: 0.8358 - val_loss: 0.4606 - val_precision: 0.8295 - val_recall: 0.8307 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4689 - precision: 0.8189 - recall: 0.8403 - val_loss: 0.4614 - val_precision: 0.8533 - val_recall: 0.8023 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4662 - precision: 0.8179 - recall: 0.8360 - val_loss: 0.4572 - val_precision: 0.8188 - val_recall: 0.8421 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4756 - precision: 0.8119 - recall: 0.8345 - val_loss: 0.4655 - val_precision: 0.8326 - val_recall: 0.8279 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4685 - precision: 0.8181 - recall: 0.8343 - val_loss: 0.4637 - val_precision: 0.8032 - val_recall: 0.8592 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4643 - precision: 0.8218 - recall: 0.8358 - val_loss: 0.4582 - val_precision: 0.8441 - val_recall: 0.8165 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4613 - precision: 0.8241 - recall: 0.8300 - val_loss: 0.4629 - val_precision: 0.8118 - val_recall: 0.8592 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4608 - precision: 0.8178 - recall: 0.8478 - val_loss: 0.4569 - val_precision: 0.8182 - val_recall: 0.8450 - lr: 5.0000e-04\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4585 - precision: 0.8239 - recall: 0.8385 - val_loss: 0.4674 - val_precision: 0.8132 - val_recall: 0.8421 - lr: 5.0000e-04\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4545 - precision: 0.8235 - recall: 0.8464 - val_loss: 0.4566 - val_precision: 0.8281 - val_recall: 0.8293 - lr: 5.0000e-04\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4532 - precision: 0.8266 - recall: 0.8395 - val_loss: 0.4506 - val_precision: 0.8292 - val_recall: 0.8492 - lr: 2.5000e-04\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4529 - precision: 0.8229 - recall: 0.8467 - val_loss: 0.4533 - val_precision: 0.8308 - val_recall: 0.8450 - lr: 2.5000e-04\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4504 - precision: 0.8242 - recall: 0.8441 - val_loss: 0.4587 - val_precision: 0.8348 - val_recall: 0.8265 - lr: 2.5000e-04\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4481 - precision: 0.8240 - recall: 0.8499 - val_loss: 0.4543 - val_precision: 0.8329 - val_recall: 0.8364 - lr: 2.5000e-04\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4528 - precision: 0.8277 - recall: 0.8425 - val_loss: 0.4512 - val_precision: 0.8152 - val_recall: 0.8535 - lr: 2.5000e-04\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4487 - precision: 0.8239 - recall: 0.8550 - val_loss: 0.4564 - val_precision: 0.8525 - val_recall: 0.8137 - lr: 1.2500e-04\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4515 - precision: 0.8281 - recall: 0.8400 - val_loss: 0.4548 - val_precision: 0.8357 - val_recall: 0.8321 - lr: 1.2500e-04\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4482 - precision: 0.8270 - recall: 0.8470 - val_loss: 0.4511 - val_precision: 0.8226 - val_recall: 0.8506 - lr: 1.2500e-04\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4475 - precision: 0.8257 - recall: 0.8507 - val_loss: 0.4522 - val_precision: 0.8312 - val_recall: 0.8336 - lr: 1.2500e-04\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4465 - precision: 0.8294 - recall: 0.8451 - val_loss: 0.4548 - val_precision: 0.8403 - val_recall: 0.8307 - lr: 1.2500e-04\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4470 - precision: 0.8247 - recall: 0.8485 - val_loss: 0.4538 - val_precision: 0.8282 - val_recall: 0.8364 - lr: 6.2500e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e9291bab490>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13473, 3840, 3)\n",
            "(13473,)\n",
            "Epoch 1/100\n",
            "24/24 [==============================] - 16s 109ms/step - loss: 0.4751 - precision: 0.8089 - recall: 0.8329 - val_loss: 0.4598 - val_precision: 0.8184 - val_recall: 0.8390 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4636 - precision: 0.8142 - recall: 0.8452 - val_loss: 0.4572 - val_precision: 0.7942 - val_recall: 0.8892 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4628 - precision: 0.8134 - recall: 0.8464 - val_loss: 0.4603 - val_precision: 0.8069 - val_recall: 0.8641 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4632 - precision: 0.8166 - recall: 0.8357 - val_loss: 0.4571 - val_precision: 0.8126 - val_recall: 0.8582 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4593 - precision: 0.8125 - recall: 0.8426 - val_loss: 0.4654 - val_precision: 0.8289 - val_recall: 0.8227 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4601 - precision: 0.8142 - recall: 0.8426 - val_loss: 0.4724 - val_precision: 0.8408 - val_recall: 0.8035 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4611 - precision: 0.8140 - recall: 0.8404 - val_loss: 0.4619 - val_precision: 0.8219 - val_recall: 0.8316 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 1s 51ms/step - loss: 0.4597 - precision: 0.8139 - recall: 0.8397 - val_loss: 0.4770 - val_precision: 0.8229 - val_recall: 0.8168 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4637 - precision: 0.8135 - recall: 0.8351 - val_loss: 0.4540 - val_precision: 0.8033 - val_recall: 0.8626 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4578 - precision: 0.8144 - recall: 0.8412 - val_loss: 0.4632 - val_precision: 0.8376 - val_recall: 0.8227 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4583 - precision: 0.8108 - recall: 0.8451 - val_loss: 0.4763 - val_precision: 0.8207 - val_recall: 0.7976 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 1s 51ms/step - loss: 0.4603 - precision: 0.8142 - recall: 0.8359 - val_loss: 0.4624 - val_precision: 0.8419 - val_recall: 0.8021 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4584 - precision: 0.8116 - recall: 0.8379 - val_loss: 0.4645 - val_precision: 0.8415 - val_recall: 0.8154 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.4558 - precision: 0.8176 - recall: 0.8417 - val_loss: 0.4503 - val_precision: 0.8190 - val_recall: 0.8419 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4545 - precision: 0.8162 - recall: 0.8439 - val_loss: 0.4608 - val_precision: 0.8274 - val_recall: 0.8213 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4588 - precision: 0.8149 - recall: 0.8366 - val_loss: 0.4562 - val_precision: 0.8081 - val_recall: 0.8582 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4598 - precision: 0.8125 - recall: 0.8364 - val_loss: 0.4504 - val_precision: 0.8109 - val_recall: 0.8552 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4556 - precision: 0.8125 - recall: 0.8386 - val_loss: 0.4682 - val_precision: 0.8482 - val_recall: 0.7843 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4528 - precision: 0.8149 - recall: 0.8391 - val_loss: 0.4580 - val_precision: 0.8364 - val_recall: 0.8080 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4531 - precision: 0.8173 - recall: 0.8397 - val_loss: 0.4608 - val_precision: 0.8274 - val_recall: 0.8287 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4555 - precision: 0.8174 - recall: 0.8351 - val_loss: 0.4523 - val_precision: 0.8234 - val_recall: 0.8331 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4481 - precision: 0.8137 - recall: 0.8474 - val_loss: 0.4489 - val_precision: 0.8281 - val_recall: 0.8183 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4589 - precision: 0.8138 - recall: 0.8367 - val_loss: 0.4718 - val_precision: 0.8122 - val_recall: 0.8242 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4562 - precision: 0.8136 - recall: 0.8376 - val_loss: 0.4491 - val_precision: 0.8241 - val_recall: 0.8375 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4508 - precision: 0.8173 - recall: 0.8346 - val_loss: 0.4532 - val_precision: 0.8328 - val_recall: 0.8316 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4499 - precision: 0.8152 - recall: 0.8416 - val_loss: 0.4597 - val_precision: 0.8048 - val_recall: 0.8464 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4489 - precision: 0.8189 - recall: 0.8434 - val_loss: 0.4474 - val_precision: 0.8060 - val_recall: 0.8715 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4494 - precision: 0.8166 - recall: 0.8449 - val_loss: 0.4554 - val_precision: 0.8366 - val_recall: 0.8242 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4498 - precision: 0.8189 - recall: 0.8323 - val_loss: 0.4642 - val_precision: 0.7700 - val_recall: 0.8804 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 1s 51ms/step - loss: 0.4559 - precision: 0.8083 - recall: 0.8462 - val_loss: 0.4667 - val_precision: 0.8438 - val_recall: 0.7903 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4534 - precision: 0.8190 - recall: 0.8357 - val_loss: 0.4552 - val_precision: 0.8351 - val_recall: 0.8154 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4446 - precision: 0.8197 - recall: 0.8481 - val_loss: 0.4524 - val_precision: 0.7978 - val_recall: 0.8626 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4480 - precision: 0.8111 - recall: 0.8442 - val_loss: 0.4631 - val_precision: 0.8193 - val_recall: 0.8168 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4506 - precision: 0.8119 - recall: 0.8389 - val_loss: 0.4508 - val_precision: 0.8309 - val_recall: 0.8346 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4500 - precision: 0.8164 - recall: 0.8479 - val_loss: 0.4566 - val_precision: 0.8200 - val_recall: 0.8346 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4441 - precision: 0.8175 - recall: 0.8446 - val_loss: 0.4459 - val_precision: 0.8163 - val_recall: 0.8597 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4470 - precision: 0.8191 - recall: 0.8411 - val_loss: 0.4474 - val_precision: 0.8058 - val_recall: 0.8582 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4420 - precision: 0.8198 - recall: 0.8462 - val_loss: 0.4555 - val_precision: 0.8419 - val_recall: 0.8021 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 1s 51ms/step - loss: 0.4443 - precision: 0.8126 - recall: 0.8446 - val_loss: 0.4590 - val_precision: 0.8198 - val_recall: 0.8331 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4455 - precision: 0.8148 - recall: 0.8386 - val_loss: 0.4594 - val_precision: 0.8372 - val_recall: 0.8050 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4440 - precision: 0.8191 - recall: 0.8409 - val_loss: 0.4503 - val_precision: 0.8025 - val_recall: 0.8641 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4389 - precision: 0.8168 - recall: 0.8512 - val_loss: 0.4429 - val_precision: 0.8190 - val_recall: 0.8419 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4415 - precision: 0.8170 - recall: 0.8406 - val_loss: 0.4415 - val_precision: 0.8038 - val_recall: 0.8715 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4470 - precision: 0.8147 - recall: 0.8396 - val_loss: 0.4761 - val_precision: 0.8581 - val_recall: 0.7681 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4418 - precision: 0.8198 - recall: 0.8406 - val_loss: 0.4482 - val_precision: 0.8294 - val_recall: 0.8257 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4461 - precision: 0.8145 - recall: 0.8482 - val_loss: 0.4460 - val_precision: 0.8162 - val_recall: 0.8464 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 1s 51ms/step - loss: 0.4416 - precision: 0.8210 - recall: 0.8456 - val_loss: 0.4454 - val_precision: 0.8196 - val_recall: 0.8390 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 1s 51ms/step - loss: 0.4447 - precision: 0.8173 - recall: 0.8426 - val_loss: 0.4465 - val_precision: 0.8070 - val_recall: 0.8523 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4381 - precision: 0.8192 - recall: 0.8469 - val_loss: 0.4785 - val_precision: 0.8419 - val_recall: 0.7784 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4449 - precision: 0.8200 - recall: 0.8356 - val_loss: 0.4488 - val_precision: 0.8126 - val_recall: 0.8390 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 1s 51ms/step - loss: 0.4447 - precision: 0.8179 - recall: 0.8442 - val_loss: 0.4647 - val_precision: 0.7947 - val_recall: 0.8464 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4368 - precision: 0.8216 - recall: 0.8452 - val_loss: 0.4533 - val_precision: 0.8353 - val_recall: 0.8168 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4328 - precision: 0.8250 - recall: 0.8426 - val_loss: 0.4517 - val_precision: 0.8174 - val_recall: 0.8198 - lr: 5.0000e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e9291bab490>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12966, 3840, 3)\n",
            "(12966,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 16s 113ms/step - loss: 0.4423 - precision: 0.8255 - recall: 0.8438 - val_loss: 0.4761 - val_precision: 0.7954 - val_recall: 0.8444 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4207 - precision: 0.8340 - recall: 0.8528 - val_loss: 0.4553 - val_precision: 0.8234 - val_recall: 0.8120 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4179 - precision: 0.8346 - recall: 0.8527 - val_loss: 0.4570 - val_precision: 0.8163 - val_recall: 0.8351 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4242 - precision: 0.8311 - recall: 0.8511 - val_loss: 0.4672 - val_precision: 0.8038 - val_recall: 0.8459 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4208 - precision: 0.8346 - recall: 0.8527 - val_loss: 0.4668 - val_precision: 0.8280 - val_recall: 0.8012 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4192 - precision: 0.8378 - recall: 0.8555 - val_loss: 0.4709 - val_precision: 0.8418 - val_recall: 0.7874 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4237 - precision: 0.8341 - recall: 0.8555 - val_loss: 0.4549 - val_precision: 0.8282 - val_recall: 0.8243 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4181 - precision: 0.8373 - recall: 0.8530 - val_loss: 0.4630 - val_precision: 0.7989 - val_recall: 0.8567 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4179 - precision: 0.8340 - recall: 0.8548 - val_loss: 0.4461 - val_precision: 0.8262 - val_recall: 0.8351 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4166 - precision: 0.8378 - recall: 0.8539 - val_loss: 0.4516 - val_precision: 0.8117 - val_recall: 0.8305 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4147 - precision: 0.8325 - recall: 0.8551 - val_loss: 0.4536 - val_precision: 0.8242 - val_recall: 0.8305 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4161 - precision: 0.8356 - recall: 0.8575 - val_loss: 0.4512 - val_precision: 0.8076 - val_recall: 0.8475 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4159 - precision: 0.8351 - recall: 0.8574 - val_loss: 0.4496 - val_precision: 0.8127 - val_recall: 0.8290 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4147 - precision: 0.8318 - recall: 0.8553 - val_loss: 0.4529 - val_precision: 0.8310 - val_recall: 0.8105 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4122 - precision: 0.8350 - recall: 0.8568 - val_loss: 0.4558 - val_precision: 0.8174 - val_recall: 0.8274 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4167 - precision: 0.8308 - recall: 0.8600 - val_loss: 0.4619 - val_precision: 0.8299 - val_recall: 0.8043 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4177 - precision: 0.8360 - recall: 0.8502 - val_loss: 0.4506 - val_precision: 0.8465 - val_recall: 0.8074 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4117 - precision: 0.8377 - recall: 0.8565 - val_loss: 0.4632 - val_precision: 0.8246 - val_recall: 0.8259 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4193 - precision: 0.8314 - recall: 0.8530 - val_loss: 0.4510 - val_precision: 0.8289 - val_recall: 0.8213 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e9291bab490>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12555, 3840, 3)\n",
            "(12555,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 16s 111ms/step - loss: 0.4556 - precision: 0.8134 - recall: 0.8382 - val_loss: 0.4535 - val_precision: 0.8257 - val_recall: 0.8283 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4482 - precision: 0.8158 - recall: 0.8393 - val_loss: 0.4444 - val_precision: 0.8304 - val_recall: 0.8251 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4463 - precision: 0.8177 - recall: 0.8346 - val_loss: 0.4483 - val_precision: 0.8374 - val_recall: 0.8188 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4433 - precision: 0.8187 - recall: 0.8434 - val_loss: 0.4424 - val_precision: 0.8328 - val_recall: 0.8315 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4440 - precision: 0.8161 - recall: 0.8455 - val_loss: 0.4554 - val_precision: 0.8632 - val_recall: 0.7822 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4525 - precision: 0.8169 - recall: 0.8318 - val_loss: 0.4625 - val_precision: 0.8503 - val_recall: 0.7949 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4421 - precision: 0.8213 - recall: 0.8422 - val_loss: 0.4504 - val_precision: 0.8361 - val_recall: 0.7949 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4478 - precision: 0.8139 - recall: 0.8420 - val_loss: 0.4758 - val_precision: 0.8643 - val_recall: 0.7695 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4505 - precision: 0.8153 - recall: 0.8359 - val_loss: 0.4465 - val_precision: 0.8125 - val_recall: 0.8474 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4476 - precision: 0.8104 - recall: 0.8441 - val_loss: 0.4590 - val_precision: 0.8214 - val_recall: 0.8188 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4466 - precision: 0.8112 - recall: 0.8393 - val_loss: 0.4418 - val_precision: 0.8378 - val_recall: 0.8378 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4462 - precision: 0.8127 - recall: 0.8468 - val_loss: 0.4598 - val_precision: 0.8520 - val_recall: 0.7965 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4392 - precision: 0.8214 - recall: 0.8400 - val_loss: 0.4649 - val_precision: 0.7637 - val_recall: 0.8887 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4596 - precision: 0.8008 - recall: 0.8495 - val_loss: 0.4564 - val_precision: 0.8361 - val_recall: 0.8108 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4464 - precision: 0.8188 - recall: 0.8371 - val_loss: 0.4523 - val_precision: 0.8006 - val_recall: 0.8490 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4425 - precision: 0.8186 - recall: 0.8396 - val_loss: 0.4705 - val_precision: 0.7653 - val_recall: 0.8919 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4495 - precision: 0.8142 - recall: 0.8371 - val_loss: 0.4510 - val_precision: 0.8232 - val_recall: 0.8362 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4448 - precision: 0.8164 - recall: 0.8330 - val_loss: 0.4402 - val_precision: 0.8267 - val_recall: 0.8267 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4413 - precision: 0.8152 - recall: 0.8477 - val_loss: 0.4472 - val_precision: 0.8211 - val_recall: 0.8537 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4495 - precision: 0.8164 - recall: 0.8352 - val_loss: 0.4556 - val_precision: 0.8339 - val_recall: 0.8299 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4429 - precision: 0.8185 - recall: 0.8334 - val_loss: 0.4757 - val_precision: 0.8764 - val_recall: 0.7663 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4434 - precision: 0.8209 - recall: 0.8398 - val_loss: 0.4728 - val_precision: 0.8587 - val_recall: 0.7727 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4553 - precision: 0.8155 - recall: 0.8255 - val_loss: 0.4386 - val_precision: 0.8214 - val_recall: 0.8553 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4438 - precision: 0.8184 - recall: 0.8418 - val_loss: 0.4390 - val_precision: 0.8096 - val_recall: 0.8585 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4432 - precision: 0.8155 - recall: 0.8422 - val_loss: 0.4438 - val_precision: 0.8355 - val_recall: 0.8315 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4410 - precision: 0.8206 - recall: 0.8371 - val_loss: 0.4524 - val_precision: 0.8382 - val_recall: 0.8156 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4435 - precision: 0.8185 - recall: 0.8373 - val_loss: 0.4719 - val_precision: 0.8594 - val_recall: 0.7870 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4500 - precision: 0.8160 - recall: 0.8309 - val_loss: 0.4396 - val_precision: 0.8145 - val_recall: 0.8585 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4440 - precision: 0.8165 - recall: 0.8329 - val_loss: 0.4517 - val_precision: 0.8449 - val_recall: 0.8140 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4371 - precision: 0.8208 - recall: 0.8450 - val_loss: 0.4514 - val_precision: 0.8433 - val_recall: 0.8045 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4444 - precision: 0.8132 - recall: 0.8371 - val_loss: 0.4514 - val_precision: 0.8314 - val_recall: 0.8156 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4398 - precision: 0.8163 - recall: 0.8396 - val_loss: 0.4529 - val_precision: 0.8235 - val_recall: 0.8235 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4385 - precision: 0.8215 - recall: 0.8375 - val_loss: 0.4530 - val_precision: 0.8502 - val_recall: 0.8029 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e9291bab490>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13001, 3840, 3)\n",
            "(13001,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 16s 115ms/step - loss: 0.4461 - precision: 0.8169 - recall: 0.8393 - val_loss: 0.4372 - val_precision: 0.8403 - val_recall: 0.8416 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4381 - precision: 0.8206 - recall: 0.8416 - val_loss: 0.4320 - val_precision: 0.8250 - val_recall: 0.8711 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4318 - precision: 0.8198 - recall: 0.8492 - val_loss: 0.4257 - val_precision: 0.8454 - val_recall: 0.8494 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4317 - precision: 0.8214 - recall: 0.8450 - val_loss: 0.4342 - val_precision: 0.8612 - val_recall: 0.8385 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4322 - precision: 0.8216 - recall: 0.8462 - val_loss: 0.4289 - val_precision: 0.8562 - val_recall: 0.8230 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4264 - precision: 0.8273 - recall: 0.8449 - val_loss: 0.4268 - val_precision: 0.8341 - val_recall: 0.8742 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4322 - precision: 0.8208 - recall: 0.8466 - val_loss: 0.4399 - val_precision: 0.8729 - val_recall: 0.7997 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4320 - precision: 0.8210 - recall: 0.8459 - val_loss: 0.4294 - val_precision: 0.8483 - val_recall: 0.8339 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4301 - precision: 0.8245 - recall: 0.8433 - val_loss: 0.4317 - val_precision: 0.8413 - val_recall: 0.8478 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4310 - precision: 0.8205 - recall: 0.8518 - val_loss: 0.4436 - val_precision: 0.8493 - val_recall: 0.8137 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4314 - precision: 0.8237 - recall: 0.8419 - val_loss: 0.4319 - val_precision: 0.8364 - val_recall: 0.8571 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4295 - precision: 0.8207 - recall: 0.8531 - val_loss: 0.4437 - val_precision: 0.8714 - val_recall: 0.7888 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4351 - precision: 0.8252 - recall: 0.8352 - val_loss: 0.4432 - val_precision: 0.8463 - val_recall: 0.8463 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e9291bab490>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training complete\n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "# sig_dict_chat = {\n",
        "#     \"EOG\": [0, 1],\n",
        "#     \"EEG\": [4, 5],\n",
        "#     \"ECG\": [15,16],\n",
        "#     \"Resp\": [9, 10],\n",
        "#     \"SPO2\": [13],\n",
        "#     \"CO2\": [14],\n",
        "# }\n",
        "\n",
        "# channel_list_chat = [\n",
        "#     [\"ECG\", \"SPO2\"]\n",
        "# ]\n",
        "\n",
        "# for ch in channel_list_chat:\n",
        "#     chs = []\n",
        "#     chstr = \"\"\n",
        "#     for name in ch:\n",
        "#         chstr += name\n",
        "#         chs = chs + sig_dict_chat[name]\n",
        "#     print(chstr, chs)\n",
        "#     config = {\n",
        "#         \"data_path\": data_path + 'chat_',\n",
        "#         \"model_path\": model_path,\n",
        "#         \"model_name\": \"model_5dropout_\"+ chstr,\n",
        "#         \"regression\": False,\n",
        "#         \"epochs\": 100,\n",
        "#         \"channels\": chs,\n",
        "#     }\n",
        "#     train(config, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pk-H1DbFQ_w",
        "outputId": "ddab57cd-2021-4e82-dc3f-fe1a69b3ce43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3506, 3840, 3)\n",
            "test starting\n",
            "78/78 [==============================] - 1s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95/95 [==============================] - 2s 9ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 2s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124/124 [==============================] - 2s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 2s 8ms/step\n",
            "=========================================================================== \n",
            "[83.75101050929669, 84.31114040870138, 80.00564812199944, 84.94433198380567, 83.25727324586423] \n",
            "[83.37368845843423, 81.70426065162907, 77.36815156169995, 83.02348336594912, 82.25988700564972] \n",
            "[84.0520748576078, 87.63440860215054, 85.03095104108047, 87.24935732647815, 84.21052631578947] \n",
            "[83.45381526104417, 81.11254851228978, 74.94331065759637, 82.71051320378675, 82.3297692740574] \n",
            "[83.71150729335494, 84.56549935149157, 81.01876675603218, 85.08398094760591, 83.22377822234924] \n",
            "[91.21334810356151, 91.43275570671452, 87.2983014252409, 91.44610828680594, 90.16320290792346] \n",
            "[89.36658219557626, 90.02628470594267, 85.51510273940235, 90.06881690443224, 88.87322465739358] \n",
            "Accuracy: 83.25 -+ 1.719 \n",
            "Precision: 81.55 -+ 2.169 \n",
            "Recall: 85.64 -+ 1.517 \n",
            "Specifity: 80.91 -+ 3.078 \n",
            "F1: 83.52 -+ 1.409 \n",
            "AUROC: 90.31 -+ 1.579 \n",
            "AUPRC: 88.77 -+ 1.687 \n",
            "$ 83.3 \\pm 1.7$& $81.5 \\pm 2.2$& $85.6 \\pm 1.5$& $83.5 \\pm 1.4$& $90.3 \\pm 1.6$& \n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "sig_dict_chat = {\n",
        "    \"EOG\": [0, 1],\n",
        "    \"EEG\": [4, 5],\n",
        "    \"ECG\": [15,16],\n",
        "    \"Resp\": [9, 10],\n",
        "    \"SPO2\": [13],\n",
        "    \"CO2\": [14],\n",
        "}\n",
        "\n",
        "channel_list_chat = [\n",
        "    [\"ECG\", \"SPO2\"],\n",
        "]\n",
        "\n",
        "for ch in channel_list_chat:\n",
        "    chs = []\n",
        "    chstr = \"\"\n",
        "    for name in ch:\n",
        "        chstr += name\n",
        "        chs = chs + sig_dict_chat[name]\n",
        "    print(chstr, chs)\n",
        "    config = {\n",
        "        \"data_path\": data_path + 'chat_',\n",
        "        \"model_path\": model_path,\n",
        "        \"model_name\": \"model_5dropout_\"+ chstr,\n",
        "        \"channels\": chs,\n",
        "    }\n",
        "    test(config, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Discussion of experiment - dropout\n",
        "\n",
        "The table below summarizes the impact on model performance with No dropout as well as twice the dropout rate of 0.5.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=11cBNlp4eMD7JI8BsvAAns35-xIH_xdhT\"/>\n",
        "</div>\n",
        "\n",
        "Interestingly we see that no dropout leads to better performance across almost all metrics. This could be the case as all nodes in the neural network together perform better and still have good generalization power. However, having no dropout means having no regularization technique, and so, could potentially lead to some overfitting.\n"
      ],
      "metadata": {
        "id": "vvwdBPcdn_O-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YSUX7ejG_kW"
      },
      "source": [
        "###Experiment - Learning rate scheduler\n",
        "\n",
        "The initial model made it so that the learning rate decreased by 50% after 50 epochs and additional 50% every 5 epochs after.\n",
        "\n",
        "We want to compare models with no learning rate adjustments and one that starts at 25 epochs instead of 50.\n",
        "\n",
        "**No Learning schedule below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLNrK34JG88j"
      },
      "outputs": [],
      "source": [
        "input_shape = (128 * 30, 3)\n",
        "num_patches = 30\n",
        "\n",
        "transformer_layers = 5\n",
        "num_heads = 4\n",
        "transformer_units = 32\n",
        "reg = False\n",
        "drop_out = 0.25\n",
        "l2_weight = 0.001\n",
        "\n",
        "model = create_transformer_model(input_shape, num_patches,\n",
        "                                projection_dim=transformer_units, transformer_layers=transformer_layers,\n",
        "                                num_heads=num_heads,\n",
        "                                transformer_units = [transformer_units*2, transformer_units],\n",
        "                                mlp_head_units=[256, 128],\n",
        "                                num_classes=1, drop_out=drop_out, reg=reg, l2_weight=l2_weight, demographic=False)\n",
        "loss_func = BinaryCrossentropy()\n",
        "optimizer = \"adam\"\n",
        "\n",
        "#Prevent over-fitting on same fold.\n",
        "def lr_schedule(epoch, lr):\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbBVCiIkI3dX",
        "outputId": "05a12782-0417-4bd8-9b89-328ac7c64523"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "5\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n",
            "(3506, 3840, 3)\n",
            "training\n",
            "(14033, 3840, 3)\n",
            "(14033,)\n",
            "Epoch 1/100\n",
            "25/25 [==============================] - 15s 104ms/step - loss: 1.4596 - precision: 0.6216 - recall: 0.7796 - val_loss: 1.2988 - val_precision: 0.6219 - val_recall: 0.9157 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 1.1813 - precision: 0.6830 - recall: 0.8392 - val_loss: 1.0905 - val_precision: 0.6822 - val_recall: 0.8488 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 1.0008 - precision: 0.7355 - recall: 0.8194 - val_loss: 0.9595 - val_precision: 0.6927 - val_recall: 0.8881 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.8885 - precision: 0.7613 - recall: 0.8047 - val_loss: 0.8587 - val_precision: 0.7255 - val_recall: 0.8605 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.8078 - precision: 0.7743 - recall: 0.8108 - val_loss: 0.7835 - val_precision: 0.8015 - val_recall: 0.7631 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.7571 - precision: 0.7910 - recall: 0.7978 - val_loss: 0.7652 - val_precision: 0.7401 - val_recall: 0.8692 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.7100 - precision: 0.7903 - recall: 0.8128 - val_loss: 0.6897 - val_precision: 0.7808 - val_recall: 0.8387 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.6689 - precision: 0.8036 - recall: 0.8170 - val_loss: 0.6589 - val_precision: 0.7915 - val_recall: 0.8387 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.6454 - precision: 0.8012 - recall: 0.8147 - val_loss: 0.6419 - val_precision: 0.7803 - val_recall: 0.8416 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.6231 - precision: 0.8062 - recall: 0.8176 - val_loss: 0.6283 - val_precision: 0.8209 - val_recall: 0.7660 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.6106 - precision: 0.8067 - recall: 0.8152 - val_loss: 0.6129 - val_precision: 0.7793 - val_recall: 0.8517 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5924 - precision: 0.8084 - recall: 0.8187 - val_loss: 0.5883 - val_precision: 0.8051 - val_recall: 0.8227 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5779 - precision: 0.8145 - recall: 0.8211 - val_loss: 0.5813 - val_precision: 0.7770 - val_recall: 0.8358 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5656 - precision: 0.8135 - recall: 0.8165 - val_loss: 0.5732 - val_precision: 0.8040 - val_recall: 0.8110 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5648 - precision: 0.8047 - recall: 0.8146 - val_loss: 0.5667 - val_precision: 0.8040 - val_recall: 0.8110 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5503 - precision: 0.8138 - recall: 0.8231 - val_loss: 0.5574 - val_precision: 0.7884 - val_recall: 0.8503 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 2s 63ms/step - loss: 0.5471 - precision: 0.8132 - recall: 0.8213 - val_loss: 0.5427 - val_precision: 0.8175 - val_recall: 0.8009 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5443 - precision: 0.8109 - recall: 0.8259 - val_loss: 0.5518 - val_precision: 0.8090 - val_recall: 0.8067 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5412 - precision: 0.8182 - recall: 0.8077 - val_loss: 0.5528 - val_precision: 0.7709 - val_recall: 0.8852 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5267 - precision: 0.8128 - recall: 0.8259 - val_loss: 0.5222 - val_precision: 0.8140 - val_recall: 0.8270 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.5194 - precision: 0.8188 - recall: 0.8275 - val_loss: 0.5392 - val_precision: 0.7663 - val_recall: 0.8866 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5191 - precision: 0.8164 - recall: 0.8266 - val_loss: 0.5128 - val_precision: 0.8091 - val_recall: 0.8256 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5091 - precision: 0.8214 - recall: 0.8277 - val_loss: 0.5305 - val_precision: 0.7901 - val_recall: 0.8314 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5090 - precision: 0.8154 - recall: 0.8343 - val_loss: 0.5107 - val_precision: 0.8274 - val_recall: 0.8081 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5062 - precision: 0.8205 - recall: 0.8224 - val_loss: 0.5174 - val_precision: 0.7891 - val_recall: 0.8590 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5053 - precision: 0.8142 - recall: 0.8319 - val_loss: 0.5079 - val_precision: 0.8207 - val_recall: 0.8183 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4957 - precision: 0.8193 - recall: 0.8275 - val_loss: 0.4991 - val_precision: 0.7949 - val_recall: 0.8561 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4954 - precision: 0.8182 - recall: 0.8365 - val_loss: 0.4952 - val_precision: 0.8144 - val_recall: 0.8358 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4891 - precision: 0.8230 - recall: 0.8307 - val_loss: 0.4954 - val_precision: 0.8081 - val_recall: 0.8387 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4877 - precision: 0.8260 - recall: 0.8333 - val_loss: 0.4992 - val_precision: 0.7801 - val_recall: 0.8663 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4877 - precision: 0.8223 - recall: 0.8341 - val_loss: 0.4811 - val_precision: 0.8324 - val_recall: 0.8227 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4870 - precision: 0.8220 - recall: 0.8274 - val_loss: 0.4893 - val_precision: 0.8245 - val_recall: 0.8125 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4792 - precision: 0.8245 - recall: 0.8383 - val_loss: 0.4848 - val_precision: 0.8218 - val_recall: 0.8314 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4799 - precision: 0.8257 - recall: 0.8322 - val_loss: 0.4846 - val_precision: 0.8061 - val_recall: 0.8517 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4776 - precision: 0.8298 - recall: 0.8330 - val_loss: 0.5022 - val_precision: 0.7632 - val_recall: 0.8808 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4808 - precision: 0.8186 - recall: 0.8368 - val_loss: 0.4947 - val_precision: 0.7994 - val_recall: 0.8110 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4847 - precision: 0.8233 - recall: 0.8178 - val_loss: 0.4827 - val_precision: 0.8251 - val_recall: 0.8299 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4796 - precision: 0.8214 - recall: 0.8304 - val_loss: 0.4898 - val_precision: 0.7944 - val_recall: 0.8590 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4752 - precision: 0.8256 - recall: 0.8317 - val_loss: 0.4721 - val_precision: 0.8251 - val_recall: 0.8299 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4669 - precision: 0.8296 - recall: 0.8397 - val_loss: 0.4721 - val_precision: 0.8190 - val_recall: 0.8285 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4655 - precision: 0.8281 - recall: 0.8349 - val_loss: 0.4895 - val_precision: 0.7738 - val_recall: 0.8852 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4704 - precision: 0.8214 - recall: 0.8338 - val_loss: 0.4709 - val_precision: 0.8328 - val_recall: 0.8183 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4663 - precision: 0.8312 - recall: 0.8339 - val_loss: 0.4817 - val_precision: 0.8191 - val_recall: 0.8358 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4635 - precision: 0.8267 - recall: 0.8389 - val_loss: 0.4662 - val_precision: 0.8245 - val_recall: 0.8328 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4661 - precision: 0.8280 - recall: 0.8325 - val_loss: 0.4889 - val_precision: 0.7817 - val_recall: 0.8590 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4674 - precision: 0.8269 - recall: 0.8378 - val_loss: 0.4617 - val_precision: 0.8311 - val_recall: 0.8299 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4597 - precision: 0.8295 - recall: 0.8336 - val_loss: 0.4688 - val_precision: 0.8187 - val_recall: 0.8401 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4623 - precision: 0.8201 - recall: 0.8408 - val_loss: 0.4748 - val_precision: 0.8402 - val_recall: 0.8023 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4663 - precision: 0.8297 - recall: 0.8338 - val_loss: 0.4704 - val_precision: 0.8083 - val_recall: 0.8517 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4581 - precision: 0.8287 - recall: 0.8387 - val_loss: 0.4901 - val_precision: 0.7761 - val_recall: 0.8866 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4570 - precision: 0.8261 - recall: 0.8413 - val_loss: 0.4700 - val_precision: 0.8273 - val_recall: 0.8285 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4532 - precision: 0.8322 - recall: 0.8427 - val_loss: 0.4649 - val_precision: 0.8226 - val_recall: 0.8358 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4558 - precision: 0.8248 - recall: 0.8352 - val_loss: 0.4642 - val_precision: 0.8200 - val_recall: 0.8343 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4562 - precision: 0.8294 - recall: 0.8355 - val_loss: 0.4637 - val_precision: 0.8280 - val_recall: 0.8328 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4581 - precision: 0.8271 - recall: 0.8339 - val_loss: 0.4680 - val_precision: 0.8196 - val_recall: 0.8256 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4581 - precision: 0.8242 - recall: 0.8365 - val_loss: 0.4732 - val_precision: 0.7931 - val_recall: 0.8634 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e9292062fb0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13473, 3840, 3)\n",
            "(13473,)\n",
            "Epoch 1/100\n",
            "24/24 [==============================] - 16s 111ms/step - loss: 0.4803 - precision: 0.8209 - recall: 0.8297 - val_loss: 0.4763 - val_precision: 0.8118 - val_recall: 0.8600 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4702 - precision: 0.8189 - recall: 0.8391 - val_loss: 0.4665 - val_precision: 0.8200 - val_recall: 0.8250 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4745 - precision: 0.8164 - recall: 0.8326 - val_loss: 0.4762 - val_precision: 0.8372 - val_recall: 0.8143 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4643 - precision: 0.8244 - recall: 0.8348 - val_loss: 0.4795 - val_precision: 0.7954 - val_recall: 0.8463 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4647 - precision: 0.8196 - recall: 0.8390 - val_loss: 0.4623 - val_precision: 0.8090 - val_recall: 0.8447 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4615 - precision: 0.8269 - recall: 0.8345 - val_loss: 0.4724 - val_precision: 0.7906 - val_recall: 0.8676 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4590 - precision: 0.8217 - recall: 0.8381 - val_loss: 0.4609 - val_precision: 0.8090 - val_recall: 0.8508 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4558 - precision: 0.8280 - recall: 0.8346 - val_loss: 0.4632 - val_precision: 0.7901 - val_recall: 0.8767 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4642 - precision: 0.8209 - recall: 0.8356 - val_loss: 0.4648 - val_precision: 0.8254 - val_recall: 0.8204 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4590 - precision: 0.8256 - recall: 0.8325 - val_loss: 0.4788 - val_precision: 0.7989 - val_recall: 0.8584 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4592 - precision: 0.8215 - recall: 0.8383 - val_loss: 0.4619 - val_precision: 0.8198 - val_recall: 0.8311 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4577 - precision: 0.8246 - recall: 0.8416 - val_loss: 0.4611 - val_precision: 0.8176 - val_recall: 0.8463 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4568 - precision: 0.8214 - recall: 0.8414 - val_loss: 0.4596 - val_precision: 0.8187 - val_recall: 0.8387 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4555 - precision: 0.8286 - recall: 0.8355 - val_loss: 0.4837 - val_precision: 0.7805 - val_recall: 0.8767 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4561 - precision: 0.8216 - recall: 0.8363 - val_loss: 0.4584 - val_precision: 0.8240 - val_recall: 0.8265 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4504 - precision: 0.8251 - recall: 0.8386 - val_loss: 0.4571 - val_precision: 0.8147 - val_recall: 0.8630 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4574 - precision: 0.8234 - recall: 0.8398 - val_loss: 0.4602 - val_precision: 0.8023 - val_recall: 0.8463 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4495 - precision: 0.8300 - recall: 0.8366 - val_loss: 0.4558 - val_precision: 0.8519 - val_recall: 0.8052 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4514 - precision: 0.8259 - recall: 0.8343 - val_loss: 0.4531 - val_precision: 0.8121 - val_recall: 0.8554 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4539 - precision: 0.8237 - recall: 0.8376 - val_loss: 0.4674 - val_precision: 0.7846 - val_recall: 0.8813 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4590 - precision: 0.8211 - recall: 0.8328 - val_loss: 0.4637 - val_precision: 0.7947 - val_recall: 0.8600 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4565 - precision: 0.8210 - recall: 0.8360 - val_loss: 0.4596 - val_precision: 0.8346 - val_recall: 0.8067 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4515 - precision: 0.8294 - recall: 0.8413 - val_loss: 0.4614 - val_precision: 0.8180 - val_recall: 0.8417 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4511 - precision: 0.8267 - recall: 0.8429 - val_loss: 0.4642 - val_precision: 0.8183 - val_recall: 0.8158 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4469 - precision: 0.8287 - recall: 0.8399 - val_loss: 0.4483 - val_precision: 0.8424 - val_recall: 0.8219 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4487 - precision: 0.8269 - recall: 0.8391 - val_loss: 0.4518 - val_precision: 0.8127 - val_recall: 0.8387 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4447 - precision: 0.8253 - recall: 0.8393 - val_loss: 0.4653 - val_precision: 0.7997 - val_recall: 0.8508 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4449 - precision: 0.8266 - recall: 0.8436 - val_loss: 0.4536 - val_precision: 0.8152 - val_recall: 0.8463 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4440 - precision: 0.8278 - recall: 0.8404 - val_loss: 0.4662 - val_precision: 0.7836 - val_recall: 0.8874 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4442 - precision: 0.8283 - recall: 0.8408 - val_loss: 0.4506 - val_precision: 0.8043 - val_recall: 0.8630 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4434 - precision: 0.8229 - recall: 0.8426 - val_loss: 0.4592 - val_precision: 0.8214 - val_recall: 0.8539 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4499 - precision: 0.8229 - recall: 0.8376 - val_loss: 0.4511 - val_precision: 0.8185 - val_recall: 0.8371 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4402 - precision: 0.8330 - recall: 0.8399 - val_loss: 0.4576 - val_precision: 0.7961 - val_recall: 0.8676 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4468 - precision: 0.8228 - recall: 0.8381 - val_loss: 0.4565 - val_precision: 0.8351 - val_recall: 0.8174 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.4480 - precision: 0.8262 - recall: 0.8424 - val_loss: 0.4503 - val_precision: 0.8267 - val_recall: 0.8280 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e9292062fb0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12966, 3840, 3)\n",
            "(12966,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 16s 110ms/step - loss: 0.4478 - precision: 0.8297 - recall: 0.8372 - val_loss: 0.4665 - val_precision: 0.8107 - val_recall: 0.8415 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4340 - precision: 0.8358 - recall: 0.8411 - val_loss: 0.4784 - val_precision: 0.7630 - val_recall: 0.8827 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4304 - precision: 0.8402 - recall: 0.8486 - val_loss: 0.4513 - val_precision: 0.8320 - val_recall: 0.8320 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4227 - precision: 0.8419 - recall: 0.8542 - val_loss: 0.4697 - val_precision: 0.7959 - val_recall: 0.8526 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4201 - precision: 0.8406 - recall: 0.8562 - val_loss: 0.4625 - val_precision: 0.8246 - val_recall: 0.8273 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4249 - precision: 0.8358 - recall: 0.8510 - val_loss: 0.4567 - val_precision: 0.8130 - val_recall: 0.8336 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4221 - precision: 0.8428 - recall: 0.8497 - val_loss: 0.4486 - val_precision: 0.8237 - val_recall: 0.8368 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4243 - precision: 0.8380 - recall: 0.8531 - val_loss: 0.4550 - val_precision: 0.8157 - val_recall: 0.8415 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4236 - precision: 0.8324 - recall: 0.8569 - val_loss: 0.4675 - val_precision: 0.8219 - val_recall: 0.8193 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4235 - precision: 0.8451 - recall: 0.8418 - val_loss: 0.4696 - val_precision: 0.7939 - val_recall: 0.8669 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4169 - precision: 0.8418 - recall: 0.8575 - val_loss: 0.4488 - val_precision: 0.8352 - val_recall: 0.8273 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4223 - precision: 0.8428 - recall: 0.8500 - val_loss: 0.4579 - val_precision: 0.8110 - val_recall: 0.8431 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4208 - precision: 0.8449 - recall: 0.8486 - val_loss: 0.4603 - val_precision: 0.8169 - val_recall: 0.8415 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4176 - precision: 0.8431 - recall: 0.8561 - val_loss: 0.4541 - val_precision: 0.8203 - val_recall: 0.8463 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4208 - precision: 0.8430 - recall: 0.8465 - val_loss: 0.4665 - val_precision: 0.7755 - val_recall: 0.8811 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4197 - precision: 0.8406 - recall: 0.8514 - val_loss: 0.4556 - val_precision: 0.8060 - val_recall: 0.8494 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4194 - precision: 0.8418 - recall: 0.8601 - val_loss: 0.4599 - val_precision: 0.8192 - val_recall: 0.8257 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e9292062fb0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12555, 3840, 3)\n",
            "(12555,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 17s 115ms/step - loss: 0.4717 - precision: 0.8061 - recall: 0.8236 - val_loss: 0.4677 - val_precision: 0.7922 - val_recall: 0.8623 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4500 - precision: 0.8237 - recall: 0.8368 - val_loss: 0.4629 - val_precision: 0.8271 - val_recall: 0.8311 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4525 - precision: 0.8257 - recall: 0.8286 - val_loss: 0.4601 - val_precision: 0.7924 - val_recall: 0.8574 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4539 - precision: 0.8273 - recall: 0.8290 - val_loss: 0.4672 - val_precision: 0.7796 - val_recall: 0.8639 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4586 - precision: 0.8128 - recall: 0.8345 - val_loss: 0.4786 - val_precision: 0.8281 - val_recall: 0.8213 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4554 - precision: 0.8245 - recall: 0.8243 - val_loss: 0.4611 - val_precision: 0.7807 - val_recall: 0.8754 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.4456 - precision: 0.8240 - recall: 0.8375 - val_loss: 0.4481 - val_precision: 0.8215 - val_recall: 0.8377 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4466 - precision: 0.8234 - recall: 0.8397 - val_loss: 0.4513 - val_precision: 0.8079 - val_recall: 0.8410 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4466 - precision: 0.8257 - recall: 0.8382 - val_loss: 0.4609 - val_precision: 0.8250 - val_recall: 0.8115 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4496 - precision: 0.8248 - recall: 0.8340 - val_loss: 0.4642 - val_precision: 0.8317 - val_recall: 0.8180 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4478 - precision: 0.8272 - recall: 0.8347 - val_loss: 0.4512 - val_precision: 0.8125 - val_recall: 0.8525 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4453 - precision: 0.8246 - recall: 0.8291 - val_loss: 0.4774 - val_precision: 0.8333 - val_recall: 0.7951 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4564 - precision: 0.8221 - recall: 0.8190 - val_loss: 0.4652 - val_precision: 0.7708 - val_recall: 0.8820 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4478 - precision: 0.8271 - recall: 0.8318 - val_loss: 0.4684 - val_precision: 0.7837 - val_recall: 0.8672 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4482 - precision: 0.8163 - recall: 0.8418 - val_loss: 0.4611 - val_precision: 0.7884 - val_recall: 0.8672 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4428 - precision: 0.8219 - recall: 0.8379 - val_loss: 0.4607 - val_precision: 0.8068 - val_recall: 0.8557 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4464 - precision: 0.8235 - recall: 0.8268 - val_loss: 0.4608 - val_precision: 0.7899 - val_recall: 0.8689 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e9292062fb0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13001, 3840, 3)\n",
            "(13001,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 18s 114ms/step - loss: 0.4546 - precision: 0.8177 - recall: 0.8335 - val_loss: 0.4101 - val_precision: 0.8464 - val_recall: 0.8718 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4388 - precision: 0.8281 - recall: 0.8467 - val_loss: 0.4140 - val_precision: 0.8604 - val_recall: 0.8481 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4406 - precision: 0.8248 - recall: 0.8423 - val_loss: 0.4088 - val_precision: 0.8585 - val_recall: 0.8449 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4417 - precision: 0.8257 - recall: 0.8435 - val_loss: 0.4156 - val_precision: 0.8686 - val_recall: 0.8259 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4383 - precision: 0.8305 - recall: 0.8460 - val_loss: 0.4114 - val_precision: 0.8595 - val_recall: 0.8418 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4359 - precision: 0.8302 - recall: 0.8478 - val_loss: 0.4024 - val_precision: 0.8525 - val_recall: 0.8687 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4400 - precision: 0.8297 - recall: 0.8412 - val_loss: 0.4230 - val_precision: 0.8103 - val_recall: 0.8924 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4406 - precision: 0.8241 - recall: 0.8536 - val_loss: 0.4167 - val_precision: 0.8678 - val_recall: 0.8307 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4442 - precision: 0.8270 - recall: 0.8440 - val_loss: 0.4147 - val_precision: 0.8659 - val_recall: 0.8275 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4402 - precision: 0.8263 - recall: 0.8438 - val_loss: 0.4106 - val_precision: 0.8464 - val_recall: 0.8718 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4379 - precision: 0.8257 - recall: 0.8445 - val_loss: 0.4084 - val_precision: 0.8479 - val_recall: 0.8734 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4363 - precision: 0.8278 - recall: 0.8411 - val_loss: 0.4080 - val_precision: 0.8562 - val_recall: 0.8386 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4414 - precision: 0.8248 - recall: 0.8447 - val_loss: 0.4075 - val_precision: 0.8508 - val_recall: 0.8481 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4382 - precision: 0.8252 - recall: 0.8479 - val_loss: 0.4176 - val_precision: 0.8576 - val_recall: 0.8481 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4381 - precision: 0.8272 - recall: 0.8416 - val_loss: 0.4085 - val_precision: 0.8556 - val_recall: 0.8528 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4350 - precision: 0.8276 - recall: 0.8455 - val_loss: 0.4104 - val_precision: 0.8498 - val_recall: 0.8592 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e9292062fb0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training complete\n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "# sig_dict_chat = {\n",
        "#     \"EOG\": [0, 1],\n",
        "#     \"EEG\": [4, 5],\n",
        "#     \"ECG\": [15,16],\n",
        "#     \"Resp\": [9, 10],\n",
        "#     \"SPO2\": [13],\n",
        "#     \"CO2\": [14],\n",
        "# }\n",
        "\n",
        "# channel_list_chat = [\n",
        "#     [\"ECG\", \"SPO2\"]\n",
        "# ]\n",
        "\n",
        "# for ch in channel_list_chat:\n",
        "#     chs = []\n",
        "#     chstr = \"\"\n",
        "#     for name in ch:\n",
        "#         chstr += name\n",
        "#         chs = chs + sig_dict_chat[name]\n",
        "#     print(chstr, chs)\n",
        "#     config = {\n",
        "#         \"data_path\": data_path + 'chat_',\n",
        "#         \"model_path\": model_path,\n",
        "#         \"model_name\": \"model_0lrs_\"+ chstr,\n",
        "#         \"regression\": False,\n",
        "#         \"epochs\": 100,\n",
        "#         \"channels\": chs,\n",
        "#     }\n",
        "#     train(config, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgpOkpxtI7f2",
        "outputId": "74de1ff9-7d81-4dce-d4af-7607dc7fed22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3506, 3840, 3)\n",
            "test starting\n",
            "78/78 [==============================] - 1s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95/95 [==============================] - 1s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 2s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124/124 [==============================] - 2s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 2s 8ms/step\n",
            "=========================================================================== \n",
            "[82.90218270008084, 84.14634146341463, 80.4010166619599, 85.60222672064778, 82.82943525385055] \n",
            "[84.44444444444444, 87.43494423791822, 79.28610059491618, 85.39094650205762, 80.64165307232192] \n",
            "[80.39056143205858, 79.03225806451613, 82.49859313449635, 85.34704370179949, 85.77212261422787] \n",
            "[85.38152610441767, 89.06856403622251, 78.28798185941042, 85.84952665670154, 79.96623522791221] \n",
            "[82.36765318882868, 83.02153194493471, 80.86045228902373, 85.36898945744407, 83.12780269058297] \n",
            "[91.03473291048655, 91.69440039505348, 87.90791124178054, 91.98417364417341, 90.25612600828073] \n",
            "[89.49346610240492, 90.78534714965475, 87.28368343781358, 90.62761158007426, 89.04605145336507] \n",
            "Accuracy: 83.18 -+ 1.716 \n",
            "Precision: 83.44 -+ 3.029 \n",
            "Recall: 82.61 -+ 2.654 \n",
            "Specifity: 83.71 -+ 3.987 \n",
            "F1: 82.95 -+ 1.456 \n",
            "AUROC: 90.58 -+ 1.460 \n",
            "AUPRC: 89.45 -+ 1.267 \n",
            "$ 83.2 \\pm 1.7$& $83.4 \\pm 3.0$& $82.6 \\pm 2.7$& $82.9 \\pm 1.5$& $90.6 \\pm 1.5$& \n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "sig_dict_chat = {\n",
        "    \"EOG\": [0, 1],\n",
        "    \"EEG\": [4, 5],\n",
        "    \"ECG\": [15,16],\n",
        "    \"Resp\": [9, 10],\n",
        "    \"SPO2\": [13],\n",
        "    \"CO2\": [14],\n",
        "}\n",
        "\n",
        "channel_list_chat = [\n",
        "    [\"ECG\", \"SPO2\"],\n",
        "]\n",
        "\n",
        "for ch in channel_list_chat:\n",
        "    chs = []\n",
        "    chstr = \"\"\n",
        "    for name in ch:\n",
        "        chstr += name\n",
        "        chs = chs + sig_dict_chat[name]\n",
        "    print(chstr, chs)\n",
        "    config = {\n",
        "        \"data_path\": data_path + 'chat_',\n",
        "        \"model_path\": model_path,\n",
        "        \"model_name\": \"model_0lrs_\"+ chstr,\n",
        "        \"channels\": chs,\n",
        "    }\n",
        "    test(config, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClYg1f5VMTNQ"
      },
      "source": [
        "**Learning rate schedule starting at 25 epochs.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_NMSXBTQqOc"
      },
      "outputs": [],
      "source": [
        "input_shape = (128 * 30, 3)\n",
        "num_patches = 30\n",
        "\n",
        "transformer_layers = 5\n",
        "num_heads = 4\n",
        "transformer_units = 32\n",
        "reg = False\n",
        "drop_out = 0.25\n",
        "l2_weight = 0.001\n",
        "\n",
        "model = create_transformer_model(input_shape, num_patches,\n",
        "                                projection_dim=transformer_units, transformer_layers=transformer_layers,\n",
        "                                num_heads=num_heads,\n",
        "                                transformer_units = [transformer_units*2, transformer_units],\n",
        "                                mlp_head_units=[256, 128],\n",
        "                                num_classes=1, drop_out=drop_out, reg=reg, l2_weight=l2_weight, demographic=False)\n",
        "loss_func = BinaryCrossentropy()\n",
        "optimizer = \"adam\"\n",
        "\n",
        "#Prevent over-fitting on same fold.\n",
        "def lr_schedule(epoch, lr):\n",
        "\n",
        "    if epoch > 25 and (epoch - 1) % 5 == 0:\n",
        "        lr *= 0.5\n",
        "\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHF7ZNTCQ2X6",
        "outputId": "ef342eef-6a4d-49bd-fe8c-dc0a86fb4309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "5\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n",
            "(3506, 3840, 3)\n",
            "training\n",
            "(14033, 3840, 3)\n",
            "(14033,)\n",
            "Epoch 1/100\n",
            "25/25 [==============================] - 16s 109ms/step - loss: 1.4614 - precision: 0.6175 - recall: 0.8002 - val_loss: 1.2957 - val_precision: 0.6404 - val_recall: 0.8746 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 1.1777 - precision: 0.6834 - recall: 0.8459 - val_loss: 1.0733 - val_precision: 0.7190 - val_recall: 0.7965 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.9962 - precision: 0.7426 - recall: 0.8147 - val_loss: 0.9398 - val_precision: 0.7274 - val_recall: 0.8304 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.8805 - precision: 0.7700 - recall: 0.8051 - val_loss: 0.8433 - val_precision: 0.7719 - val_recall: 0.7684 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.8082 - precision: 0.7760 - recall: 0.8008 - val_loss: 0.7964 - val_precision: 0.7352 - val_recall: 0.8599 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.7504 - precision: 0.7875 - recall: 0.8098 - val_loss: 0.7339 - val_precision: 0.7723 - val_recall: 0.8053 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.7015 - precision: 0.7968 - recall: 0.8166 - val_loss: 0.6998 - val_precision: 0.8042 - val_recall: 0.7817 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.6753 - precision: 0.7987 - recall: 0.8146 - val_loss: 0.6916 - val_precision: 0.7776 - val_recall: 0.7994 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.6500 - precision: 0.8021 - recall: 0.8200 - val_loss: 0.6620 - val_precision: 0.7873 - val_recall: 0.7861 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.6247 - precision: 0.8060 - recall: 0.8190 - val_loss: 0.6333 - val_precision: 0.7854 - val_recall: 0.8097 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.6051 - precision: 0.8061 - recall: 0.8285 - val_loss: 0.6266 - val_precision: 0.8000 - val_recall: 0.7906 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5915 - precision: 0.8058 - recall: 0.8325 - val_loss: 0.6054 - val_precision: 0.8101 - val_recall: 0.7802 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5831 - precision: 0.8075 - recall: 0.8216 - val_loss: 0.6001 - val_precision: 0.7848 - val_recall: 0.8392 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5647 - precision: 0.8147 - recall: 0.8396 - val_loss: 0.5838 - val_precision: 0.8038 - val_recall: 0.8038 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5566 - precision: 0.8109 - recall: 0.8305 - val_loss: 0.5681 - val_precision: 0.7997 - val_recall: 0.8186 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5473 - precision: 0.8147 - recall: 0.8379 - val_loss: 0.5824 - val_precision: 0.8245 - val_recall: 0.7552 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5384 - precision: 0.8153 - recall: 0.8333 - val_loss: 0.5528 - val_precision: 0.7977 - val_recall: 0.8319 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5327 - precision: 0.8171 - recall: 0.8325 - val_loss: 0.5509 - val_precision: 0.7855 - val_recall: 0.8643 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5328 - precision: 0.8082 - recall: 0.8420 - val_loss: 0.5554 - val_precision: 0.8092 - val_recall: 0.7817 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.5211 - precision: 0.8163 - recall: 0.8376 - val_loss: 0.5391 - val_precision: 0.7989 - val_recall: 0.8201 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5176 - precision: 0.8138 - recall: 0.8358 - val_loss: 0.5456 - val_precision: 0.8218 - val_recall: 0.7552 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.5149 - precision: 0.8172 - recall: 0.8382 - val_loss: 0.5488 - val_precision: 0.8122 - val_recall: 0.7847 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5105 - precision: 0.8193 - recall: 0.8347 - val_loss: 0.5266 - val_precision: 0.8020 - val_recall: 0.8186 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.5052 - precision: 0.8193 - recall: 0.8387 - val_loss: 0.5180 - val_precision: 0.7978 - val_recall: 0.8555 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4990 - precision: 0.8155 - recall: 0.8401 - val_loss: 0.5398 - val_precision: 0.8091 - val_recall: 0.8127 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4985 - precision: 0.8198 - recall: 0.8380 - val_loss: 0.5294 - val_precision: 0.8234 - val_recall: 0.7773 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4922 - precision: 0.8215 - recall: 0.8388 - val_loss: 0.5077 - val_precision: 0.8043 - val_recall: 0.8363 - lr: 5.0000e-04\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4858 - precision: 0.8266 - recall: 0.8430 - val_loss: 0.5085 - val_precision: 0.7905 - val_recall: 0.8628 - lr: 5.0000e-04\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4839 - precision: 0.8245 - recall: 0.8473 - val_loss: 0.5098 - val_precision: 0.8204 - val_recall: 0.7950 - lr: 5.0000e-04\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.4837 - precision: 0.8202 - recall: 0.8460 - val_loss: 0.5029 - val_precision: 0.8262 - val_recall: 0.7994 - lr: 5.0000e-04\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4818 - precision: 0.8268 - recall: 0.8468 - val_loss: 0.5043 - val_precision: 0.8034 - val_recall: 0.8378 - lr: 5.0000e-04\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4773 - precision: 0.8264 - recall: 0.8425 - val_loss: 0.4997 - val_precision: 0.8039 - val_recall: 0.8407 - lr: 2.5000e-04\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4740 - precision: 0.8275 - recall: 0.8479 - val_loss: 0.5001 - val_precision: 0.8075 - val_recall: 0.8289 - lr: 2.5000e-04\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4705 - precision: 0.8299 - recall: 0.8487 - val_loss: 0.5014 - val_precision: 0.8081 - val_recall: 0.8260 - lr: 2.5000e-04\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4734 - precision: 0.8282 - recall: 0.8516 - val_loss: 0.4985 - val_precision: 0.8112 - val_recall: 0.8363 - lr: 2.5000e-04\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4722 - precision: 0.8284 - recall: 0.8497 - val_loss: 0.4969 - val_precision: 0.8130 - val_recall: 0.8274 - lr: 2.5000e-04\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4718 - precision: 0.8280 - recall: 0.8491 - val_loss: 0.4986 - val_precision: 0.8037 - val_recall: 0.8333 - lr: 1.2500e-04\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4667 - precision: 0.8305 - recall: 0.8523 - val_loss: 0.4977 - val_precision: 0.8065 - val_recall: 0.8363 - lr: 1.2500e-04\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4692 - precision: 0.8323 - recall: 0.8444 - val_loss: 0.4955 - val_precision: 0.8063 - val_recall: 0.8348 - lr: 1.2500e-04\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4682 - precision: 0.8314 - recall: 0.8511 - val_loss: 0.4950 - val_precision: 0.7989 - val_recall: 0.8496 - lr: 1.2500e-04\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4671 - precision: 0.8289 - recall: 0.8507 - val_loss: 0.4956 - val_precision: 0.8104 - val_recall: 0.8260 - lr: 1.2500e-04\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4680 - precision: 0.8315 - recall: 0.8503 - val_loss: 0.4932 - val_precision: 0.8065 - val_recall: 0.8363 - lr: 6.2500e-05\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4657 - precision: 0.8296 - recall: 0.8529 - val_loss: 0.4941 - val_precision: 0.8089 - val_recall: 0.8304 - lr: 6.2500e-05\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4636 - precision: 0.8315 - recall: 0.8543 - val_loss: 0.4954 - val_precision: 0.8065 - val_recall: 0.8363 - lr: 6.2500e-05\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4658 - precision: 0.8293 - recall: 0.8553 - val_loss: 0.4952 - val_precision: 0.8069 - val_recall: 0.8319 - lr: 6.2500e-05\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4625 - precision: 0.8320 - recall: 0.8510 - val_loss: 0.4944 - val_precision: 0.8054 - val_recall: 0.8363 - lr: 6.2500e-05\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4634 - precision: 0.8307 - recall: 0.8508 - val_loss: 0.4936 - val_precision: 0.8048 - val_recall: 0.8333 - lr: 3.1250e-05\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4631 - precision: 0.8337 - recall: 0.8518 - val_loss: 0.4940 - val_precision: 0.8074 - val_recall: 0.8348 - lr: 3.1250e-05\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4640 - precision: 0.8320 - recall: 0.8494 - val_loss: 0.4932 - val_precision: 0.8054 - val_recall: 0.8363 - lr: 3.1250e-05\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4633 - precision: 0.8308 - recall: 0.8543 - val_loss: 0.4940 - val_precision: 0.8121 - val_recall: 0.8289 - lr: 3.1250e-05\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4626 - precision: 0.8338 - recall: 0.8494 - val_loss: 0.4927 - val_precision: 0.8048 - val_recall: 0.8333 - lr: 3.1250e-05\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4626 - precision: 0.8324 - recall: 0.8499 - val_loss: 0.4934 - val_precision: 0.8080 - val_recall: 0.8319 - lr: 1.5625e-05\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4622 - precision: 0.8327 - recall: 0.8483 - val_loss: 0.4934 - val_precision: 0.8057 - val_recall: 0.8319 - lr: 1.5625e-05\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4612 - precision: 0.8281 - recall: 0.8527 - val_loss: 0.4943 - val_precision: 0.8119 - val_recall: 0.8274 - lr: 1.5625e-05\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4618 - precision: 0.8305 - recall: 0.8529 - val_loss: 0.4943 - val_precision: 0.8116 - val_recall: 0.8260 - lr: 1.5625e-05\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4626 - precision: 0.8328 - recall: 0.8467 - val_loss: 0.4935 - val_precision: 0.8057 - val_recall: 0.8319 - lr: 1.5625e-05\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4609 - precision: 0.8364 - recall: 0.8547 - val_loss: 0.4935 - val_precision: 0.8069 - val_recall: 0.8319 - lr: 7.8125e-06\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4625 - precision: 0.8293 - recall: 0.8561 - val_loss: 0.4937 - val_precision: 0.8069 - val_recall: 0.8319 - lr: 7.8125e-06\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4619 - precision: 0.8322 - recall: 0.8481 - val_loss: 0.4936 - val_precision: 0.8057 - val_recall: 0.8319 - lr: 7.8125e-06\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4607 - precision: 0.8303 - recall: 0.8542 - val_loss: 0.4936 - val_precision: 0.8057 - val_recall: 0.8319 - lr: 7.8125e-06\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4618 - precision: 0.8348 - recall: 0.8489 - val_loss: 0.4936 - val_precision: 0.8057 - val_recall: 0.8319 - lr: 7.8125e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e928458fd00>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13473, 3840, 3)\n",
            "(13473,)\n",
            "Epoch 1/100\n",
            "24/24 [==============================] - 18s 115ms/step - loss: 0.5046 - precision: 0.8066 - recall: 0.8244 - val_loss: 0.5042 - val_precision: 0.8161 - val_recall: 0.8123 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4869 - precision: 0.8187 - recall: 0.8340 - val_loss: 0.4999 - val_precision: 0.7988 - val_recall: 0.8308 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4796 - precision: 0.8180 - recall: 0.8423 - val_loss: 0.4879 - val_precision: 0.7938 - val_recall: 0.8646 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4762 - precision: 0.8179 - recall: 0.8423 - val_loss: 0.4921 - val_precision: 0.7836 - val_recall: 0.8800 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4736 - precision: 0.8196 - recall: 0.8469 - val_loss: 0.4926 - val_precision: 0.8214 - val_recall: 0.7923 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4730 - precision: 0.8244 - recall: 0.8383 - val_loss: 0.4916 - val_precision: 0.8210 - val_recall: 0.8185 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4817 - precision: 0.8189 - recall: 0.8294 - val_loss: 0.4914 - val_precision: 0.7913 - val_recall: 0.8631 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4827 - precision: 0.8104 - recall: 0.8385 - val_loss: 0.4988 - val_precision: 0.7738 - val_recall: 0.8892 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4688 - precision: 0.8151 - recall: 0.8466 - val_loss: 0.4747 - val_precision: 0.8097 - val_recall: 0.8446 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.4684 - precision: 0.8208 - recall: 0.8439 - val_loss: 0.4742 - val_precision: 0.8011 - val_recall: 0.8677 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4642 - precision: 0.8206 - recall: 0.8433 - val_loss: 0.4976 - val_precision: 0.8237 - val_recall: 0.7908 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4651 - precision: 0.8175 - recall: 0.8463 - val_loss: 0.4788 - val_precision: 0.8144 - val_recall: 0.8031 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4671 - precision: 0.8194 - recall: 0.8425 - val_loss: 0.4783 - val_precision: 0.8018 - val_recall: 0.8400 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4641 - precision: 0.8218 - recall: 0.8403 - val_loss: 0.4718 - val_precision: 0.8026 - val_recall: 0.8631 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4567 - precision: 0.8239 - recall: 0.8431 - val_loss: 0.4731 - val_precision: 0.8092 - val_recall: 0.8354 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.4610 - precision: 0.8219 - recall: 0.8425 - val_loss: 0.4698 - val_precision: 0.8152 - val_recall: 0.8277 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4546 - precision: 0.8241 - recall: 0.8486 - val_loss: 0.4700 - val_precision: 0.8103 - val_recall: 0.8477 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4551 - precision: 0.8231 - recall: 0.8441 - val_loss: 0.4831 - val_precision: 0.8317 - val_recall: 0.7908 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.4622 - precision: 0.8211 - recall: 0.8371 - val_loss: 0.4682 - val_precision: 0.7994 - val_recall: 0.8585 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4535 - precision: 0.8238 - recall: 0.8451 - val_loss: 0.4714 - val_precision: 0.8172 - val_recall: 0.8185 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4550 - precision: 0.8223 - recall: 0.8395 - val_loss: 0.5044 - val_precision: 0.7621 - val_recall: 0.8969 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4598 - precision: 0.8177 - recall: 0.8436 - val_loss: 0.4730 - val_precision: 0.8011 - val_recall: 0.8677 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4514 - precision: 0.8243 - recall: 0.8454 - val_loss: 0.4744 - val_precision: 0.8027 - val_recall: 0.8385 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4530 - precision: 0.8219 - recall: 0.8454 - val_loss: 0.4660 - val_precision: 0.8076 - val_recall: 0.8462 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4544 - precision: 0.8249 - recall: 0.8401 - val_loss: 0.4679 - val_precision: 0.8074 - val_recall: 0.8446 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.4473 - precision: 0.8217 - recall: 0.8446 - val_loss: 0.4640 - val_precision: 0.8126 - val_recall: 0.8338 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4421 - precision: 0.8226 - recall: 0.8514 - val_loss: 0.4713 - val_precision: 0.8202 - val_recall: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4423 - precision: 0.8275 - recall: 0.8494 - val_loss: 0.4634 - val_precision: 0.8120 - val_recall: 0.8508 - lr: 5.0000e-04\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4401 - precision: 0.8270 - recall: 0.8549 - val_loss: 0.4716 - val_precision: 0.8216 - val_recall: 0.8077 - lr: 5.0000e-04\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4416 - precision: 0.8266 - recall: 0.8469 - val_loss: 0.4643 - val_precision: 0.8052 - val_recall: 0.8523 - lr: 5.0000e-04\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4408 - precision: 0.8267 - recall: 0.8491 - val_loss: 0.4603 - val_precision: 0.8202 - val_recall: 0.8138 - lr: 5.0000e-04\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4380 - precision: 0.8286 - recall: 0.8496 - val_loss: 0.4605 - val_precision: 0.8117 - val_recall: 0.8354 - lr: 2.5000e-04\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4349 - precision: 0.8307 - recall: 0.8461 - val_loss: 0.4627 - val_precision: 0.8122 - val_recall: 0.8585 - lr: 2.5000e-04\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4340 - precision: 0.8274 - recall: 0.8531 - val_loss: 0.4649 - val_precision: 0.8126 - val_recall: 0.8338 - lr: 2.5000e-04\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4338 - precision: 0.8296 - recall: 0.8542 - val_loss: 0.4608 - val_precision: 0.8168 - val_recall: 0.8369 - lr: 2.5000e-04\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 1s 55ms/step - loss: 0.4331 - precision: 0.8306 - recall: 0.8499 - val_loss: 0.4663 - val_precision: 0.7969 - val_recall: 0.8631 - lr: 2.5000e-04\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4324 - precision: 0.8280 - recall: 0.8534 - val_loss: 0.4585 - val_precision: 0.8135 - val_recall: 0.8523 - lr: 1.2500e-04\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4269 - precision: 0.8342 - recall: 0.8556 - val_loss: 0.4594 - val_precision: 0.8115 - val_recall: 0.8477 - lr: 1.2500e-04\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4311 - precision: 0.8282 - recall: 0.8577 - val_loss: 0.4605 - val_precision: 0.8129 - val_recall: 0.8354 - lr: 1.2500e-04\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4298 - precision: 0.8330 - recall: 0.8559 - val_loss: 0.4584 - val_precision: 0.8191 - val_recall: 0.8431 - lr: 1.2500e-04\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4287 - precision: 0.8312 - recall: 0.8567 - val_loss: 0.4624 - val_precision: 0.8159 - val_recall: 0.8385 - lr: 1.2500e-04\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4296 - precision: 0.8318 - recall: 0.8589 - val_loss: 0.4589 - val_precision: 0.8155 - val_recall: 0.8431 - lr: 6.2500e-05\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4286 - precision: 0.8294 - recall: 0.8524 - val_loss: 0.4591 - val_precision: 0.8168 - val_recall: 0.8508 - lr: 6.2500e-05\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4301 - precision: 0.8304 - recall: 0.8541 - val_loss: 0.4588 - val_precision: 0.8151 - val_recall: 0.8477 - lr: 6.2500e-05\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4280 - precision: 0.8323 - recall: 0.8551 - val_loss: 0.4592 - val_precision: 0.8189 - val_recall: 0.8415 - lr: 6.2500e-05\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4292 - precision: 0.8320 - recall: 0.8516 - val_loss: 0.4597 - val_precision: 0.8072 - val_recall: 0.8569 - lr: 6.2500e-05\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4276 - precision: 0.8340 - recall: 0.8557 - val_loss: 0.4589 - val_precision: 0.8111 - val_recall: 0.8523 - lr: 3.1250e-05\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4281 - precision: 0.8353 - recall: 0.8570 - val_loss: 0.4584 - val_precision: 0.8139 - val_recall: 0.8477 - lr: 3.1250e-05\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4315 - precision: 0.8255 - recall: 0.8542 - val_loss: 0.4595 - val_precision: 0.8194 - val_recall: 0.8446 - lr: 3.1250e-05\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4275 - precision: 0.8309 - recall: 0.8589 - val_loss: 0.4583 - val_precision: 0.8144 - val_recall: 0.8508 - lr: 3.1250e-05\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4275 - precision: 0.8342 - recall: 0.8502 - val_loss: 0.4590 - val_precision: 0.8046 - val_recall: 0.8554 - lr: 3.1250e-05\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4266 - precision: 0.8261 - recall: 0.8650 - val_loss: 0.4589 - val_precision: 0.8185 - val_recall: 0.8462 - lr: 1.5625e-05\n",
            "Epoch 53/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4271 - precision: 0.8363 - recall: 0.8541 - val_loss: 0.4587 - val_precision: 0.8166 - val_recall: 0.8492 - lr: 1.5625e-05\n",
            "Epoch 54/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4269 - precision: 0.8340 - recall: 0.8559 - val_loss: 0.4590 - val_precision: 0.8156 - val_recall: 0.8508 - lr: 1.5625e-05\n",
            "Epoch 55/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4267 - precision: 0.8329 - recall: 0.8539 - val_loss: 0.4588 - val_precision: 0.8166 - val_recall: 0.8492 - lr: 1.5625e-05\n",
            "Epoch 56/100\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4274 - precision: 0.8317 - recall: 0.8534 - val_loss: 0.4588 - val_precision: 0.8120 - val_recall: 0.8508 - lr: 1.5625e-05\n",
            "Epoch 57/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4261 - precision: 0.8335 - recall: 0.8585 - val_loss: 0.4589 - val_precision: 0.8118 - val_recall: 0.8492 - lr: 7.8125e-06\n",
            "Epoch 58/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4273 - precision: 0.8294 - recall: 0.8572 - val_loss: 0.4588 - val_precision: 0.8120 - val_recall: 0.8508 - lr: 7.8125e-06\n",
            "Epoch 59/100\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4265 - precision: 0.8328 - recall: 0.8572 - val_loss: 0.4586 - val_precision: 0.8120 - val_recall: 0.8508 - lr: 7.8125e-06\n",
            "Epoch 60/100\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4270 - precision: 0.8301 - recall: 0.8562 - val_loss: 0.4587 - val_precision: 0.8142 - val_recall: 0.8492 - lr: 7.8125e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e928458fd00>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12966, 3840, 3)\n",
            "(12966,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 16s 113ms/step - loss: 0.4514 - precision: 0.8293 - recall: 0.8451 - val_loss: 0.4692 - val_precision: 0.8085 - val_recall: 0.8512 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4261 - precision: 0.8362 - recall: 0.8569 - val_loss: 0.4561 - val_precision: 0.8141 - val_recall: 0.8480 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4231 - precision: 0.8396 - recall: 0.8522 - val_loss: 0.4608 - val_precision: 0.7988 - val_recall: 0.8704 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4188 - precision: 0.8416 - recall: 0.8585 - val_loss: 0.4652 - val_precision: 0.8033 - val_recall: 0.8496 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.4176 - precision: 0.8393 - recall: 0.8623 - val_loss: 0.4615 - val_precision: 0.8088 - val_recall: 0.8528 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4185 - precision: 0.8432 - recall: 0.8512 - val_loss: 0.4825 - val_precision: 0.7808 - val_recall: 0.8720 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4247 - precision: 0.8349 - recall: 0.8574 - val_loss: 0.4684 - val_precision: 0.8273 - val_recall: 0.8048 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 57ms/step - loss: 0.4207 - precision: 0.8408 - recall: 0.8521 - val_loss: 0.4585 - val_precision: 0.8165 - val_recall: 0.8400 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4162 - precision: 0.8417 - recall: 0.8587 - val_loss: 0.4742 - val_precision: 0.7985 - val_recall: 0.8688 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4194 - precision: 0.8362 - recall: 0.8567 - val_loss: 0.4662 - val_precision: 0.8027 - val_recall: 0.8720 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4132 - precision: 0.8445 - recall: 0.8592 - val_loss: 0.4719 - val_precision: 0.7971 - val_recall: 0.8864 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4126 - precision: 0.8432 - recall: 0.8587 - val_loss: 0.4649 - val_precision: 0.8202 - val_recall: 0.8320 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e928458fd00>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12555, 3840, 3)\n",
            "(12555,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 16s 116ms/step - loss: 0.4744 - precision: 0.8107 - recall: 0.8274 - val_loss: 0.4744 - val_precision: 0.8070 - val_recall: 0.8405 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4555 - precision: 0.8170 - recall: 0.8417 - val_loss: 0.4586 - val_precision: 0.8173 - val_recall: 0.8322 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4538 - precision: 0.8210 - recall: 0.8370 - val_loss: 0.4669 - val_precision: 0.7945 - val_recall: 0.8605 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4579 - precision: 0.8154 - recall: 0.8315 - val_loss: 0.4620 - val_precision: 0.8035 - val_recall: 0.8422 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4536 - precision: 0.8201 - recall: 0.8417 - val_loss: 0.4712 - val_precision: 0.8319 - val_recall: 0.7973 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4600 - precision: 0.8219 - recall: 0.8257 - val_loss: 0.4633 - val_precision: 0.8217 - val_recall: 0.8189 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4477 - precision: 0.8290 - recall: 0.8378 - val_loss: 0.4941 - val_precision: 0.7487 - val_recall: 0.9252 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4543 - precision: 0.8162 - recall: 0.8360 - val_loss: 0.4668 - val_precision: 0.8119 - val_recall: 0.8389 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4479 - precision: 0.8246 - recall: 0.8383 - val_loss: 0.4679 - val_precision: 0.8070 - val_recall: 0.8472 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4537 - precision: 0.8173 - recall: 0.8308 - val_loss: 0.4767 - val_precision: 0.7925 - val_recall: 0.8754 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4517 - precision: 0.8213 - recall: 0.8429 - val_loss: 0.4688 - val_precision: 0.8250 - val_recall: 0.7990 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4486 - precision: 0.8281 - recall: 0.8383 - val_loss: 0.4527 - val_precision: 0.8063 - val_recall: 0.8505 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4432 - precision: 0.8203 - recall: 0.8472 - val_loss: 0.4737 - val_precision: 0.8275 - val_recall: 0.7807 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4433 - precision: 0.8257 - recall: 0.8422 - val_loss: 0.4548 - val_precision: 0.8278 - val_recall: 0.8223 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4437 - precision: 0.8280 - recall: 0.8401 - val_loss: 0.4567 - val_precision: 0.8197 - val_recall: 0.8156 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4416 - precision: 0.8262 - recall: 0.8463 - val_loss: 0.4752 - val_precision: 0.7688 - val_recall: 0.9003 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4544 - precision: 0.8136 - recall: 0.8378 - val_loss: 0.4517 - val_precision: 0.8048 - val_recall: 0.8422 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4398 - precision: 0.8252 - recall: 0.8443 - val_loss: 0.4550 - val_precision: 0.8140 - val_recall: 0.8289 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4358 - precision: 0.8298 - recall: 0.8454 - val_loss: 0.4623 - val_precision: 0.8238 - val_recall: 0.8156 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4389 - precision: 0.8277 - recall: 0.8390 - val_loss: 0.4653 - val_precision: 0.7885 - val_recall: 0.8854 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4429 - precision: 0.8204 - recall: 0.8468 - val_loss: 0.4633 - val_precision: 0.8192 - val_recall: 0.8206 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4493 - precision: 0.8230 - recall: 0.8321 - val_loss: 0.4560 - val_precision: 0.8129 - val_recall: 0.8372 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4491 - precision: 0.8202 - recall: 0.8438 - val_loss: 0.5064 - val_precision: 0.7497 - val_recall: 0.9153 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4468 - precision: 0.8187 - recall: 0.8475 - val_loss: 0.4719 - val_precision: 0.7824 - val_recall: 0.8721 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4436 - precision: 0.8284 - recall: 0.8417 - val_loss: 0.4596 - val_precision: 0.7946 - val_recall: 0.8738 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4441 - precision: 0.8241 - recall: 0.8395 - val_loss: 0.4651 - val_precision: 0.8138 - val_recall: 0.8422 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4346 - precision: 0.8288 - recall: 0.8486 - val_loss: 0.4537 - val_precision: 0.7957 - val_recall: 0.8671 - lr: 5.0000e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e928458fd00>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13001, 3840, 3)\n",
            "(13001,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 16s 117ms/step - loss: 0.4623 - precision: 0.8161 - recall: 0.8348 - val_loss: 0.4006 - val_precision: 0.8527 - val_recall: 0.8649 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4336 - precision: 0.8257 - recall: 0.8513 - val_loss: 0.4191 - val_precision: 0.8509 - val_recall: 0.8347 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4395 - precision: 0.8245 - recall: 0.8509 - val_loss: 0.4100 - val_precision: 0.8519 - val_recall: 0.8410 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4366 - precision: 0.8267 - recall: 0.8442 - val_loss: 0.4083 - val_precision: 0.8511 - val_recall: 0.8362 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4341 - precision: 0.8247 - recall: 0.8509 - val_loss: 0.4066 - val_precision: 0.8288 - val_recall: 0.8776 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4396 - precision: 0.8244 - recall: 0.8437 - val_loss: 0.4068 - val_precision: 0.8569 - val_recall: 0.8283 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4318 - precision: 0.8251 - recall: 0.8499 - val_loss: 0.4059 - val_precision: 0.8495 - val_recall: 0.8617 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4335 - precision: 0.8288 - recall: 0.8501 - val_loss: 0.3963 - val_precision: 0.8562 - val_recall: 0.8521 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4293 - precision: 0.8299 - recall: 0.8496 - val_loss: 0.4090 - val_precision: 0.8398 - val_recall: 0.8585 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4330 - precision: 0.8265 - recall: 0.8487 - val_loss: 0.4052 - val_precision: 0.8394 - val_recall: 0.8728 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4286 - precision: 0.8271 - recall: 0.8532 - val_loss: 0.4202 - val_precision: 0.8634 - val_recall: 0.8140 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4312 - precision: 0.8281 - recall: 0.8451 - val_loss: 0.4056 - val_precision: 0.8562 - val_recall: 0.8426 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4301 - precision: 0.8290 - recall: 0.8451 - val_loss: 0.4113 - val_precision: 0.8569 - val_recall: 0.8283 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4315 - precision: 0.8289 - recall: 0.8487 - val_loss: 0.3989 - val_precision: 0.8482 - val_recall: 0.8442 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4280 - precision: 0.8262 - recall: 0.8475 - val_loss: 0.3932 - val_precision: 0.8565 - val_recall: 0.8537 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4319 - precision: 0.8308 - recall: 0.8460 - val_loss: 0.4135 - val_precision: 0.8553 - val_recall: 0.8267 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4277 - precision: 0.8256 - recall: 0.8520 - val_loss: 0.4041 - val_precision: 0.8625 - val_recall: 0.8378 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4257 - precision: 0.8301 - recall: 0.8537 - val_loss: 0.4080 - val_precision: 0.8474 - val_recall: 0.8474 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4259 - precision: 0.8296 - recall: 0.8511 - val_loss: 0.4027 - val_precision: 0.8524 - val_recall: 0.8633 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4281 - precision: 0.8296 - recall: 0.8494 - val_loss: 0.4017 - val_precision: 0.8361 - val_recall: 0.8839 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4362 - precision: 0.8235 - recall: 0.8509 - val_loss: 0.4203 - val_precision: 0.8552 - val_recall: 0.8076 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4360 - precision: 0.8296 - recall: 0.8446 - val_loss: 0.4219 - val_precision: 0.8555 - val_recall: 0.8188 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4258 - precision: 0.8329 - recall: 0.8494 - val_loss: 0.4127 - val_precision: 0.8472 - val_recall: 0.8553 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4236 - precision: 0.8302 - recall: 0.8523 - val_loss: 0.4104 - val_precision: 0.8654 - val_recall: 0.8378 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 1s 57ms/step - loss: 0.4243 - precision: 0.8285 - recall: 0.8528 - val_loss: 0.4042 - val_precision: 0.8428 - val_recall: 0.8696 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e928458fd00>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training complete\n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "# sig_dict_chat = {\n",
        "#     \"EOG\": [0, 1],\n",
        "#     \"EEG\": [4, 5],\n",
        "#     \"ECG\": [15,16],\n",
        "#     \"Resp\": [9, 10],\n",
        "#     \"SPO2\": [13],\n",
        "#     \"CO2\": [14],\n",
        "# }\n",
        "\n",
        "# channel_list_chat = [\n",
        "#     [\"ECG\", \"SPO2\"]\n",
        "# ]\n",
        "\n",
        "# for ch in channel_list_chat:\n",
        "#     chs = []\n",
        "#     chstr = \"\"\n",
        "#     for name in ch:\n",
        "#         chstr += name\n",
        "#         chs = chs + sig_dict_chat[name]\n",
        "#     print(chstr, chs)\n",
        "#     config = {\n",
        "#         \"data_path\": data_path + 'chat_',\n",
        "#         \"model_path\": model_path,\n",
        "#         \"model_name\": \"model_25lrs_\"+ chstr,\n",
        "#         \"regression\": False,\n",
        "#         \"epochs\": 100,\n",
        "#         \"channels\": chs,\n",
        "#     }\n",
        "#     train(config, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn7r0q3dQ6cO",
        "outputId": "ade9ecaa-cfa4-45df-ae6d-8be685e286b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3506, 3840, 3)\n",
            "test starting\n",
            "78/78 [==============================] - 1s 9ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95/95 [==============================] - 1s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 2s 9ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124/124 [==============================] - 2s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 2s 9ms/step\n",
            "=========================================================================== \n",
            "[82.94260307194826, 85.00329597890574, 80.59870093194013, 85.4251012145749, 83.71363377067884] \n",
            "[84.16596104995766, 86.1948142957253, 79.20685959271168, 86.19777895293495, 82.1309655937847] \n",
            "[80.87876322213181, 82.66129032258065, 83.17388857625211, 83.80462724935732, 85.59861191440139] \n",
            "[84.97991967871485, 87.25743855109961, 78.00453514739229, 86.99551569506725, 81.87957231288688] \n",
            "[82.48962655601659, 84.3910806174957, 81.14191600329399, 84.98435870698644, 83.82894364202775] \n",
            "[91.33418948372824, 92.00768719831964, 88.05676463044419, 91.70366442387376, 90.40758577973872] \n",
            "[89.99353325682134, 91.07876060697824, 87.14165388985897, 90.46401956243955, 88.60939313919211] \n",
            "Accuracy: 83.54 -+ 1.717 \n",
            "Precision: 83.58 -+ 2.655 \n",
            "Recall: 83.22 -+ 1.536 \n",
            "Specifity: 83.82 -+ 3.488 \n",
            "F1: 83.37 -+ 1.386 \n",
            "AUROC: 90.70 -+ 1.428 \n",
            "AUPRC: 89.46 -+ 1.415 \n",
            "$ 83.5 \\pm 1.7$& $83.6 \\pm 2.7$& $83.2 \\pm 1.5$& $83.4 \\pm 1.4$& $90.7 \\pm 1.4$& \n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "sig_dict_chat = {\n",
        "    \"EOG\": [0, 1],\n",
        "    \"EEG\": [4, 5],\n",
        "    \"ECG\": [15,16],\n",
        "    \"Resp\": [9, 10],\n",
        "    \"SPO2\": [13],\n",
        "    \"CO2\": [14],\n",
        "}\n",
        "\n",
        "channel_list_chat = [\n",
        "    [\"ECG\", \"SPO2\"],\n",
        "]\n",
        "\n",
        "for ch in channel_list_chat:\n",
        "    chs = []\n",
        "    chstr = \"\"\n",
        "    for name in ch:\n",
        "        chstr += name\n",
        "        chs = chs + sig_dict_chat[name]\n",
        "    print(chstr, chs)\n",
        "    config = {\n",
        "        \"data_path\": data_path + 'chat_',\n",
        "        \"model_path\": model_path,\n",
        "        \"model_name\": \"model_25lrs_\"+ chstr,\n",
        "        \"channels\": chs,\n",
        "    }\n",
        "    test(config, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QMxMpXRFf1O"
      },
      "source": [
        "### Discussion of learning rate schedule experiment\n",
        "\n",
        "The difference in model performance based on different learning rate schedules is summarized in the table below.\n",
        "\n",
        "As you can see, the learning rate that starts decreasing at an earlier epoch stage actually performs better than the other options. But, the original author's learning rate scheduling algorithm outperforms in some metrics.\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1MBbzNvq9A_zoXf9eMoSFzuFHPZoP5nl5\"/>\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCeZj2zFSTmg"
      },
      "source": [
        "###Experiment - number of epochs\n",
        "\n",
        "We will now compare using 100 epochs (already tested above in inital model above) to 200 epochs and  400 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PqDMTOiSel7"
      },
      "outputs": [],
      "source": [
        "#Same as initial model\n",
        "input_shape = (128 * 30, 3)\n",
        "num_patches = 30\n",
        "\n",
        "transformer_layers = 5\n",
        "num_heads = 4\n",
        "transformer_units = 32\n",
        "reg = False\n",
        "drop_out = 0.25\n",
        "l2_weight = 0.001\n",
        "\n",
        "model = create_transformer_model(input_shape, num_patches,\n",
        "                                projection_dim=transformer_units, transformer_layers=transformer_layers,\n",
        "                                num_heads=num_heads,\n",
        "                                transformer_units = [transformer_units*2, transformer_units],\n",
        "                                mlp_head_units=[256, 128],\n",
        "                                num_classes=1, drop_out=drop_out, reg=reg, l2_weight=l2_weight, demographic=False)\n",
        "loss_func = BinaryCrossentropy()\n",
        "optimizer = \"adam\"\n",
        "\n",
        "#Prevent over-fitting on same fold.\n",
        "def lr_schedule(epoch, lr):\n",
        "\n",
        "    if epoch > 50 and (epoch - 1) % 5 == 0:\n",
        "        lr *= 0.5\n",
        "\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnld1OPdTE7z"
      },
      "source": [
        "###**200 epochs:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRWZWwe-TLNj",
        "outputId": "e354bae5-e730-411d-f7e1-0837962743f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "5\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n",
            "(3506, 3840, 3)\n",
            "training\n",
            "(14033, 3840, 3)\n",
            "(14033,)\n",
            "Epoch 1/200\n",
            "25/25 [==============================] - 17s 111ms/step - loss: 1.4532 - precision: 0.6318 - recall: 0.8173 - val_loss: 1.2931 - val_precision: 0.6740 - val_recall: 0.7525 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 1.2002 - precision: 0.6806 - recall: 0.8004 - val_loss: 1.0975 - val_precision: 0.6926 - val_recall: 0.7813 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 1.0314 - precision: 0.7176 - recall: 0.8251 - val_loss: 0.9824 - val_precision: 0.6812 - val_recall: 0.8791 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.9177 - precision: 0.7477 - recall: 0.8192 - val_loss: 0.8982 - val_precision: 0.7477 - val_recall: 0.8187 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.8623 - precision: 0.7504 - recall: 0.8093 - val_loss: 0.8377 - val_precision: 0.7704 - val_recall: 0.7727 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.7909 - precision: 0.7839 - recall: 0.8118 - val_loss: 0.7909 - val_precision: 0.7776 - val_recall: 0.7799 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.7518 - precision: 0.7865 - recall: 0.8181 - val_loss: 0.7600 - val_precision: 0.7449 - val_recall: 0.8403 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.7107 - precision: 0.7970 - recall: 0.8198 - val_loss: 0.7407 - val_precision: 0.7972 - val_recall: 0.7410 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.6854 - precision: 0.7969 - recall: 0.8274 - val_loss: 0.7124 - val_precision: 0.7723 - val_recall: 0.8101 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.6648 - precision: 0.8018 - recall: 0.8174 - val_loss: 0.6808 - val_precision: 0.7711 - val_recall: 0.8432 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.6404 - precision: 0.8032 - recall: 0.8315 - val_loss: 0.6735 - val_precision: 0.7901 - val_recall: 0.7799 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.6212 - precision: 0.8017 - recall: 0.8309 - val_loss: 0.6488 - val_precision: 0.7911 - val_recall: 0.8230 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.6042 - precision: 0.8120 - recall: 0.8302 - val_loss: 0.6267 - val_precision: 0.7923 - val_recall: 0.8345 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5906 - precision: 0.8118 - recall: 0.8344 - val_loss: 0.6214 - val_precision: 0.7878 - val_recall: 0.8388 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5833 - precision: 0.8052 - recall: 0.8370 - val_loss: 0.6170 - val_precision: 0.7872 - val_recall: 0.8302 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5719 - precision: 0.8138 - recall: 0.8373 - val_loss: 0.6043 - val_precision: 0.8003 - val_recall: 0.8014 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.5635 - precision: 0.8127 - recall: 0.8392 - val_loss: 0.5905 - val_precision: 0.7962 - val_recall: 0.8432 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5527 - precision: 0.8134 - recall: 0.8370 - val_loss: 0.5866 - val_precision: 0.7933 - val_recall: 0.8230 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5444 - precision: 0.8163 - recall: 0.8442 - val_loss: 0.5732 - val_precision: 0.7778 - val_recall: 0.8763 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5381 - precision: 0.8154 - recall: 0.8439 - val_loss: 0.5800 - val_precision: 0.7892 - val_recall: 0.8619 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5317 - precision: 0.8148 - recall: 0.8429 - val_loss: 0.5696 - val_precision: 0.8116 - val_recall: 0.8058 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5313 - precision: 0.8165 - recall: 0.8416 - val_loss: 0.5601 - val_precision: 0.7873 - val_recall: 0.8734 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5248 - precision: 0.8182 - recall: 0.8326 - val_loss: 0.5535 - val_precision: 0.7624 - val_recall: 0.8863 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5204 - precision: 0.8157 - recall: 0.8400 - val_loss: 0.5552 - val_precision: 0.7951 - val_recall: 0.8374 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.5147 - precision: 0.8142 - recall: 0.8480 - val_loss: 0.5560 - val_precision: 0.7938 - val_recall: 0.8532 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5098 - precision: 0.8217 - recall: 0.8424 - val_loss: 0.5477 - val_precision: 0.8003 - val_recall: 0.8475 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.5016 - precision: 0.8211 - recall: 0.8495 - val_loss: 0.5361 - val_precision: 0.8121 - val_recall: 0.8331 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4995 - precision: 0.8220 - recall: 0.8461 - val_loss: 0.5406 - val_precision: 0.7819 - val_recall: 0.8561 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.5004 - precision: 0.8160 - recall: 0.8471 - val_loss: 0.5429 - val_precision: 0.7989 - val_recall: 0.8518 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4990 - precision: 0.8204 - recall: 0.8400 - val_loss: 0.5362 - val_precision: 0.7876 - val_recall: 0.8748 - lr: 0.0010\n",
            "Epoch 31/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4900 - precision: 0.8254 - recall: 0.8480 - val_loss: 0.5264 - val_precision: 0.7754 - val_recall: 0.8892 - lr: 0.0010\n",
            "Epoch 32/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4911 - precision: 0.8182 - recall: 0.8450 - val_loss: 0.5272 - val_precision: 0.7608 - val_recall: 0.8835 - lr: 0.0010\n",
            "Epoch 33/200\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.4891 - precision: 0.8237 - recall: 0.8453 - val_loss: 0.5137 - val_precision: 0.8064 - val_recall: 0.8331 - lr: 0.0010\n",
            "Epoch 34/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4839 - precision: 0.8167 - recall: 0.8443 - val_loss: 0.5178 - val_precision: 0.8132 - val_recall: 0.8144 - lr: 0.0010\n",
            "Epoch 35/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4867 - precision: 0.8201 - recall: 0.8459 - val_loss: 0.5232 - val_precision: 0.8046 - val_recall: 0.8058 - lr: 0.0010\n",
            "Epoch 36/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4892 - precision: 0.8209 - recall: 0.8378 - val_loss: 0.5299 - val_precision: 0.7640 - val_recall: 0.8849 - lr: 0.0010\n",
            "Epoch 37/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4805 - precision: 0.8205 - recall: 0.8435 - val_loss: 0.5086 - val_precision: 0.8186 - val_recall: 0.8115 - lr: 0.0010\n",
            "Epoch 38/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4779 - precision: 0.8239 - recall: 0.8495 - val_loss: 0.5064 - val_precision: 0.7848 - val_recall: 0.8763 - lr: 0.0010\n",
            "Epoch 39/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4729 - precision: 0.8196 - recall: 0.8475 - val_loss: 0.5029 - val_precision: 0.7885 - val_recall: 0.8691 - lr: 0.0010\n",
            "Epoch 40/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4723 - precision: 0.8201 - recall: 0.8533 - val_loss: 0.5049 - val_precision: 0.8179 - val_recall: 0.8144 - lr: 0.0010\n",
            "Epoch 41/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4731 - precision: 0.8188 - recall: 0.8386 - val_loss: 0.4936 - val_precision: 0.8014 - val_recall: 0.8532 - lr: 0.0010\n",
            "Epoch 42/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4699 - precision: 0.8259 - recall: 0.8488 - val_loss: 0.5083 - val_precision: 0.7911 - val_recall: 0.8662 - lr: 0.0010\n",
            "Epoch 43/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4679 - precision: 0.8246 - recall: 0.8458 - val_loss: 0.5197 - val_precision: 0.7666 - val_recall: 0.8791 - lr: 0.0010\n",
            "Epoch 44/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4696 - precision: 0.8200 - recall: 0.8475 - val_loss: 0.4969 - val_precision: 0.7971 - val_recall: 0.8647 - lr: 0.0010\n",
            "Epoch 45/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4655 - precision: 0.8260 - recall: 0.8451 - val_loss: 0.5093 - val_precision: 0.7863 - val_recall: 0.8734 - lr: 0.0010\n",
            "Epoch 46/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4618 - precision: 0.8191 - recall: 0.8506 - val_loss: 0.5052 - val_precision: 0.8000 - val_recall: 0.8576 - lr: 0.0010\n",
            "Epoch 47/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4634 - precision: 0.8244 - recall: 0.8430 - val_loss: 0.4976 - val_precision: 0.7926 - val_recall: 0.8633 - lr: 0.0010\n",
            "Epoch 48/200\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.4621 - precision: 0.8191 - recall: 0.8491 - val_loss: 0.4799 - val_precision: 0.8085 - val_recall: 0.8446 - lr: 0.0010\n",
            "Epoch 49/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4599 - precision: 0.8215 - recall: 0.8488 - val_loss: 0.5015 - val_precision: 0.8180 - val_recall: 0.8086 - lr: 0.0010\n",
            "Epoch 50/200\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4594 - precision: 0.8236 - recall: 0.8459 - val_loss: 0.4910 - val_precision: 0.7942 - val_recall: 0.8662 - lr: 0.0010\n",
            "Epoch 51/200\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.4569 - precision: 0.8282 - recall: 0.8440 - val_loss: 0.5011 - val_precision: 0.7759 - val_recall: 0.8820 - lr: 0.0010\n",
            "Epoch 52/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4539 - precision: 0.8264 - recall: 0.8528 - val_loss: 0.4906 - val_precision: 0.8141 - val_recall: 0.8129 - lr: 5.0000e-04\n",
            "Epoch 53/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4518 - precision: 0.8290 - recall: 0.8485 - val_loss: 0.4813 - val_precision: 0.8135 - val_recall: 0.8345 - lr: 5.0000e-04\n",
            "Epoch 54/200\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4463 - precision: 0.8278 - recall: 0.8560 - val_loss: 0.4821 - val_precision: 0.7992 - val_recall: 0.8705 - lr: 5.0000e-04\n",
            "Epoch 55/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4464 - precision: 0.8268 - recall: 0.8563 - val_loss: 0.4942 - val_precision: 0.7935 - val_recall: 0.8734 - lr: 5.0000e-04\n",
            "Epoch 56/200\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4457 - precision: 0.8272 - recall: 0.8519 - val_loss: 0.4918 - val_precision: 0.8005 - val_recall: 0.8604 - lr: 5.0000e-04\n",
            "Epoch 57/200\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4419 - precision: 0.8290 - recall: 0.8581 - val_loss: 0.4845 - val_precision: 0.8016 - val_recall: 0.8719 - lr: 2.5000e-04\n",
            "Epoch 58/200\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.4413 - precision: 0.8296 - recall: 0.8506 - val_loss: 0.4848 - val_precision: 0.8013 - val_recall: 0.8647 - lr: 2.5000e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e926ec0e590>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13473, 3840, 3)\n",
            "(13473,)\n",
            "Epoch 1/200\n",
            "24/24 [==============================] - 16s 111ms/step - loss: 0.4797 - precision: 0.8049 - recall: 0.8394 - val_loss: 0.5099 - val_precision: 0.8158 - val_recall: 0.8000 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4628 - precision: 0.8172 - recall: 0.8456 - val_loss: 0.4905 - val_precision: 0.8060 - val_recall: 0.8373 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4587 - precision: 0.8211 - recall: 0.8479 - val_loss: 0.4975 - val_precision: 0.8009 - val_recall: 0.8403 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4648 - precision: 0.8119 - recall: 0.8506 - val_loss: 0.4871 - val_precision: 0.7962 - val_recall: 0.8746 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4650 - precision: 0.8165 - recall: 0.8374 - val_loss: 0.4807 - val_precision: 0.8100 - val_recall: 0.8463 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4559 - precision: 0.8193 - recall: 0.8464 - val_loss: 0.4970 - val_precision: 0.8032 - val_recall: 0.8343 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4565 - precision: 0.8182 - recall: 0.8499 - val_loss: 0.4802 - val_precision: 0.8058 - val_recall: 0.8672 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4521 - precision: 0.8216 - recall: 0.8514 - val_loss: 0.4905 - val_precision: 0.7980 - val_recall: 0.8493 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4501 - precision: 0.8181 - recall: 0.8517 - val_loss: 0.4965 - val_precision: 0.7763 - val_recall: 0.8910 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4547 - precision: 0.8103 - recall: 0.8506 - val_loss: 0.4938 - val_precision: 0.8014 - val_recall: 0.8433 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4505 - precision: 0.8215 - recall: 0.8532 - val_loss: 0.5034 - val_precision: 0.7984 - val_recall: 0.8687 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4565 - precision: 0.8162 - recall: 0.8484 - val_loss: 0.4850 - val_precision: 0.8109 - val_recall: 0.8448 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4519 - precision: 0.8176 - recall: 0.8456 - val_loss: 0.5001 - val_precision: 0.7649 - val_recall: 0.8791 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4535 - precision: 0.8160 - recall: 0.8507 - val_loss: 0.4995 - val_precision: 0.8116 - val_recall: 0.7910 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4525 - precision: 0.8146 - recall: 0.8443 - val_loss: 0.4939 - val_precision: 0.7951 - val_recall: 0.8284 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4557 - precision: 0.8148 - recall: 0.8464 - val_loss: 0.4815 - val_precision: 0.7885 - val_recall: 0.8627 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4490 - precision: 0.8152 - recall: 0.8486 - val_loss: 0.4806 - val_precision: 0.7989 - val_recall: 0.8299 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e926ec0e590>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12966, 3840, 3)\n",
            "(12966,)\n",
            "Epoch 1/200\n",
            "23/23 [==============================] - 16s 113ms/step - loss: 0.4383 - precision: 0.8299 - recall: 0.8576 - val_loss: 0.5028 - val_precision: 0.7887 - val_recall: 0.8594 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4281 - precision: 0.8344 - recall: 0.8630 - val_loss: 0.4879 - val_precision: 0.8000 - val_recall: 0.8346 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4290 - precision: 0.8310 - recall: 0.8626 - val_loss: 0.4965 - val_precision: 0.7869 - val_recall: 0.8563 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4281 - precision: 0.8333 - recall: 0.8614 - val_loss: 0.4992 - val_precision: 0.7917 - val_recall: 0.8578 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4194 - precision: 0.8378 - recall: 0.8694 - val_loss: 0.4916 - val_precision: 0.8051 - val_recall: 0.8300 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4270 - precision: 0.8340 - recall: 0.8600 - val_loss: 0.4800 - val_precision: 0.7980 - val_recall: 0.8609 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4236 - precision: 0.8363 - recall: 0.8593 - val_loss: 0.5186 - val_precision: 0.7640 - val_recall: 0.9057 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4216 - precision: 0.8323 - recall: 0.8616 - val_loss: 0.4883 - val_precision: 0.7853 - val_recall: 0.8764 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4175 - precision: 0.8377 - recall: 0.8618 - val_loss: 0.5089 - val_precision: 0.7686 - val_recall: 0.8779 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4222 - precision: 0.8327 - recall: 0.8647 - val_loss: 0.4823 - val_precision: 0.7866 - val_recall: 0.8547 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4174 - precision: 0.8374 - recall: 0.8625 - val_loss: 0.4982 - val_precision: 0.7805 - val_recall: 0.8516 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4224 - precision: 0.8327 - recall: 0.8619 - val_loss: 0.4877 - val_precision: 0.7945 - val_recall: 0.8423 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4132 - precision: 0.8384 - recall: 0.8689 - val_loss: 0.4990 - val_precision: 0.8034 - val_recall: 0.8145 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4177 - precision: 0.8376 - recall: 0.8593 - val_loss: 0.4884 - val_precision: 0.7857 - val_recall: 0.8671 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4169 - precision: 0.8340 - recall: 0.8670 - val_loss: 0.4848 - val_precision: 0.7988 - val_recall: 0.8470 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4155 - precision: 0.8380 - recall: 0.8621 - val_loss: 0.4888 - val_precision: 0.7848 - val_recall: 0.8624 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e926ec0e590>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12555, 3840, 3)\n",
            "(12555,)\n",
            "Epoch 1/200\n",
            "23/23 [==============================] - 16s 112ms/step - loss: 0.4656 - precision: 0.8091 - recall: 0.8371 - val_loss: 0.4872 - val_precision: 0.8113 - val_recall: 0.8203 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4553 - precision: 0.8144 - recall: 0.8398 - val_loss: 0.4964 - val_precision: 0.7709 - val_recall: 0.8935 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4510 - precision: 0.8168 - recall: 0.8514 - val_loss: 0.4798 - val_precision: 0.7973 - val_recall: 0.8506 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4473 - precision: 0.8157 - recall: 0.8457 - val_loss: 0.4751 - val_precision: 0.8027 - val_recall: 0.8537 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4559 - precision: 0.8144 - recall: 0.8404 - val_loss: 0.4819 - val_precision: 0.8261 - val_recall: 0.8156 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4557 - precision: 0.8165 - recall: 0.8455 - val_loss: 0.4897 - val_precision: 0.7927 - val_recall: 0.8633 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4518 - precision: 0.8133 - recall: 0.8448 - val_loss: 0.4846 - val_precision: 0.7953 - val_recall: 0.8521 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4505 - precision: 0.8124 - recall: 0.8548 - val_loss: 0.4973 - val_precision: 0.8197 - val_recall: 0.7949 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4542 - precision: 0.8109 - recall: 0.8427 - val_loss: 0.4841 - val_precision: 0.8043 - val_recall: 0.8299 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4455 - precision: 0.8178 - recall: 0.8472 - val_loss: 0.4848 - val_precision: 0.7885 - val_recall: 0.8712 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4499 - precision: 0.8196 - recall: 0.8429 - val_loss: 0.4714 - val_precision: 0.8080 - val_recall: 0.8362 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.4485 - precision: 0.8189 - recall: 0.8472 - val_loss: 0.4675 - val_precision: 0.7911 - val_recall: 0.8728 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4405 - precision: 0.8180 - recall: 0.8495 - val_loss: 0.4840 - val_precision: 0.8205 - val_recall: 0.8140 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4467 - precision: 0.8208 - recall: 0.8416 - val_loss: 0.4824 - val_precision: 0.8030 - val_recall: 0.8490 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4488 - precision: 0.8160 - recall: 0.8402 - val_loss: 0.4862 - val_precision: 0.8188 - val_recall: 0.8045 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4482 - precision: 0.8132 - recall: 0.8411 - val_loss: 0.5006 - val_precision: 0.8363 - val_recall: 0.7552 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4548 - precision: 0.8140 - recall: 0.8332 - val_loss: 0.4695 - val_precision: 0.8064 - val_recall: 0.8474 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4420 - precision: 0.8209 - recall: 0.8482 - val_loss: 0.4705 - val_precision: 0.7919 - val_recall: 0.8712 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4435 - precision: 0.8188 - recall: 0.8455 - val_loss: 0.4727 - val_precision: 0.7876 - val_recall: 0.8665 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4412 - precision: 0.8151 - recall: 0.8509 - val_loss: 0.4751 - val_precision: 0.7947 - val_recall: 0.8617 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4403 - precision: 0.8223 - recall: 0.8527 - val_loss: 0.4949 - val_precision: 0.7731 - val_recall: 0.8776 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4501 - precision: 0.8134 - recall: 0.8379 - val_loss: 0.4839 - val_precision: 0.7800 - val_recall: 0.8792 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e926ec0e590>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13001, 3840, 3)\n",
            "(13001,)\n",
            "Epoch 1/200\n",
            "23/23 [==============================] - 16s 114ms/step - loss: 0.4470 - precision: 0.8208 - recall: 0.8522 - val_loss: 0.4242 - val_precision: 0.8286 - val_recall: 0.8594 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4440 - precision: 0.8180 - recall: 0.8534 - val_loss: 0.4280 - val_precision: 0.8528 - val_recall: 0.8331 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4406 - precision: 0.8197 - recall: 0.8508 - val_loss: 0.4330 - val_precision: 0.8437 - val_recall: 0.8176 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4380 - precision: 0.8204 - recall: 0.8503 - val_loss: 0.4247 - val_precision: 0.8346 - val_recall: 0.8655 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4402 - precision: 0.8174 - recall: 0.8531 - val_loss: 0.4243 - val_precision: 0.8470 - val_recall: 0.8300 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4338 - precision: 0.8234 - recall: 0.8541 - val_loss: 0.4210 - val_precision: 0.8475 - val_recall: 0.8501 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4370 - precision: 0.8208 - recall: 0.8526 - val_loss: 0.4260 - val_precision: 0.8560 - val_recall: 0.8269 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4336 - precision: 0.8228 - recall: 0.8512 - val_loss: 0.4256 - val_precision: 0.8495 - val_recall: 0.8377 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4324 - precision: 0.8230 - recall: 0.8532 - val_loss: 0.4206 - val_precision: 0.8348 - val_recall: 0.8516 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4328 - precision: 0.8218 - recall: 0.8503 - val_loss: 0.4189 - val_precision: 0.8240 - val_recall: 0.8609 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4348 - precision: 0.8208 - recall: 0.8515 - val_loss: 0.4273 - val_precision: 0.8156 - val_recall: 0.8748 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4413 - precision: 0.8178 - recall: 0.8446 - val_loss: 0.4200 - val_precision: 0.8427 - val_recall: 0.8532 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4379 - precision: 0.8208 - recall: 0.8508 - val_loss: 0.4192 - val_precision: 0.8222 - val_recall: 0.8717 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4361 - precision: 0.8184 - recall: 0.8543 - val_loss: 0.4259 - val_precision: 0.8504 - val_recall: 0.8083 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4309 - precision: 0.8247 - recall: 0.8555 - val_loss: 0.4282 - val_precision: 0.8488 - val_recall: 0.8068 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4328 - precision: 0.8236 - recall: 0.8529 - val_loss: 0.4194 - val_precision: 0.8165 - val_recall: 0.8733 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "23/23 [==============================] - 1s 56ms/step - loss: 0.4337 - precision: 0.8219 - recall: 0.8534 - val_loss: 0.4186 - val_precision: 0.8299 - val_recall: 0.8748 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4299 - precision: 0.8271 - recall: 0.8550 - val_loss: 0.4172 - val_precision: 0.8392 - val_recall: 0.8470 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4268 - precision: 0.8273 - recall: 0.8488 - val_loss: 0.4242 - val_precision: 0.8151 - val_recall: 0.8655 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4288 - precision: 0.8205 - recall: 0.8548 - val_loss: 0.4294 - val_precision: 0.8285 - val_recall: 0.8362 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4277 - precision: 0.8256 - recall: 0.8527 - val_loss: 0.4261 - val_precision: 0.8122 - val_recall: 0.8825 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4249 - precision: 0.8218 - recall: 0.8596 - val_loss: 0.4238 - val_precision: 0.8427 - val_recall: 0.8362 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4287 - precision: 0.8230 - recall: 0.8491 - val_loss: 0.4184 - val_precision: 0.8128 - val_recall: 0.8655 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4303 - precision: 0.8194 - recall: 0.8576 - val_loss: 0.4280 - val_precision: 0.8482 - val_recall: 0.8207 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4296 - precision: 0.8245 - recall: 0.8470 - val_loss: 0.4397 - val_precision: 0.8106 - val_recall: 0.8733 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4267 - precision: 0.8212 - recall: 0.8543 - val_loss: 0.4218 - val_precision: 0.8395 - val_recall: 0.8408 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4237 - precision: 0.8261 - recall: 0.8553 - val_loss: 0.4182 - val_precision: 0.8242 - val_recall: 0.8624 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4239 - precision: 0.8248 - recall: 0.8581 - val_loss: 0.4272 - val_precision: 0.8381 - val_recall: 0.8563 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e926ec0e590>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training complete\n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "# sig_dict_chat = {\n",
        "#     \"EOG\": [0, 1],\n",
        "#     \"EEG\": [4, 5],\n",
        "#     \"ECG\": [15,16],\n",
        "#     \"Resp\": [9, 10],\n",
        "#     \"SPO2\": [13],\n",
        "#     \"CO2\": [14],\n",
        "# }\n",
        "\n",
        "# channel_list_chat = [\n",
        "#     [\"ECG\", \"SPO2\"]\n",
        "# ]\n",
        "\n",
        "# for ch in channel_list_chat:\n",
        "#     chs = []\n",
        "#     chstr = \"\"\n",
        "#     for name in ch:\n",
        "#         chstr += name\n",
        "#         chs = chs + sig_dict_chat[name]\n",
        "#     print(chstr, chs)\n",
        "#     config = {\n",
        "#         \"data_path\": data_path + 'chat_',\n",
        "#         \"model_path\": model_path,\n",
        "#         \"model_name\": \"model_200epochs_\"+ chstr,\n",
        "#         \"regression\": False,\n",
        "#         \"epochs\": 200, #changed to 200\n",
        "#         \"channels\": chs,\n",
        "#     }\n",
        "#     train(config, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX-M6zVMTPUr",
        "outputId": "31ed1058-4047-4ed2-c050-6349f30e22c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3506, 3840, 3)\n",
            "test starting\n",
            "78/78 [==============================] - 1s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95/95 [==============================] - 1s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 2s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124/124 [==============================] - 2s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 2s 8ms/step\n",
            "=========================================================================== \n",
            "[83.30638641875505, 85.36585365853658, 79.77972324202203, 84.89372469635627, 83.62806617227609] \n",
            "[83.83084577114428, 85.1278600269179, 77.76033490319205, 82.9423264907136, 81.36882129277566] \n",
            "[82.2620016273393, 85.01344086021506, 83.62408553742262, 87.24935732647815, 86.63967611336032] \n",
            "[84.33734939759037, 85.70504527813712, 75.90702947845806, 82.6108619830593, 80.6978052898143] \n",
            "[83.03901437371664, 85.07061197041021, 80.58568329718004, 85.04134302179905, 83.92156862745097] \n",
            "[90.9763055476585, 91.71013646037642, 87.32978841508466, 91.40145736708153, 90.03106007519122] \n",
            "[89.18326775654197, 90.20537623923101, 85.59015980529287, 89.55404635501469, 88.3405913579643] \n",
            "Accuracy: 83.39 -+ 1.963 \n",
            "Precision: 82.21 -+ 2.537 \n",
            "Recall: 84.96 -+ 1.851 \n",
            "Specifity: 81.85 -+ 3.414 \n",
            "F1: 83.53 -+ 1.657 \n",
            "AUROC: 90.29 -+ 1.584 \n",
            "AUPRC: 88.57 -+ 1.609 \n",
            "$ 83.4 \\pm 2.0$& $82.2 \\pm 2.5$& $85.0 \\pm 1.9$& $83.5 \\pm 1.7$& $90.3 \\pm 1.6$& \n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "sig_dict_chat = {\n",
        "    \"EOG\": [0, 1],\n",
        "    \"EEG\": [4, 5],\n",
        "    \"ECG\": [15,16],\n",
        "    \"Resp\": [9, 10],\n",
        "    \"SPO2\": [13],\n",
        "    \"CO2\": [14],\n",
        "}\n",
        "\n",
        "channel_list_chat = [\n",
        "    [\"ECG\", \"SPO2\"],\n",
        "]\n",
        "\n",
        "for ch in channel_list_chat:\n",
        "    chs = []\n",
        "    chstr = \"\"\n",
        "    for name in ch:\n",
        "        chstr += name\n",
        "        chs = chs + sig_dict_chat[name]\n",
        "    print(chstr, chs)\n",
        "    config = {\n",
        "        \"data_path\": data_path + 'chat_',\n",
        "        \"model_path\": model_path,\n",
        "        \"model_name\": \"model_200epochs_\"+ chstr,\n",
        "        \"channels\": chs,\n",
        "    }\n",
        "    test(config, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLNcCy8pTMBG"
      },
      "source": [
        "###**400 epochs:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si4zMY83TNjr",
        "outputId": "6c0a4964-d7b1-45f0-d1f5-a831e9336121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "5\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n",
            "(3506, 3840, 3)\n",
            "training\n",
            "(14033, 3840, 3)\n",
            "(14033,)\n",
            "Epoch 1/400\n",
            "25/25 [==============================] - 20s 108ms/step - loss: 0.4524 - precision: 0.8131 - recall: 0.8401 - val_loss: 0.4482 - val_precision: 0.8143 - val_recall: 0.8465 - lr: 0.0010\n",
            "Epoch 2/400\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4381 - precision: 0.8237 - recall: 0.8438 - val_loss: 0.4519 - val_precision: 0.8117 - val_recall: 0.8757 - lr: 0.0010\n",
            "Epoch 3/400\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4381 - precision: 0.8251 - recall: 0.8483 - val_loss: 0.4432 - val_precision: 0.8060 - val_recall: 0.8684 - lr: 0.0010\n",
            "Epoch 4/400\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4350 - precision: 0.8260 - recall: 0.8480 - val_loss: 0.4526 - val_precision: 0.8137 - val_recall: 0.8684 - lr: 0.0010\n",
            "Epoch 5/400\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4346 - precision: 0.8262 - recall: 0.8464 - val_loss: 0.4492 - val_precision: 0.8187 - val_recall: 0.8187 - lr: 0.0010\n",
            "Epoch 6/400\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4375 - precision: 0.8239 - recall: 0.8457 - val_loss: 0.4450 - val_precision: 0.8142 - val_recall: 0.8904 - lr: 0.0010\n",
            "Epoch 7/400\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4311 - precision: 0.8240 - recall: 0.8510 - val_loss: 0.4437 - val_precision: 0.8150 - val_recall: 0.8436 - lr: 0.0010\n",
            "Epoch 8/400\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4310 - precision: 0.8262 - recall: 0.8465 - val_loss: 0.4554 - val_precision: 0.8032 - val_recall: 0.8889 - lr: 0.0010\n",
            "Epoch 9/400\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4321 - precision: 0.8253 - recall: 0.8473 - val_loss: 0.4572 - val_precision: 0.8016 - val_recall: 0.8743 - lr: 0.0010\n",
            "Epoch 10/400\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4327 - precision: 0.8220 - recall: 0.8496 - val_loss: 0.4351 - val_precision: 0.8126 - val_recall: 0.8684 - lr: 0.0010\n",
            "Epoch 11/400\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4367 - precision: 0.8222 - recall: 0.8406 - val_loss: 0.4696 - val_precision: 0.7854 - val_recall: 0.8991 - lr: 0.0010\n",
            "Epoch 12/400\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4376 - precision: 0.8237 - recall: 0.8478 - val_loss: 0.4461 - val_precision: 0.7997 - val_recall: 0.8933 - lr: 0.0010\n",
            "Epoch 13/400\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4342 - precision: 0.8285 - recall: 0.8440 - val_loss: 0.4392 - val_precision: 0.8194 - val_recall: 0.8626 - lr: 0.0010\n",
            "Epoch 14/400\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4279 - precision: 0.8269 - recall: 0.8518 - val_loss: 0.4560 - val_precision: 0.7933 - val_recall: 0.8977 - lr: 0.0010\n",
            "Epoch 15/400\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4298 - precision: 0.8259 - recall: 0.8531 - val_loss: 0.4515 - val_precision: 0.8113 - val_recall: 0.8611 - lr: 0.0010\n",
            "Epoch 16/400\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.4297 - precision: 0.8273 - recall: 0.8446 - val_loss: 0.4327 - val_precision: 0.8348 - val_recall: 0.8275 - lr: 0.0010\n",
            "Epoch 17/400\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4358 - precision: 0.8203 - recall: 0.8436 - val_loss: 0.4530 - val_precision: 0.8104 - val_recall: 0.8626 - lr: 0.0010\n",
            "Epoch 18/400\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4337 - precision: 0.8227 - recall: 0.8508 - val_loss: 0.4459 - val_precision: 0.8148 - val_recall: 0.8553 - lr: 0.0010\n",
            "Epoch 19/400\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4270 - precision: 0.8289 - recall: 0.8507 - val_loss: 0.4505 - val_precision: 0.8027 - val_recall: 0.8801 - lr: 0.0010\n",
            "Epoch 20/400\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4263 - precision: 0.8262 - recall: 0.8524 - val_loss: 0.4442 - val_precision: 0.8195 - val_recall: 0.8494 - lr: 0.0010\n",
            "Epoch 21/400\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4270 - precision: 0.8299 - recall: 0.8500 - val_loss: 0.4475 - val_precision: 0.8099 - val_recall: 0.8596 - lr: 0.0010\n",
            "Epoch 22/400\n",
            "25/25 [==============================] - 1s 51ms/step - loss: 0.4271 - precision: 0.8256 - recall: 0.8512 - val_loss: 0.4418 - val_precision: 0.8067 - val_recall: 0.8480 - lr: 0.0010\n",
            "Epoch 23/400\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4325 - precision: 0.8254 - recall: 0.8518 - val_loss: 0.4410 - val_precision: 0.8133 - val_recall: 0.8596 - lr: 0.0010\n",
            "Epoch 24/400\n",
            "25/25 [==============================] - 1s 52ms/step - loss: 0.4311 - precision: 0.8314 - recall: 0.8425 - val_loss: 0.4609 - val_precision: 0.7995 - val_recall: 0.8977 - lr: 0.0010\n",
            "Epoch 25/400\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4248 - precision: 0.8283 - recall: 0.8492 - val_loss: 0.4461 - val_precision: 0.7937 - val_recall: 0.8889 - lr: 0.0010\n",
            "Epoch 26/400\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.4247 - precision: 0.8279 - recall: 0.8508 - val_loss: 0.4577 - val_precision: 0.7927 - val_recall: 0.8889 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e926ec0e590>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13473, 3840, 3)\n",
            "(13473,)\n",
            "Epoch 1/400\n",
            "24/24 [==============================] - 16s 112ms/step - loss: 0.4571 - precision: 0.8104 - recall: 0.8387 - val_loss: 0.4456 - val_precision: 0.7975 - val_recall: 0.8806 - lr: 0.0010\n",
            "Epoch 2/400\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4295 - precision: 0.8221 - recall: 0.8475 - val_loss: 0.4406 - val_precision: 0.8079 - val_recall: 0.8760 - lr: 0.0010\n",
            "Epoch 3/400\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4281 - precision: 0.8228 - recall: 0.8545 - val_loss: 0.4512 - val_precision: 0.8003 - val_recall: 0.8775 - lr: 0.0010\n",
            "Epoch 4/400\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4313 - precision: 0.8197 - recall: 0.8470 - val_loss: 0.4453 - val_precision: 0.8110 - val_recall: 0.8606 - lr: 0.0010\n",
            "Epoch 5/400\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4302 - precision: 0.8268 - recall: 0.8505 - val_loss: 0.4491 - val_precision: 0.7962 - val_recall: 0.8913 - lr: 0.0010\n",
            "Epoch 6/400\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4340 - precision: 0.8170 - recall: 0.8513 - val_loss: 0.4372 - val_precision: 0.8074 - val_recall: 0.8668 - lr: 0.0010\n",
            "Epoch 7/400\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4312 - precision: 0.8198 - recall: 0.8490 - val_loss: 0.4547 - val_precision: 0.7890 - val_recall: 0.8989 - lr: 0.0010\n",
            "Epoch 8/400\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4315 - precision: 0.8182 - recall: 0.8522 - val_loss: 0.4394 - val_precision: 0.8125 - val_recall: 0.8760 - lr: 0.0010\n",
            "Epoch 9/400\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4274 - precision: 0.8240 - recall: 0.8454 - val_loss: 0.4481 - val_precision: 0.7967 - val_recall: 0.8760 - lr: 0.0010\n",
            "Epoch 10/400\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4299 - precision: 0.8229 - recall: 0.8525 - val_loss: 0.4497 - val_precision: 0.7989 - val_recall: 0.8760 - lr: 0.0010\n",
            "Epoch 11/400\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4312 - precision: 0.8213 - recall: 0.8505 - val_loss: 0.4465 - val_precision: 0.8050 - val_recall: 0.8851 - lr: 0.0010\n",
            "Epoch 12/400\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4286 - precision: 0.8213 - recall: 0.8527 - val_loss: 0.4432 - val_precision: 0.8039 - val_recall: 0.8790 - lr: 0.0010\n",
            "Epoch 13/400\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4328 - precision: 0.8232 - recall: 0.8497 - val_loss: 0.4614 - val_precision: 0.7848 - val_recall: 0.8989 - lr: 0.0010\n",
            "Epoch 14/400\n",
            "24/24 [==============================] - 1s 53ms/step - loss: 0.4321 - precision: 0.8211 - recall: 0.8460 - val_loss: 0.4534 - val_precision: 0.7929 - val_recall: 0.8913 - lr: 0.0010\n",
            "Epoch 15/400\n",
            "24/24 [==============================] - 1s 52ms/step - loss: 0.4274 - precision: 0.8217 - recall: 0.8472 - val_loss: 0.4460 - val_precision: 0.8079 - val_recall: 0.8499 - lr: 0.0010\n",
            "Epoch 16/400\n",
            "24/24 [==============================] - 1s 54ms/step - loss: 0.4302 - precision: 0.8193 - recall: 0.8552 - val_loss: 0.4515 - val_precision: 0.8059 - val_recall: 0.8714 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e926ec0e590>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12966, 3840, 3)\n",
            "(12966,)\n",
            "Epoch 1/400\n",
            "23/23 [==============================] - 18s 117ms/step - loss: 0.4206 - precision: 0.8323 - recall: 0.8526 - val_loss: 0.4433 - val_precision: 0.8044 - val_recall: 0.8830 - lr: 0.0010\n",
            "Epoch 2/400\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4040 - precision: 0.8383 - recall: 0.8618 - val_loss: 0.4490 - val_precision: 0.8072 - val_recall: 0.8590 - lr: 0.0010\n",
            "Epoch 3/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4034 - precision: 0.8377 - recall: 0.8670 - val_loss: 0.4607 - val_precision: 0.7982 - val_recall: 0.8622 - lr: 0.0010\n",
            "Epoch 4/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4060 - precision: 0.8378 - recall: 0.8641 - val_loss: 0.4492 - val_precision: 0.8119 - val_recall: 0.8510 - lr: 0.0010\n",
            "Epoch 5/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4035 - precision: 0.8373 - recall: 0.8635 - val_loss: 0.4555 - val_precision: 0.8087 - val_recall: 0.8606 - lr: 0.0010\n",
            "Epoch 6/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4084 - precision: 0.8330 - recall: 0.8556 - val_loss: 0.4487 - val_precision: 0.8095 - val_recall: 0.8510 - lr: 0.0010\n",
            "Epoch 7/400\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4115 - precision: 0.8343 - recall: 0.8580 - val_loss: 0.4666 - val_precision: 0.7764 - val_recall: 0.8958 - lr: 0.0010\n",
            "Epoch 8/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4043 - precision: 0.8332 - recall: 0.8634 - val_loss: 0.4399 - val_precision: 0.8099 - val_recall: 0.8397 - lr: 0.0010\n",
            "Epoch 9/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4026 - precision: 0.8360 - recall: 0.8618 - val_loss: 0.4593 - val_precision: 0.7840 - val_recall: 0.8958 - lr: 0.0010\n",
            "Epoch 10/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4060 - precision: 0.8338 - recall: 0.8665 - val_loss: 0.4427 - val_precision: 0.8033 - val_recall: 0.8574 - lr: 0.0010\n",
            "Epoch 11/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4056 - precision: 0.8338 - recall: 0.8618 - val_loss: 0.4475 - val_precision: 0.8074 - val_recall: 0.8734 - lr: 0.0010\n",
            "Epoch 12/400\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4091 - precision: 0.8340 - recall: 0.8569 - val_loss: 0.4389 - val_precision: 0.8200 - val_recall: 0.8686 - lr: 0.0010\n",
            "Epoch 13/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4021 - precision: 0.8372 - recall: 0.8632 - val_loss: 0.4514 - val_precision: 0.7975 - val_recall: 0.9022 - lr: 0.0010\n",
            "Epoch 14/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4006 - precision: 0.8402 - recall: 0.8642 - val_loss: 0.4450 - val_precision: 0.8079 - val_recall: 0.8558 - lr: 0.0010\n",
            "Epoch 15/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4020 - precision: 0.8344 - recall: 0.8661 - val_loss: 0.4470 - val_precision: 0.8095 - val_recall: 0.8446 - lr: 0.0010\n",
            "Epoch 16/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.3989 - precision: 0.8374 - recall: 0.8618 - val_loss: 0.4489 - val_precision: 0.8085 - val_recall: 0.8798 - lr: 0.0010\n",
            "Epoch 17/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4007 - precision: 0.8388 - recall: 0.8623 - val_loss: 0.4530 - val_precision: 0.8035 - val_recall: 0.8718 - lr: 0.0010\n",
            "Epoch 18/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4019 - precision: 0.8348 - recall: 0.8637 - val_loss: 0.4466 - val_precision: 0.8041 - val_recall: 0.8750 - lr: 0.0010\n",
            "Epoch 19/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4042 - precision: 0.8338 - recall: 0.8637 - val_loss: 0.4522 - val_precision: 0.8103 - val_recall: 0.8349 - lr: 0.0010\n",
            "Epoch 20/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4016 - precision: 0.8401 - recall: 0.8608 - val_loss: 0.4437 - val_precision: 0.8068 - val_recall: 0.8702 - lr: 0.0010\n",
            "Epoch 21/400\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.3973 - precision: 0.8365 - recall: 0.8665 - val_loss: 0.4586 - val_precision: 0.7904 - val_recall: 0.8942 - lr: 0.0010\n",
            "Epoch 22/400\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.3943 - precision: 0.8399 - recall: 0.8687 - val_loss: 0.4502 - val_precision: 0.8071 - val_recall: 0.8718 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e926ec0e590>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12555, 3840, 3)\n",
            "(12555,)\n",
            "Epoch 1/400\n",
            "23/23 [==============================] - 16s 113ms/step - loss: 0.4495 - precision: 0.8072 - recall: 0.8447 - val_loss: 0.4493 - val_precision: 0.8122 - val_recall: 0.8621 - lr: 0.0010\n",
            "Epoch 2/400\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4346 - precision: 0.8161 - recall: 0.8417 - val_loss: 0.4572 - val_precision: 0.7927 - val_recall: 0.8704 - lr: 0.0010\n",
            "Epoch 3/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4346 - precision: 0.8187 - recall: 0.8538 - val_loss: 0.4587 - val_precision: 0.7905 - val_recall: 0.8837 - lr: 0.0010\n",
            "Epoch 4/400\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4284 - precision: 0.8185 - recall: 0.8522 - val_loss: 0.4420 - val_precision: 0.8226 - val_recall: 0.8090 - lr: 0.0010\n",
            "Epoch 5/400\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4307 - precision: 0.8194 - recall: 0.8443 - val_loss: 0.4426 - val_precision: 0.8112 - val_recall: 0.8422 - lr: 0.0010\n",
            "Epoch 6/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4253 - precision: 0.8203 - recall: 0.8484 - val_loss: 0.4605 - val_precision: 0.7885 - val_recall: 0.8854 - lr: 0.0010\n",
            "Epoch 7/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4285 - precision: 0.8228 - recall: 0.8477 - val_loss: 0.4838 - val_precision: 0.7460 - val_recall: 0.9219 - lr: 0.0010\n",
            "Epoch 8/400\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4362 - precision: 0.8128 - recall: 0.8554 - val_loss: 0.4532 - val_precision: 0.8128 - val_recall: 0.8007 - lr: 0.0010\n",
            "Epoch 9/400\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4326 - precision: 0.8241 - recall: 0.8386 - val_loss: 0.4413 - val_precision: 0.8264 - val_recall: 0.8306 - lr: 0.0010\n",
            "Epoch 10/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4267 - precision: 0.8250 - recall: 0.8498 - val_loss: 0.4661 - val_precision: 0.7779 - val_recall: 0.8904 - lr: 0.0010\n",
            "Epoch 11/400\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4336 - precision: 0.8199 - recall: 0.8527 - val_loss: 0.4476 - val_precision: 0.8045 - val_recall: 0.8821 - lr: 0.0010\n",
            "Epoch 12/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4288 - precision: 0.8215 - recall: 0.8541 - val_loss: 0.4576 - val_precision: 0.8240 - val_recall: 0.8090 - lr: 0.0010\n",
            "Epoch 13/400\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4321 - precision: 0.8238 - recall: 0.8392 - val_loss: 0.4626 - val_precision: 0.7786 - val_recall: 0.8937 - lr: 0.0010\n",
            "Epoch 14/400\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.4289 - precision: 0.8211 - recall: 0.8490 - val_loss: 0.4542 - val_precision: 0.7818 - val_recall: 0.8870 - lr: 0.0010\n",
            "Epoch 15/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4281 - precision: 0.8189 - recall: 0.8488 - val_loss: 0.4515 - val_precision: 0.8342 - val_recall: 0.8106 - lr: 0.0010\n",
            "Epoch 16/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4336 - precision: 0.8177 - recall: 0.8498 - val_loss: 0.4441 - val_precision: 0.8103 - val_recall: 0.8372 - lr: 0.0010\n",
            "Epoch 17/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4342 - precision: 0.8249 - recall: 0.8397 - val_loss: 0.4447 - val_precision: 0.7871 - val_recall: 0.8721 - lr: 0.0010\n",
            "Epoch 18/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4415 - precision: 0.8085 - recall: 0.8518 - val_loss: 0.4540 - val_precision: 0.8009 - val_recall: 0.8754 - lr: 0.0010\n",
            "Epoch 19/400\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4356 - precision: 0.8153 - recall: 0.8520 - val_loss: 0.4425 - val_precision: 0.7943 - val_recall: 0.8721 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e926ec0e590>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13001, 3840, 3)\n",
            "(13001,)\n",
            "Epoch 1/400\n",
            "23/23 [==============================] - 19s 116ms/step - loss: 0.4294 - precision: 0.8176 - recall: 0.8480 - val_loss: 0.3933 - val_precision: 0.8600 - val_recall: 0.8600 - lr: 0.0010\n",
            "Epoch 2/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4228 - precision: 0.8237 - recall: 0.8578 - val_loss: 0.4050 - val_precision: 0.8549 - val_recall: 0.8523 - lr: 0.0010\n",
            "Epoch 3/400\n",
            "23/23 [==============================] - 1s 54ms/step - loss: 0.4215 - precision: 0.8241 - recall: 0.8568 - val_loss: 0.3914 - val_precision: 0.8558 - val_recall: 0.8585 - lr: 0.0010\n",
            "Epoch 4/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4213 - precision: 0.8218 - recall: 0.8596 - val_loss: 0.3999 - val_precision: 0.8654 - val_recall: 0.8508 - lr: 0.0010\n",
            "Epoch 5/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4197 - precision: 0.8256 - recall: 0.8504 - val_loss: 0.4077 - val_precision: 0.8712 - val_recall: 0.8323 - lr: 0.0010\n",
            "Epoch 6/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4197 - precision: 0.8253 - recall: 0.8558 - val_loss: 0.4022 - val_precision: 0.8704 - val_recall: 0.8369 - lr: 0.0010\n",
            "Epoch 7/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4197 - precision: 0.8243 - recall: 0.8547 - val_loss: 0.3948 - val_precision: 0.8602 - val_recall: 0.8523 - lr: 0.0010\n",
            "Epoch 8/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4199 - precision: 0.8212 - recall: 0.8592 - val_loss: 0.3967 - val_precision: 0.8574 - val_recall: 0.8508 - lr: 0.0010\n",
            "Epoch 9/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4201 - precision: 0.8251 - recall: 0.8556 - val_loss: 0.3968 - val_precision: 0.8519 - val_recall: 0.8585 - lr: 0.0010\n",
            "Epoch 10/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4177 - precision: 0.8242 - recall: 0.8568 - val_loss: 0.4214 - val_precision: 0.8666 - val_recall: 0.8092 - lr: 0.0010\n",
            "Epoch 11/400\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.4230 - precision: 0.8240 - recall: 0.8556 - val_loss: 0.4046 - val_precision: 0.8567 - val_recall: 0.8462 - lr: 0.0010\n",
            "Epoch 12/400\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.4168 - precision: 0.8231 - recall: 0.8511 - val_loss: 0.3956 - val_precision: 0.8341 - val_recall: 0.8815 - lr: 0.0010\n",
            "Epoch 13/400\n",
            "23/23 [==============================] - 1s 55ms/step - loss: 0.4205 - precision: 0.8195 - recall: 0.8556 - val_loss: 0.4005 - val_precision: 0.8684 - val_recall: 0.8323 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7e926ec0e590>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training complete\n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "# sig_dict_chat = {\n",
        "#     \"EOG\": [0, 1],\n",
        "#     \"EEG\": [4, 5],\n",
        "#     \"ECG\": [15,16],\n",
        "#     \"Resp\": [9, 10],\n",
        "#     \"SPO2\": [13],\n",
        "#     \"CO2\": [14],\n",
        "# }\n",
        "\n",
        "# channel_list_chat = [\n",
        "#     [\"ECG\", \"SPO2\"]\n",
        "# ]\n",
        "\n",
        "# for ch in channel_list_chat:\n",
        "#     chs = []\n",
        "#     chstr = \"\"\n",
        "#     for name in ch:\n",
        "#         chstr += name\n",
        "#         chs = chs + sig_dict_chat[name]\n",
        "#     print(chstr, chs)\n",
        "#     config = {\n",
        "#         \"data_path\": data_path + 'chat_',\n",
        "#         \"model_path\": model_path,\n",
        "#         \"model_name\": \"model_400epochs_\"+ chstr,\n",
        "#         \"regression\": False,\n",
        "#         \"epochs\": 400, #changed to 400\n",
        "#         \"channels\": chs,\n",
        "#     }\n",
        "#     train(config, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCZ1wTTCTQAb",
        "outputId": "73fc695b-e22f-4251-c7a2-039364154e9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3506, 3840, 3)\n",
            "test starting\n",
            "78/78 [==============================] - 1s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95/95 [==============================] - 2s 9ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 2s 9ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124/124 [==============================] - 2s 8ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 2s 8ms/step\n",
            "=========================================================================== \n",
            "[83.34680679062248, 85.72841133816743, 79.8079638520192, 84.59008097165992, 83.3998859098688] \n",
            "[85.99118942731278, 85.3315472203617, 77.37113402061856, 85.38135593220339, 80.13662637940094] \n",
            "[79.41415785191212, 85.61827956989248, 84.46820483961733, 82.87917737789203, 88.20127241179873] \n",
            "[87.2289156626506, 85.83441138421733, 75.11337868480726, 86.24813153961136, 78.7281935846933] \n",
            "[82.57191201353638, 85.47467292854746, 80.76405703524348, 84.11166188364206, 83.97577092511014] \n",
            "[91.42830067217609, 92.24194591662148, 87.49692148478225, 91.84791532976485, 90.37879751975065] \n",
            "[89.75743349699317, 90.97601461985424, 85.92852064797634, 90.54725734577242, 88.91609773907493] \n",
            "Accuracy: 83.37 -+ 1.987 \n",
            "Precision: 82.84 -+ 3.459 \n",
            "Recall: 84.12 -+ 2.923 \n",
            "Specifity: 82.63 -+ 4.821 \n",
            "F1: 83.38 -+ 1.598 \n",
            "AUROC: 90.68 -+ 1.708 \n",
            "AUPRC: 89.23 -+ 1.792 \n",
            "$ 83.4 \\pm 2.0$& $82.8 \\pm 3.5$& $84.1 \\pm 2.9$& $83.4 \\pm 1.6$& $90.7 \\pm 1.7$& \n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "sig_dict_chat = {\n",
        "    \"EOG\": [0, 1],\n",
        "    \"EEG\": [4, 5],\n",
        "    \"ECG\": [15,16],\n",
        "    \"Resp\": [9, 10],\n",
        "    \"SPO2\": [13],\n",
        "    \"CO2\": [14],\n",
        "}\n",
        "\n",
        "channel_list_chat = [\n",
        "    [\"ECG\", \"SPO2\"],\n",
        "]\n",
        "\n",
        "for ch in channel_list_chat:\n",
        "    chs = []\n",
        "    chstr = \"\"\n",
        "    for name in ch:\n",
        "        chstr += name\n",
        "        chs = chs + sig_dict_chat[name]\n",
        "    print(chstr, chs)\n",
        "    config = {\n",
        "        \"data_path\": data_path + 'chat_',\n",
        "        \"model_path\": model_path,\n",
        "        \"model_name\": \"model_400epochs_\"+ chstr,\n",
        "        \"channels\": chs,\n",
        "    }\n",
        "    test(config, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEGoyAnI9TDd"
      },
      "source": [
        "###Discussion of epochs experiment\n",
        "\n",
        "The table below summarizes how increasing the number of epochs impacts model performance. Bolded are the highest values within each column. As you can see, not all metrics improve as the number of epochs increases.\n",
        "\n",
        "The authors had also done similar studies and chose 200 as the best number of epochs. In our case, we choose 100 epochs to proceed with further in the notebook as it actually shows better performance than 200 epochs and trains in less time.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=15YFd2MK6_F6UQ4r7hMt464XtgpycJXVE\"/>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gDPd1INTivc"
      },
      "source": [
        "##Ablation Study\n",
        "We wanted to see how changing number of transformer layer affects the model. The author used 5 layers, but we will be testing 1, 3, and 10 layers."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 layer"
      ],
      "metadata": {
        "id": "L6JdFIywtEYs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXtJjH5xXuav"
      },
      "outputs": [],
      "source": [
        "input_shape = (128 * 30, 3)\n",
        "num_patches = 30\n",
        "\n",
        "transformer_layers = 1 #changed to single layer\n",
        "num_heads = 4\n",
        "transformer_units = 32\n",
        "reg = False\n",
        "drop_out = 0.25\n",
        "l2_weight = 0.001\n",
        "\n",
        "model = create_transformer_model(input_shape, num_patches,\n",
        "                                projection_dim=transformer_units, transformer_layers=transformer_layers,\n",
        "                                num_heads=num_heads,\n",
        "                                transformer_units = [transformer_units*2, transformer_units],\n",
        "                                mlp_head_units=[256, 128],\n",
        "                                num_classes=1, drop_out=drop_out, reg=reg, l2_weight=l2_weight, demographic=False)\n",
        "loss_func = BinaryCrossentropy()\n",
        "optimizer = \"adam\"\n",
        "\n",
        "#Prevent over-fitting on same fold.\n",
        "def lr_schedule(epoch, lr):\n",
        "\n",
        "    if epoch > 50 and (epoch - 1) % 5 == 0:\n",
        "        lr *= 0.5\n",
        "\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GxOo0C0aj_u",
        "outputId": "6a84eb79-50f7-4de2-c1d6-bbb8e25d66c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "5\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n",
            "(3506, 3840, 3)\n",
            "training\n",
            "(14033, 3840, 3)\n",
            "(14033,)\n",
            "Epoch 1/100\n",
            "25/25 [==============================] - 6s 47ms/step - loss: 0.6253 - precision_1: 0.7492 - recall_1: 0.8135 - val_loss: 0.6407 - val_precision_1: 0.6987 - val_recall_1: 0.8687 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.5950 - precision_1: 0.7686 - recall_1: 0.8146 - val_loss: 0.5914 - val_precision_1: 0.7564 - val_recall_1: 0.8343 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.5815 - precision_1: 0.7783 - recall_1: 0.8061 - val_loss: 0.5924 - val_precision_1: 0.7379 - val_recall_1: 0.8448 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 0.5673 - precision_1: 0.7865 - recall_1: 0.8044 - val_loss: 0.5829 - val_precision_1: 0.7474 - val_recall_1: 0.8478 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.5588 - precision_1: 0.7834 - recall_1: 0.8148 - val_loss: 0.5704 - val_precision_1: 0.7477 - val_recall_1: 0.8403 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.5544 - precision_1: 0.7869 - recall_1: 0.8039 - val_loss: 0.5686 - val_precision_1: 0.7082 - val_recall_1: 0.8910 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.5419 - precision_1: 0.7865 - recall_1: 0.8215 - val_loss: 0.5384 - val_precision_1: 0.7926 - val_recall_1: 0.7985 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.5353 - precision_1: 0.7888 - recall_1: 0.8178 - val_loss: 0.5445 - val_precision_1: 0.7526 - val_recall_1: 0.8493 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.5255 - precision_1: 0.7912 - recall_1: 0.8188 - val_loss: 0.5277 - val_precision_1: 0.7630 - val_recall_1: 0.8746 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.5192 - precision_1: 0.7963 - recall_1: 0.8292 - val_loss: 0.5188 - val_precision_1: 0.7750 - val_recall_1: 0.8433 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.5149 - precision_1: 0.7938 - recall_1: 0.8272 - val_loss: 0.5134 - val_precision_1: 0.7815 - val_recall_1: 0.8433 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.5113 - precision_1: 0.7955 - recall_1: 0.8272 - val_loss: 0.5183 - val_precision_1: 0.7683 - val_recall_1: 0.8612 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.5104 - precision_1: 0.7944 - recall_1: 0.8314 - val_loss: 0.5223 - val_precision_1: 0.7406 - val_recall_1: 0.8866 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.5077 - precision_1: 0.7949 - recall_1: 0.8308 - val_loss: 0.5086 - val_precision_1: 0.7719 - val_recall_1: 0.8433 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.5030 - precision_1: 0.8025 - recall_1: 0.8308 - val_loss: 0.5098 - val_precision_1: 0.7748 - val_recall_1: 0.8627 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.5024 - precision_1: 0.7979 - recall_1: 0.8317 - val_loss: 0.5178 - val_precision_1: 0.7558 - val_recall_1: 0.8687 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4947 - precision_1: 0.7976 - recall_1: 0.8404 - val_loss: 0.5152 - val_precision_1: 0.7557 - val_recall_1: 0.8910 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.4897 - precision_1: 0.8038 - recall_1: 0.8324 - val_loss: 0.4968 - val_precision_1: 0.7845 - val_recall_1: 0.8478 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.4871 - precision_1: 0.8031 - recall_1: 0.8370 - val_loss: 0.4968 - val_precision_1: 0.7766 - val_recall_1: 0.8507 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4887 - precision_1: 0.8049 - recall_1: 0.8322 - val_loss: 0.4866 - val_precision_1: 0.7793 - val_recall_1: 0.8537 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4909 - precision_1: 0.7999 - recall_1: 0.8385 - val_loss: 0.4998 - val_precision_1: 0.7728 - val_recall_1: 0.8478 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4891 - precision_1: 0.8046 - recall_1: 0.8367 - val_loss: 0.4985 - val_precision_1: 0.7577 - val_recall_1: 0.8821 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4804 - precision_1: 0.8017 - recall_1: 0.8404 - val_loss: 0.4869 - val_precision_1: 0.7880 - val_recall_1: 0.8433 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4808 - precision_1: 0.8033 - recall_1: 0.8370 - val_loss: 0.5042 - val_precision_1: 0.7438 - val_recall_1: 0.9015 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4787 - precision_1: 0.8008 - recall_1: 0.8437 - val_loss: 0.4763 - val_precision_1: 0.8111 - val_recall_1: 0.8075 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.4837 - precision_1: 0.8026 - recall_1: 0.8377 - val_loss: 0.4751 - val_precision_1: 0.7819 - val_recall_1: 0.8507 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.4781 - precision_1: 0.8042 - recall_1: 0.8364 - val_loss: 0.4765 - val_precision_1: 0.7781 - val_recall_1: 0.8687 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.4748 - precision_1: 0.8105 - recall_1: 0.8359 - val_loss: 0.4965 - val_precision_1: 0.7463 - val_recall_1: 0.9045 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.4821 - precision_1: 0.7993 - recall_1: 0.8457 - val_loss: 0.4718 - val_precision_1: 0.7948 - val_recall_1: 0.8269 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.4757 - precision_1: 0.8067 - recall_1: 0.8404 - val_loss: 0.4684 - val_precision_1: 0.7939 - val_recall_1: 0.8507 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.4702 - precision_1: 0.8074 - recall_1: 0.8396 - val_loss: 0.4765 - val_precision_1: 0.7944 - val_recall_1: 0.8478 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.4726 - precision_1: 0.8028 - recall_1: 0.8436 - val_loss: 0.4745 - val_precision_1: 0.7949 - val_recall_1: 0.8388 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4647 - precision_1: 0.8101 - recall_1: 0.8381 - val_loss: 0.4661 - val_precision_1: 0.8220 - val_recall_1: 0.8134 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4649 - precision_1: 0.8091 - recall_1: 0.8413 - val_loss: 0.4546 - val_precision_1: 0.8104 - val_recall_1: 0.8358 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4643 - precision_1: 0.8094 - recall_1: 0.8433 - val_loss: 0.4655 - val_precision_1: 0.7871 - val_recall_1: 0.8716 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4614 - precision_1: 0.8145 - recall_1: 0.8444 - val_loss: 0.4570 - val_precision_1: 0.7937 - val_recall_1: 0.8672 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4635 - precision_1: 0.8096 - recall_1: 0.8420 - val_loss: 0.4602 - val_precision_1: 0.7962 - val_recall_1: 0.8687 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.4648 - precision_1: 0.8113 - recall_1: 0.8413 - val_loss: 0.4554 - val_precision_1: 0.8201 - val_recall_1: 0.8299 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.4615 - precision_1: 0.8147 - recall_1: 0.8441 - val_loss: 0.4589 - val_precision_1: 0.8071 - val_recall_1: 0.8433 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4603 - precision_1: 0.8110 - recall_1: 0.8417 - val_loss: 0.4670 - val_precision_1: 0.8331 - val_recall_1: 0.7821 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4604 - precision_1: 0.8120 - recall_1: 0.8429 - val_loss: 0.4721 - val_precision_1: 0.7566 - val_recall_1: 0.9045 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4577 - precision_1: 0.8110 - recall_1: 0.8445 - val_loss: 0.4576 - val_precision_1: 0.8161 - val_recall_1: 0.8015 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4567 - precision_1: 0.8121 - recall_1: 0.8433 - val_loss: 0.4600 - val_precision_1: 0.8183 - val_recall_1: 0.8134 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.4620 - precision_1: 0.8114 - recall_1: 0.8423 - val_loss: 0.4572 - val_precision_1: 0.8175 - val_recall_1: 0.8090 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x78443f424640>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13473, 3840, 3)\n",
            "(13473,)\n",
            "Epoch 1/100\n",
            "24/24 [==============================] - 6s 57ms/step - loss: 0.4816 - precision: 0.8027 - recall: 0.8356 - val_loss: 0.4862 - val_precision: 0.7784 - val_recall: 0.8780 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4651 - precision: 0.8063 - recall: 0.8436 - val_loss: 0.4956 - val_precision: 0.8095 - val_recall: 0.7997 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.4694 - precision: 0.8066 - recall: 0.8398 - val_loss: 0.4866 - val_precision: 0.7997 - val_recall: 0.8358 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4651 - precision: 0.8074 - recall: 0.8479 - val_loss: 0.4823 - val_precision: 0.7942 - val_recall: 0.8599 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4600 - precision: 0.8074 - recall: 0.8431 - val_loss: 0.4795 - val_precision: 0.8062 - val_recall: 0.8268 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.4613 - precision: 0.8133 - recall: 0.8354 - val_loss: 0.4935 - val_precision: 0.7865 - val_recall: 0.8931 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4669 - precision: 0.8096 - recall: 0.8433 - val_loss: 0.4923 - val_precision: 0.7851 - val_recall: 0.8916 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4603 - precision: 0.8096 - recall: 0.8472 - val_loss: 0.4900 - val_precision: 0.8052 - val_recall: 0.7967 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4644 - precision: 0.8073 - recall: 0.8399 - val_loss: 0.4862 - val_precision: 0.8104 - val_recall: 0.7982 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4691 - precision: 0.8066 - recall: 0.8293 - val_loss: 0.5042 - val_precision: 0.7957 - val_recall: 0.8389 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.4650 - precision: 0.8051 - recall: 0.8452 - val_loss: 0.4805 - val_precision: 0.8068 - val_recall: 0.8178 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.4597 - precision: 0.8097 - recall: 0.8424 - val_loss: 0.4741 - val_precision: 0.7947 - val_recall: 0.8569 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4576 - precision: 0.8155 - recall: 0.8426 - val_loss: 0.4764 - val_precision: 0.7969 - val_recall: 0.8449 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4520 - precision: 0.8153 - recall: 0.8447 - val_loss: 0.4795 - val_precision: 0.7844 - val_recall: 0.8660 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4548 - precision: 0.8121 - recall: 0.8477 - val_loss: 0.4774 - val_precision: 0.8046 - val_recall: 0.8373 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4506 - precision: 0.8110 - recall: 0.8504 - val_loss: 0.4794 - val_precision: 0.8119 - val_recall: 0.8253 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4547 - precision: 0.8102 - recall: 0.8351 - val_loss: 0.4753 - val_precision: 0.8090 - val_recall: 0.8358 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.4601 - precision: 0.8048 - recall: 0.8484 - val_loss: 0.4744 - val_precision: 0.8020 - val_recall: 0.8419 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.4580 - precision: 0.8093 - recall: 0.8403 - val_loss: 0.4829 - val_precision: 0.7971 - val_recall: 0.8404 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 1s 23ms/step - loss: 0.4577 - precision: 0.8014 - recall: 0.8446 - val_loss: 0.4834 - val_precision: 0.8137 - val_recall: 0.7892 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4568 - precision: 0.8102 - recall: 0.8423 - val_loss: 0.4791 - val_precision: 0.7910 - val_recall: 0.8720 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4514 - precision: 0.8131 - recall: 0.8456 - val_loss: 0.4727 - val_precision: 0.7938 - val_recall: 0.8810 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.4510 - precision: 0.8122 - recall: 0.8477 - val_loss: 0.4758 - val_precision: 0.8157 - val_recall: 0.8133 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.4516 - precision: 0.8109 - recall: 0.8462 - val_loss: 0.4723 - val_precision: 0.8130 - val_recall: 0.8313 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 1s 26ms/step - loss: 0.4494 - precision: 0.8150 - recall: 0.8431 - val_loss: 0.4837 - val_precision: 0.7766 - val_recall: 0.8795 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4446 - precision: 0.8149 - recall: 0.8479 - val_loss: 0.4795 - val_precision: 0.8062 - val_recall: 0.8268 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.4520 - precision: 0.8154 - recall: 0.8423 - val_loss: 0.4832 - val_precision: 0.7850 - val_recall: 0.8855 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4531 - precision: 0.8072 - recall: 0.8492 - val_loss: 0.4781 - val_precision: 0.8033 - val_recall: 0.8178 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.4499 - precision: 0.8120 - recall: 0.8398 - val_loss: 0.4765 - val_precision: 0.8120 - val_recall: 0.8133 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4445 - precision: 0.8131 - recall: 0.8456 - val_loss: 0.4751 - val_precision: 0.8083 - val_recall: 0.8253 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.4454 - precision: 0.8156 - recall: 0.8454 - val_loss: 0.4857 - val_precision: 0.7935 - val_recall: 0.8509 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.4510 - precision: 0.8071 - recall: 0.8431 - val_loss: 0.4807 - val_precision: 0.8059 - val_recall: 0.8193 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 1s 24ms/step - loss: 0.4510 - precision: 0.8136 - recall: 0.8481 - val_loss: 0.4760 - val_precision: 0.8023 - val_recall: 0.8373 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 1s 25ms/step - loss: 0.4438 - precision: 0.8142 - recall: 0.8486 - val_loss: 0.4802 - val_precision: 0.8196 - val_recall: 0.7801 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x78443f424640>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12966, 3840, 3)\n",
            "(12966,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 6s 60ms/step - loss: 0.4411 - precision: 0.8226 - recall: 0.8513 - val_loss: 0.4819 - val_precision: 0.7776 - val_recall: 0.8756 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.4295 - precision: 0.8285 - recall: 0.8568 - val_loss: 0.4913 - val_precision: 0.7633 - val_recall: 0.8835 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4274 - precision: 0.8270 - recall: 0.8562 - val_loss: 0.4747 - val_precision: 0.7872 - val_recall: 0.8740 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4225 - precision: 0.8331 - recall: 0.8532 - val_loss: 0.4914 - val_precision: 0.7457 - val_recall: 0.8961 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4260 - precision: 0.8250 - recall: 0.8607 - val_loss: 0.4716 - val_precision: 0.7923 - val_recall: 0.8472 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4212 - precision: 0.8310 - recall: 0.8601 - val_loss: 0.4782 - val_precision: 0.7812 - val_recall: 0.8661 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4235 - precision: 0.8277 - recall: 0.8562 - val_loss: 0.4839 - val_precision: 0.7973 - val_recall: 0.8488 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4267 - precision: 0.8267 - recall: 0.8527 - val_loss: 0.4850 - val_precision: 0.7964 - val_recall: 0.8378 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4204 - precision: 0.8316 - recall: 0.8586 - val_loss: 0.4778 - val_precision: 0.8150 - val_recall: 0.8047 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4185 - precision: 0.8321 - recall: 0.8603 - val_loss: 0.4747 - val_precision: 0.8019 - val_recall: 0.8157 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4225 - precision: 0.8304 - recall: 0.8541 - val_loss: 0.4946 - val_precision: 0.7577 - val_recall: 0.8866 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4266 - precision: 0.8249 - recall: 0.8562 - val_loss: 0.4824 - val_precision: 0.7857 - val_recall: 0.8661 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4265 - precision: 0.8283 - recall: 0.8516 - val_loss: 0.4883 - val_precision: 0.7688 - val_recall: 0.9008 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4202 - precision: 0.8336 - recall: 0.8582 - val_loss: 0.4908 - val_precision: 0.7530 - val_recall: 0.9024 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4179 - precision: 0.8302 - recall: 0.8603 - val_loss: 0.4792 - val_precision: 0.8096 - val_recall: 0.8236 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x78443f424640>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12555, 3840, 3)\n",
            "(12555,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 6s 59ms/step - loss: 0.4972 - precision: 0.7883 - recall: 0.8264 - val_loss: 0.4909 - val_precision: 0.7804 - val_recall: 0.8567 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4641 - precision: 0.7997 - recall: 0.8390 - val_loss: 0.4707 - val_precision: 0.7881 - val_recall: 0.8599 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4529 - precision: 0.8082 - recall: 0.8492 - val_loss: 0.4771 - val_precision: 0.8213 - val_recall: 0.7785 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4547 - precision: 0.8124 - recall: 0.8408 - val_loss: 0.4791 - val_precision: 0.7786 - val_recall: 0.8990 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4548 - precision: 0.8095 - recall: 0.8454 - val_loss: 0.4886 - val_precision: 0.7685 - val_recall: 0.8974 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4534 - precision: 0.8083 - recall: 0.8435 - val_loss: 0.4734 - val_precision: 0.7903 - val_recall: 0.8534 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4583 - precision: 0.8012 - recall: 0.8510 - val_loss: 0.4800 - val_precision: 0.8114 - val_recall: 0.7638 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4542 - precision: 0.8150 - recall: 0.8410 - val_loss: 0.4668 - val_precision: 0.8021 - val_recall: 0.8518 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4520 - precision: 0.8104 - recall: 0.8404 - val_loss: 0.4683 - val_precision: 0.8089 - val_recall: 0.8274 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.4556 - precision: 0.8083 - recall: 0.8367 - val_loss: 0.4704 - val_precision: 0.8019 - val_recall: 0.8176 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.4502 - precision: 0.8149 - recall: 0.8451 - val_loss: 0.4667 - val_precision: 0.8088 - val_recall: 0.8127 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4550 - precision: 0.8137 - recall: 0.8394 - val_loss: 0.4718 - val_precision: 0.7925 - val_recall: 0.8583 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4535 - precision: 0.8127 - recall: 0.8431 - val_loss: 0.4740 - val_precision: 0.7745 - val_recall: 0.8893 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.4492 - precision: 0.8189 - recall: 0.8401 - val_loss: 0.4677 - val_precision: 0.7824 - val_recall: 0.8550 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4547 - precision: 0.8107 - recall: 0.8465 - val_loss: 0.4722 - val_precision: 0.7837 - val_recall: 0.8795 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4491 - precision: 0.8123 - recall: 0.8449 - val_loss: 0.4639 - val_precision: 0.8116 - val_recall: 0.8208 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4504 - precision: 0.8170 - recall: 0.8451 - val_loss: 0.4787 - val_precision: 0.7706 - val_recall: 0.8974 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4509 - precision: 0.8122 - recall: 0.8452 - val_loss: 0.4787 - val_precision: 0.7618 - val_recall: 0.8958 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4468 - precision: 0.8146 - recall: 0.8474 - val_loss: 0.4885 - val_precision: 0.8182 - val_recall: 0.7476 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4513 - precision: 0.8164 - recall: 0.8442 - val_loss: 0.4707 - val_precision: 0.8167 - val_recall: 0.7980 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4457 - precision: 0.8152 - recall: 0.8495 - val_loss: 0.4600 - val_precision: 0.8031 - val_recall: 0.8502 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4478 - precision: 0.8144 - recall: 0.8428 - val_loss: 0.4663 - val_precision: 0.8031 - val_recall: 0.8436 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4476 - precision: 0.8124 - recall: 0.8476 - val_loss: 0.4653 - val_precision: 0.8116 - val_recall: 0.8208 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4426 - precision: 0.8191 - recall: 0.8476 - val_loss: 0.4682 - val_precision: 0.8110 - val_recall: 0.7899 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4685 - precision: 0.8067 - recall: 0.8256 - val_loss: 0.4713 - val_precision: 0.7822 - val_recall: 0.8713 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4473 - precision: 0.8123 - recall: 0.8479 - val_loss: 0.4644 - val_precision: 0.7997 - val_recall: 0.8388 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4438 - precision: 0.8183 - recall: 0.8440 - val_loss: 0.4692 - val_precision: 0.8050 - val_recall: 0.8469 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4467 - precision: 0.8133 - recall: 0.8458 - val_loss: 0.4695 - val_precision: 0.7783 - val_recall: 0.8746 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4522 - precision: 0.8093 - recall: 0.8388 - val_loss: 0.4773 - val_precision: 0.7692 - val_recall: 0.8958 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4486 - precision: 0.8148 - recall: 0.8501 - val_loss: 0.4642 - val_precision: 0.7862 - val_recall: 0.8746 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.4390 - precision: 0.8206 - recall: 0.8517 - val_loss: 0.4731 - val_precision: 0.8171 - val_recall: 0.8078 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x78443f424640>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13001, 3840, 3)\n",
            "(13001,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 6s 59ms/step - loss: 0.4603 - precision: 0.8047 - recall: 0.8492 - val_loss: 0.4242 - val_precision: 0.8531 - val_recall: 0.7896 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4421 - precision: 0.8201 - recall: 0.8481 - val_loss: 0.4082 - val_precision: 0.8586 - val_recall: 0.8058 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4389 - precision: 0.8165 - recall: 0.8509 - val_loss: 0.4092 - val_precision: 0.8562 - val_recall: 0.8285 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4380 - precision: 0.8225 - recall: 0.8500 - val_loss: 0.4032 - val_precision: 0.8326 - val_recall: 0.8689 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4412 - precision: 0.8191 - recall: 0.8497 - val_loss: 0.4055 - val_precision: 0.8525 - val_recall: 0.8511 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4386 - precision: 0.8146 - recall: 0.8531 - val_loss: 0.4027 - val_precision: 0.8395 - val_recall: 0.8382 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.4422 - precision: 0.8166 - recall: 0.8485 - val_loss: 0.4124 - val_precision: 0.8512 - val_recall: 0.8236 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4437 - precision: 0.8149 - recall: 0.8466 - val_loss: 0.4435 - val_precision: 0.8691 - val_recall: 0.7411 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4444 - precision: 0.8189 - recall: 0.8474 - val_loss: 0.4111 - val_precision: 0.8584 - val_recall: 0.8139 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4391 - precision: 0.8183 - recall: 0.8540 - val_loss: 0.4185 - val_precision: 0.8648 - val_recall: 0.7864 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4359 - precision: 0.8245 - recall: 0.8555 - val_loss: 0.4210 - val_precision: 0.8699 - val_recall: 0.7896 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4364 - precision: 0.8206 - recall: 0.8487 - val_loss: 0.4032 - val_precision: 0.8371 - val_recall: 0.8479 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4352 - precision: 0.8229 - recall: 0.8483 - val_loss: 0.4058 - val_precision: 0.8433 - val_recall: 0.8447 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4342 - precision: 0.8201 - recall: 0.8529 - val_loss: 0.3987 - val_precision: 0.8489 - val_recall: 0.8544 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.4337 - precision: 0.8179 - recall: 0.8516 - val_loss: 0.4023 - val_precision: 0.8339 - val_recall: 0.8608 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.4372 - precision: 0.8209 - recall: 0.8512 - val_loss: 0.4124 - val_precision: 0.8534 - val_recall: 0.8382 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4353 - precision: 0.8167 - recall: 0.8548 - val_loss: 0.4078 - val_precision: 0.8608 - val_recall: 0.8204 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4345 - precision: 0.8233 - recall: 0.8509 - val_loss: 0.4059 - val_precision: 0.8529 - val_recall: 0.8350 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4321 - precision: 0.8205 - recall: 0.8514 - val_loss: 0.4052 - val_precision: 0.8307 - val_recall: 0.8576 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4310 - precision: 0.8225 - recall: 0.8528 - val_loss: 0.4131 - val_precision: 0.8676 - val_recall: 0.8058 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.4335 - precision: 0.8215 - recall: 0.8531 - val_loss: 0.4142 - val_precision: 0.8622 - val_recall: 0.7896 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 25ms/step - loss: 0.4331 - precision: 0.8238 - recall: 0.8504 - val_loss: 0.4156 - val_precision: 0.8717 - val_recall: 0.8026 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 26ms/step - loss: 0.4334 - precision: 0.8207 - recall: 0.8531 - val_loss: 0.4178 - val_precision: 0.8683 - val_recall: 0.7896 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 1s 27ms/step - loss: 0.4399 - precision: 0.8182 - recall: 0.8476 - val_loss: 0.4185 - val_precision: 0.8451 - val_recall: 0.8301 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x78443f424640>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training complete\n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "# sig_dict_chat = {\n",
        "#     \"EOG\": [0, 1],\n",
        "#     \"EEG\": [4, 5],\n",
        "#     \"ECG\": [15,16],\n",
        "#     \"Resp\": [9, 10],\n",
        "#     \"SPO2\": [13],\n",
        "#     \"CO2\": [14],\n",
        "# }\n",
        "\n",
        "# channel_list_chat = [\n",
        "#     [\"ECG\", \"SPO2\"]\n",
        "# ]\n",
        "\n",
        "# for ch in channel_list_chat:\n",
        "#     chs = []\n",
        "#     chstr = \"\"\n",
        "#     for name in ch:\n",
        "#         chstr += name\n",
        "#         chs = chs + sig_dict_chat[name]\n",
        "#     print(chstr, chs)\n",
        "#     config = {\n",
        "#         \"data_path\": data_path + 'chat_',\n",
        "#         \"model_path\": model_path,\n",
        "#         \"model_name\": \"model_1trasformerlayer_\"+ chstr,\n",
        "#         \"regression\": False,\n",
        "#         \"epochs\": 100,\n",
        "#         \"channels\": chs,\n",
        "#     }\n",
        "#     train(config, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHijEGSMan70",
        "outputId": "d7296c8a-e2e0-4cd9-9bd4-d11289d72205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3506, 3840, 3)\n",
            "test starting\n",
            "78/78 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95/95 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124/124 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 1s 4ms/step\n",
            "=========================================================================== \n",
            "[82.90218270008084, 84.54185893210283, 78.76306128212369, 84.48886639676113, 82.80091272104963] \n",
            "[84.80138169257341, 85.85503166783955, 76.62337662337663, 85.05263157894737, 80.07478632478633] \n",
            "[79.90235964198536, 81.98924731182797, 83.00506471581318, 83.08483290488432, 86.69751301330248] \n",
            "[85.86345381526105, 86.9987063389392, 74.48979591836735, 85.84952665670154, 79.00956668542487] \n",
            "[82.27901131126939, 83.87762117566174, 79.68665586169638, 84.05721716514954, 83.25465148569842] \n",
            "[90.8246166112783, 91.10368936833173, 86.42925093503919, 91.1202308629309, 89.46736999635144] \n",
            "[89.54340177442536, 89.02047582501295, 83.89965620232837, 89.09087747733659, 86.39791293109691] \n",
            "Accuracy: 82.70 -+ 2.104 \n",
            "Precision: 82.48 -+ 3.563 \n",
            "Recall: 82.94 -+ 2.203 \n",
            "Specifity: 82.44 -+ 4.881 \n",
            "F1: 82.63 -+ 1.598 \n",
            "AUROC: 89.79 -+ 1.787 \n",
            "AUPRC: 87.59 -+ 2.152 \n",
            "$ 82.7 \\pm 2.1$& $82.5 \\pm 3.6$& $82.9 \\pm 2.2$& $82.6 \\pm 1.6$& $89.8 \\pm 1.8$& \n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "sig_dict_chat = {\n",
        "    \"EOG\": [0, 1],\n",
        "    \"EEG\": [4, 5],\n",
        "    \"ECG\": [15,16],\n",
        "    \"Resp\": [9, 10],\n",
        "    \"SPO2\": [13],\n",
        "    \"CO2\": [14],\n",
        "}\n",
        "\n",
        "channel_list_chat = [\n",
        "    [\"ECG\", \"SPO2\"],\n",
        "]\n",
        "\n",
        "for ch in channel_list_chat:\n",
        "    chs = []\n",
        "    chstr = \"\"\n",
        "    for name in ch:\n",
        "        chstr += name\n",
        "        chs = chs + sig_dict_chat[name]\n",
        "    print(chstr, chs)\n",
        "    config = {\n",
        "        \"data_path\": data_path + 'chat_',\n",
        "        \"model_path\": model_path,\n",
        "        \"model_name\": \"model_1trasformerlayer_\"+ chstr,\n",
        "        \"channels\": chs,\n",
        "    }\n",
        "    test(config, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 layers"
      ],
      "metadata": {
        "id": "LVNhJhUNtHFD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BMfhcCUXuwR"
      },
      "outputs": [],
      "source": [
        "input_shape = (128 * 30, 3)\n",
        "num_patches = 30\n",
        "\n",
        "transformer_layers = 3 #changed to 3 layers\n",
        "num_heads = 4\n",
        "transformer_units = 32\n",
        "reg = False\n",
        "drop_out = 0.25\n",
        "l2_weight = 0.001\n",
        "\n",
        "model = create_transformer_model(input_shape, num_patches,\n",
        "                                projection_dim=transformer_units, transformer_layers=transformer_layers,\n",
        "                                num_heads=num_heads,\n",
        "                                transformer_units = [transformer_units*2, transformer_units],\n",
        "                                mlp_head_units=[256, 128],\n",
        "                                num_classes=1, drop_out=drop_out, reg=reg, l2_weight=l2_weight, demographic=False)\n",
        "loss_func = BinaryCrossentropy()\n",
        "optimizer = \"adam\"\n",
        "\n",
        "#Prevent over-fitting on same fold.\n",
        "def lr_schedule(epoch, lr):\n",
        "\n",
        "    if epoch > 50 and (epoch - 1) % 5 == 0:\n",
        "        lr *= 0.5\n",
        "\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykGiIc-0akm-",
        "outputId": "0832642f-7ca6-4dcf-b880-43fa842259ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "5\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n",
            "(3506, 3840, 3)\n",
            "training\n",
            "(14033, 3840, 3)\n",
            "(14033,)\n",
            "Epoch 1/100\n",
            "25/25 [==============================] - 13s 127ms/step - loss: 1.2281 - precision: 0.6245 - recall: 0.7860 - val_loss: 1.0944 - val_precision: 0.6500 - val_recall: 0.8032 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.0231 - precision: 0.6719 - recall: 0.8115 - val_loss: 0.9372 - val_precision: 0.6910 - val_recall: 0.8161 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.8925 - precision: 0.7030 - recall: 0.8302 - val_loss: 0.8422 - val_precision: 0.7094 - val_recall: 0.8276 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.8014 - precision: 0.7380 - recall: 0.8163 - val_loss: 0.7772 - val_precision: 0.7172 - val_recall: 0.8707 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.7390 - precision: 0.7623 - recall: 0.8238 - val_loss: 0.7152 - val_precision: 0.7745 - val_recall: 0.8190 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.7006 - precision: 0.7787 - recall: 0.8206 - val_loss: 0.6962 - val_precision: 0.7717 - val_recall: 0.8060 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.6682 - precision: 0.7801 - recall: 0.8315 - val_loss: 0.6628 - val_precision: 0.7854 - val_recall: 0.8362 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.6446 - precision: 0.7913 - recall: 0.8296 - val_loss: 0.6516 - val_precision: 0.8021 - val_recall: 0.7687 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.6214 - precision: 0.7946 - recall: 0.8187 - val_loss: 0.6298 - val_precision: 0.7634 - val_recall: 0.8621 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.6114 - precision: 0.7877 - recall: 0.8289 - val_loss: 0.6265 - val_precision: 0.8063 - val_recall: 0.7773 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.5948 - precision: 0.7999 - recall: 0.8291 - val_loss: 0.6022 - val_precision: 0.7918 - val_recall: 0.8032 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.5761 - precision: 0.8040 - recall: 0.8344 - val_loss: 0.5852 - val_precision: 0.8077 - val_recall: 0.8089 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.5671 - precision: 0.8066 - recall: 0.8377 - val_loss: 0.5853 - val_precision: 0.8164 - val_recall: 0.7730 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.5591 - precision: 0.8032 - recall: 0.8307 - val_loss: 0.5699 - val_precision: 0.7635 - val_recall: 0.8764 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.5543 - precision: 0.8048 - recall: 0.8379 - val_loss: 0.5537 - val_precision: 0.7860 - val_recall: 0.8391 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.5453 - precision: 0.8060 - recall: 0.8433 - val_loss: 0.5654 - val_precision: 0.8086 - val_recall: 0.7830 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.5409 - precision: 0.8072 - recall: 0.8334 - val_loss: 0.5383 - val_precision: 0.8179 - val_recall: 0.8261 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.5255 - precision: 0.8144 - recall: 0.8401 - val_loss: 0.5340 - val_precision: 0.7891 - val_recall: 0.8549 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.5271 - precision: 0.8117 - recall: 0.8472 - val_loss: 0.5461 - val_precision: 0.8032 - val_recall: 0.8032 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.5230 - precision: 0.8160 - recall: 0.8406 - val_loss: 0.5234 - val_precision: 0.8005 - val_recall: 0.8477 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.5125 - precision: 0.8181 - recall: 0.8443 - val_loss: 0.5187 - val_precision: 0.7978 - val_recall: 0.8333 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.5167 - precision: 0.8107 - recall: 0.8440 - val_loss: 0.5183 - val_precision: 0.8027 - val_recall: 0.8477 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.5051 - precision: 0.8226 - recall: 0.8445 - val_loss: 0.5287 - val_precision: 0.7607 - val_recall: 0.8951 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.5041 - precision: 0.8142 - recall: 0.8440 - val_loss: 0.5100 - val_precision: 0.7952 - val_recall: 0.8592 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.5017 - precision: 0.8129 - recall: 0.8433 - val_loss: 0.5133 - val_precision: 0.8219 - val_recall: 0.7888 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4974 - precision: 0.8174 - recall: 0.8427 - val_loss: 0.5330 - val_precision: 0.7600 - val_recall: 0.8966 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.5009 - precision: 0.8128 - recall: 0.8411 - val_loss: 0.5173 - val_precision: 0.8280 - val_recall: 0.7816 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4902 - precision: 0.8186 - recall: 0.8424 - val_loss: 0.5007 - val_precision: 0.7900 - val_recall: 0.8649 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 0.4918 - precision: 0.8155 - recall: 0.8494 - val_loss: 0.5034 - val_precision: 0.8103 - val_recall: 0.8103 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4957 - precision: 0.8155 - recall: 0.8438 - val_loss: 0.4955 - val_precision: 0.8035 - val_recall: 0.8520 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4943 - precision: 0.8150 - recall: 0.8441 - val_loss: 0.4948 - val_precision: 0.8100 - val_recall: 0.8578 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4862 - precision: 0.8198 - recall: 0.8408 - val_loss: 0.5053 - val_precision: 0.7781 - val_recall: 0.8966 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4843 - precision: 0.8209 - recall: 0.8457 - val_loss: 0.4914 - val_precision: 0.8259 - val_recall: 0.7974 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4786 - precision: 0.8193 - recall: 0.8459 - val_loss: 0.4921 - val_precision: 0.7831 - val_recall: 0.8764 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4772 - precision: 0.8218 - recall: 0.8472 - val_loss: 0.5071 - val_precision: 0.7659 - val_recall: 0.9023 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4782 - precision: 0.8161 - recall: 0.8507 - val_loss: 0.4871 - val_precision: 0.8113 - val_recall: 0.8463 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.4777 - precision: 0.8181 - recall: 0.8448 - val_loss: 0.4849 - val_precision: 0.7958 - val_recall: 0.8678 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4744 - precision: 0.8233 - recall: 0.8457 - val_loss: 0.4862 - val_precision: 0.8150 - val_recall: 0.8420 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4692 - precision: 0.8210 - recall: 0.8469 - val_loss: 0.4782 - val_precision: 0.8041 - val_recall: 0.8549 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4744 - precision: 0.8217 - recall: 0.8462 - val_loss: 0.4881 - val_precision: 0.7969 - val_recall: 0.8793 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4715 - precision: 0.8161 - recall: 0.8494 - val_loss: 0.4843 - val_precision: 0.8053 - val_recall: 0.8261 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4699 - precision: 0.8190 - recall: 0.8488 - val_loss: 0.4896 - val_precision: 0.8250 - val_recall: 0.8060 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 0.4722 - precision: 0.8214 - recall: 0.8457 - val_loss: 0.4758 - val_precision: 0.8043 - val_recall: 0.8506 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.4687 - precision: 0.8213 - recall: 0.8496 - val_loss: 0.4890 - val_precision: 0.8129 - val_recall: 0.8175 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4695 - precision: 0.8211 - recall: 0.8459 - val_loss: 0.4870 - val_precision: 0.8056 - val_recall: 0.8276 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.4655 - precision: 0.8233 - recall: 0.8501 - val_loss: 0.4717 - val_precision: 0.8011 - val_recall: 0.8506 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4656 - precision: 0.8225 - recall: 0.8496 - val_loss: 0.4780 - val_precision: 0.8281 - val_recall: 0.8032 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4637 - precision: 0.8229 - recall: 0.8493 - val_loss: 0.4808 - val_precision: 0.8204 - val_recall: 0.8204 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 0.4587 - precision: 0.8222 - recall: 0.8512 - val_loss: 0.4727 - val_precision: 0.8154 - val_recall: 0.8506 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 0.4622 - precision: 0.8216 - recall: 0.8477 - val_loss: 0.4771 - val_precision: 0.7927 - val_recall: 0.8793 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4631 - precision: 0.8200 - recall: 0.8531 - val_loss: 0.4727 - val_precision: 0.8192 - val_recall: 0.8333 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4563 - precision: 0.8286 - recall: 0.8443 - val_loss: 0.4706 - val_precision: 0.8052 - val_recall: 0.8434 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4525 - precision: 0.8266 - recall: 0.8538 - val_loss: 0.4631 - val_precision: 0.8169 - val_recall: 0.8463 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4522 - precision: 0.8259 - recall: 0.8547 - val_loss: 0.4714 - val_precision: 0.8181 - val_recall: 0.8204 - lr: 5.0000e-04\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4507 - precision: 0.8255 - recall: 0.8534 - val_loss: 0.4763 - val_precision: 0.8234 - val_recall: 0.8103 - lr: 5.0000e-04\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4495 - precision: 0.8291 - recall: 0.8526 - val_loss: 0.4669 - val_precision: 0.8145 - val_recall: 0.8391 - lr: 5.0000e-04\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4453 - precision: 0.8263 - recall: 0.8558 - val_loss: 0.4698 - val_precision: 0.8223 - val_recall: 0.8175 - lr: 2.5000e-04\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4436 - precision: 0.8285 - recall: 0.8550 - val_loss: 0.4683 - val_precision: 0.8223 - val_recall: 0.8247 - lr: 2.5000e-04\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4458 - precision: 0.8323 - recall: 0.8530 - val_loss: 0.4620 - val_precision: 0.8042 - val_recall: 0.8736 - lr: 2.5000e-04\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4473 - precision: 0.8223 - recall: 0.8571 - val_loss: 0.4684 - val_precision: 0.8118 - val_recall: 0.8305 - lr: 2.5000e-04\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4443 - precision: 0.8273 - recall: 0.8557 - val_loss: 0.4603 - val_precision: 0.8076 - val_recall: 0.8506 - lr: 2.5000e-04\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4441 - precision: 0.8267 - recall: 0.8597 - val_loss: 0.4640 - val_precision: 0.8232 - val_recall: 0.8161 - lr: 1.2500e-04\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4419 - precision: 0.8310 - recall: 0.8555 - val_loss: 0.4621 - val_precision: 0.8091 - val_recall: 0.8405 - lr: 1.2500e-04\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4421 - precision: 0.8283 - recall: 0.8598 - val_loss: 0.4620 - val_precision: 0.8127 - val_recall: 0.8290 - lr: 1.2500e-04\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4424 - precision: 0.8327 - recall: 0.8557 - val_loss: 0.4630 - val_precision: 0.8079 - val_recall: 0.8520 - lr: 1.2500e-04\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4404 - precision: 0.8293 - recall: 0.8605 - val_loss: 0.4622 - val_precision: 0.8051 - val_recall: 0.8606 - lr: 1.2500e-04\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 0.4421 - precision: 0.8295 - recall: 0.8594 - val_loss: 0.4612 - val_precision: 0.8112 - val_recall: 0.8333 - lr: 6.2500e-05\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4403 - precision: 0.8301 - recall: 0.8590 - val_loss: 0.4596 - val_precision: 0.8100 - val_recall: 0.8391 - lr: 6.2500e-05\n",
            "Epoch 69/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4415 - precision: 0.8303 - recall: 0.8560 - val_loss: 0.4587 - val_precision: 0.8111 - val_recall: 0.8391 - lr: 6.2500e-05\n",
            "Epoch 70/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4398 - precision: 0.8306 - recall: 0.8614 - val_loss: 0.4610 - val_precision: 0.8182 - val_recall: 0.8276 - lr: 6.2500e-05\n",
            "Epoch 71/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4400 - precision: 0.8294 - recall: 0.8637 - val_loss: 0.4610 - val_precision: 0.8150 - val_recall: 0.8290 - lr: 6.2500e-05\n",
            "Epoch 72/100\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 0.4378 - precision: 0.8331 - recall: 0.8595 - val_loss: 0.4601 - val_precision: 0.8144 - val_recall: 0.8261 - lr: 3.1250e-05\n",
            "Epoch 73/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4395 - precision: 0.8329 - recall: 0.8626 - val_loss: 0.4610 - val_precision: 0.8141 - val_recall: 0.8305 - lr: 3.1250e-05\n",
            "Epoch 74/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4378 - precision: 0.8310 - recall: 0.8590 - val_loss: 0.4601 - val_precision: 0.8117 - val_recall: 0.8362 - lr: 3.1250e-05\n",
            "Epoch 75/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4382 - precision: 0.8287 - recall: 0.8603 - val_loss: 0.4608 - val_precision: 0.8159 - val_recall: 0.8276 - lr: 3.1250e-05\n",
            "Epoch 76/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4401 - precision: 0.8313 - recall: 0.8526 - val_loss: 0.4599 - val_precision: 0.8108 - val_recall: 0.8376 - lr: 3.1250e-05\n",
            "Epoch 77/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.4394 - precision: 0.8297 - recall: 0.8598 - val_loss: 0.4602 - val_precision: 0.8107 - val_recall: 0.8305 - lr: 1.5625e-05\n",
            "Epoch 78/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.4390 - precision: 0.8300 - recall: 0.8586 - val_loss: 0.4604 - val_precision: 0.8147 - val_recall: 0.8276 - lr: 1.5625e-05\n",
            "Epoch 79/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.4403 - precision: 0.8275 - recall: 0.8581 - val_loss: 0.4607 - val_precision: 0.8147 - val_recall: 0.8276 - lr: 1.5625e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x78478d05e5c0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13473, 3840, 3)\n",
            "(13473,)\n",
            "Epoch 1/100\n",
            "24/24 [==============================] - 12s 88ms/step - loss: 0.4989 - precision: 0.8002 - recall: 0.8292 - val_loss: 0.4810 - val_precision: 0.7860 - val_recall: 0.8841 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 0.4624 - precision: 0.8136 - recall: 0.8485 - val_loss: 0.4687 - val_precision: 0.8069 - val_recall: 0.8380 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 1s 44ms/step - loss: 0.4545 - precision: 0.8218 - recall: 0.8467 - val_loss: 0.4632 - val_precision: 0.8206 - val_recall: 0.8158 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 0.4548 - precision: 0.8205 - recall: 0.8517 - val_loss: 0.4630 - val_precision: 0.8038 - val_recall: 0.8767 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4544 - precision: 0.8188 - recall: 0.8490 - val_loss: 0.4635 - val_precision: 0.8112 - val_recall: 0.8425 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 0.4543 - precision: 0.8158 - recall: 0.8528 - val_loss: 0.4665 - val_precision: 0.8333 - val_recall: 0.8172 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 0.4518 - precision: 0.8189 - recall: 0.8507 - val_loss: 0.4636 - val_precision: 0.8180 - val_recall: 0.8351 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 0.4524 - precision: 0.8172 - recall: 0.8538 - val_loss: 0.4583 - val_precision: 0.8219 - val_recall: 0.8366 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 0.4499 - precision: 0.8187 - recall: 0.8527 - val_loss: 0.4581 - val_precision: 0.8069 - val_recall: 0.8633 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4526 - precision: 0.8180 - recall: 0.8460 - val_loss: 0.4635 - val_precision: 0.8268 - val_recall: 0.8158 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4543 - precision: 0.8153 - recall: 0.8480 - val_loss: 0.4638 - val_precision: 0.8025 - val_recall: 0.8514 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 0.4506 - precision: 0.8173 - recall: 0.8482 - val_loss: 0.4591 - val_precision: 0.8097 - val_recall: 0.8410 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4452 - precision: 0.8225 - recall: 0.8518 - val_loss: 0.4660 - val_precision: 0.8298 - val_recall: 0.8113 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4472 - precision: 0.8197 - recall: 0.8505 - val_loss: 0.4553 - val_precision: 0.8218 - val_recall: 0.8291 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 0.4467 - precision: 0.8215 - recall: 0.8552 - val_loss: 0.4549 - val_precision: 0.8186 - val_recall: 0.8380 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4484 - precision: 0.8144 - recall: 0.8552 - val_loss: 0.4564 - val_precision: 0.8138 - val_recall: 0.8440 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 1s 38ms/step - loss: 0.4487 - precision: 0.8226 - recall: 0.8483 - val_loss: 0.4584 - val_precision: 0.8101 - val_recall: 0.8306 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4509 - precision: 0.8158 - recall: 0.8507 - val_loss: 0.4539 - val_precision: 0.8166 - val_recall: 0.8470 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4457 - precision: 0.8186 - recall: 0.8552 - val_loss: 0.4765 - val_precision: 0.8422 - val_recall: 0.7771 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 0.4436 - precision: 0.8235 - recall: 0.8507 - val_loss: 0.4592 - val_precision: 0.8222 - val_recall: 0.8247 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4451 - precision: 0.8210 - recall: 0.8485 - val_loss: 0.4874 - val_precision: 0.7813 - val_recall: 0.8811 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4466 - precision: 0.8191 - recall: 0.8542 - val_loss: 0.4553 - val_precision: 0.8227 - val_recall: 0.8202 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4485 - precision: 0.8204 - recall: 0.8493 - val_loss: 0.4657 - val_precision: 0.8129 - val_recall: 0.8262 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4482 - precision: 0.8184 - recall: 0.8460 - val_loss: 0.4630 - val_precision: 0.7958 - val_recall: 0.8455 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 0.4456 - precision: 0.8207 - recall: 0.8450 - val_loss: 0.4562 - val_precision: 0.8145 - val_recall: 0.8158 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4425 - precision: 0.8220 - recall: 0.8518 - val_loss: 0.4622 - val_precision: 0.8277 - val_recall: 0.8068 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 0.4424 - precision: 0.8229 - recall: 0.8487 - val_loss: 0.4521 - val_precision: 0.8082 - val_recall: 0.8455 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4391 - precision: 0.8211 - recall: 0.8525 - val_loss: 0.4650 - val_precision: 0.8044 - val_recall: 0.8737 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 1s 41ms/step - loss: 0.4422 - precision: 0.8196 - recall: 0.8530 - val_loss: 0.4477 - val_precision: 0.8153 - val_recall: 0.8529 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 0.4427 - precision: 0.8217 - recall: 0.8498 - val_loss: 0.4707 - val_precision: 0.8147 - val_recall: 0.8425 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4436 - precision: 0.8192 - recall: 0.8513 - val_loss: 0.4485 - val_precision: 0.8190 - val_recall: 0.8336 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 0.4414 - precision: 0.8171 - recall: 0.8543 - val_loss: 0.4565 - val_precision: 0.8233 - val_recall: 0.8306 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 0.4366 - precision: 0.8235 - recall: 0.8542 - val_loss: 0.4679 - val_precision: 0.8177 - val_recall: 0.8395 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4404 - precision: 0.8191 - recall: 0.8550 - val_loss: 0.4720 - val_precision: 0.8295 - val_recall: 0.7949 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4444 - precision: 0.8191 - recall: 0.8482 - val_loss: 0.4543 - val_precision: 0.8174 - val_recall: 0.8380 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4353 - precision: 0.8229 - recall: 0.8542 - val_loss: 0.4630 - val_precision: 0.8162 - val_recall: 0.8380 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4384 - precision: 0.8226 - recall: 0.8515 - val_loss: 0.4698 - val_precision: 0.7836 - val_recall: 0.8826 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 1s 39ms/step - loss: 0.4479 - precision: 0.8135 - recall: 0.8432 - val_loss: 0.4630 - val_precision: 0.8097 - val_recall: 0.8470 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 1s 40ms/step - loss: 0.4415 - precision: 0.8189 - recall: 0.8512 - val_loss: 0.4510 - val_precision: 0.8158 - val_recall: 0.8291 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x78478d05e5c0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12966, 3840, 3)\n",
            "(12966,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 12s 87ms/step - loss: 0.4373 - precision: 0.8274 - recall: 0.8516 - val_loss: 0.4668 - val_precision: 0.8102 - val_recall: 0.8552 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4267 - precision: 0.8349 - recall: 0.8581 - val_loss: 0.4510 - val_precision: 0.8075 - val_recall: 0.8659 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.4202 - precision: 0.8351 - recall: 0.8596 - val_loss: 0.4526 - val_precision: 0.8160 - val_recall: 0.8336 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4153 - precision: 0.8347 - recall: 0.8661 - val_loss: 0.4701 - val_precision: 0.8350 - val_recall: 0.7720 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.4174 - precision: 0.8359 - recall: 0.8607 - val_loss: 0.4568 - val_precision: 0.7961 - val_recall: 0.8721 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4164 - precision: 0.8352 - recall: 0.8621 - val_loss: 0.4654 - val_precision: 0.7750 - val_recall: 0.8968 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4185 - precision: 0.8333 - recall: 0.8626 - val_loss: 0.4562 - val_precision: 0.8009 - val_recall: 0.8490 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4151 - precision: 0.8385 - recall: 0.8602 - val_loss: 0.4575 - val_precision: 0.8196 - val_recall: 0.8120 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4135 - precision: 0.8370 - recall: 0.8638 - val_loss: 0.4509 - val_precision: 0.8074 - val_recall: 0.8459 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4124 - precision: 0.8340 - recall: 0.8635 - val_loss: 0.4547 - val_precision: 0.8096 - val_recall: 0.8582 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4155 - precision: 0.8309 - recall: 0.8652 - val_loss: 0.4496 - val_precision: 0.8313 - val_recall: 0.8197 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4246 - precision: 0.8311 - recall: 0.8555 - val_loss: 0.4570 - val_precision: 0.8035 - val_recall: 0.8382 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4184 - precision: 0.8333 - recall: 0.8608 - val_loss: 0.4584 - val_precision: 0.8018 - val_recall: 0.8413 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4151 - precision: 0.8358 - recall: 0.8605 - val_loss: 0.4528 - val_precision: 0.8009 - val_recall: 0.8490 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4158 - precision: 0.8325 - recall: 0.8633 - val_loss: 0.4592 - val_precision: 0.8100 - val_recall: 0.8475 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4105 - precision: 0.8371 - recall: 0.8629 - val_loss: 0.4504 - val_precision: 0.8093 - val_recall: 0.8567 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4152 - precision: 0.8344 - recall: 0.8671 - val_loss: 0.4491 - val_precision: 0.8023 - val_recall: 0.8444 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4108 - precision: 0.8371 - recall: 0.8654 - val_loss: 0.4529 - val_precision: 0.8305 - val_recall: 0.8151 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4142 - precision: 0.8302 - recall: 0.8619 - val_loss: 0.4650 - val_precision: 0.8344 - val_recall: 0.7997 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4128 - precision: 0.8348 - recall: 0.8624 - val_loss: 0.4539 - val_precision: 0.8143 - val_recall: 0.8444 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4149 - precision: 0.8348 - recall: 0.8624 - val_loss: 0.4524 - val_precision: 0.8061 - val_recall: 0.8582 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4084 - precision: 0.8382 - recall: 0.8607 - val_loss: 0.4588 - val_precision: 0.8154 - val_recall: 0.8166 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4151 - precision: 0.8323 - recall: 0.8607 - val_loss: 0.4517 - val_precision: 0.8072 - val_recall: 0.8582 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4076 - precision: 0.8363 - recall: 0.8629 - val_loss: 0.4619 - val_precision: 0.7835 - val_recall: 0.8644 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4091 - precision: 0.8350 - recall: 0.8629 - val_loss: 0.4567 - val_precision: 0.7952 - val_recall: 0.8675 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.4130 - precision: 0.8322 - recall: 0.8662 - val_loss: 0.4476 - val_precision: 0.8274 - val_recall: 0.8274 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4087 - precision: 0.8346 - recall: 0.8638 - val_loss: 0.4617 - val_precision: 0.8309 - val_recall: 0.8028 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4073 - precision: 0.8379 - recall: 0.8640 - val_loss: 0.4525 - val_precision: 0.8193 - val_recall: 0.8382 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4118 - precision: 0.8341 - recall: 0.8624 - val_loss: 0.4749 - val_precision: 0.8228 - val_recall: 0.8012 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4156 - precision: 0.8333 - recall: 0.8584 - val_loss: 0.4535 - val_precision: 0.8078 - val_recall: 0.8290 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4117 - precision: 0.8329 - recall: 0.8603 - val_loss: 0.4601 - val_precision: 0.8272 - val_recall: 0.7966 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4045 - precision: 0.8396 - recall: 0.8671 - val_loss: 0.4467 - val_precision: 0.8090 - val_recall: 0.8613 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4122 - precision: 0.8356 - recall: 0.8596 - val_loss: 0.4552 - val_precision: 0.8038 - val_recall: 0.8521 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4049 - precision: 0.8348 - recall: 0.8608 - val_loss: 0.4558 - val_precision: 0.8232 - val_recall: 0.8320 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4047 - precision: 0.8365 - recall: 0.8626 - val_loss: 0.4499 - val_precision: 0.8129 - val_recall: 0.8567 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4044 - precision: 0.8364 - recall: 0.8603 - val_loss: 0.4506 - val_precision: 0.8049 - val_recall: 0.8644 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4043 - precision: 0.8361 - recall: 0.8664 - val_loss: 0.4551 - val_precision: 0.8218 - val_recall: 0.8243 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.4034 - precision: 0.8387 - recall: 0.8621 - val_loss: 0.4489 - val_precision: 0.7994 - val_recall: 0.8598 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4071 - precision: 0.8403 - recall: 0.8622 - val_loss: 0.4590 - val_precision: 0.8286 - val_recall: 0.8043 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4080 - precision: 0.8368 - recall: 0.8607 - val_loss: 0.4573 - val_precision: 0.7896 - val_recall: 0.8906 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4026 - precision: 0.8371 - recall: 0.8619 - val_loss: 0.4557 - val_precision: 0.7946 - val_recall: 0.8644 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4034 - precision: 0.8325 - recall: 0.8701 - val_loss: 0.4466 - val_precision: 0.8089 - val_recall: 0.8413 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4059 - precision: 0.8361 - recall: 0.8581 - val_loss: 0.4488 - val_precision: 0.8160 - val_recall: 0.8336 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4009 - precision: 0.8370 - recall: 0.8683 - val_loss: 0.4509 - val_precision: 0.7961 - val_recall: 0.8721 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4055 - precision: 0.8381 - recall: 0.8635 - val_loss: 0.4534 - val_precision: 0.8207 - val_recall: 0.8182 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4020 - precision: 0.8343 - recall: 0.8675 - val_loss: 0.4658 - val_precision: 0.8134 - val_recall: 0.8059 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4011 - precision: 0.8357 - recall: 0.8673 - val_loss: 0.4516 - val_precision: 0.8077 - val_recall: 0.8351 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4050 - precision: 0.8332 - recall: 0.8629 - val_loss: 0.4486 - val_precision: 0.8144 - val_recall: 0.8382 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4043 - precision: 0.8356 - recall: 0.8699 - val_loss: 0.4488 - val_precision: 0.8186 - val_recall: 0.8274 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4057 - precision: 0.8356 - recall: 0.8621 - val_loss: 0.4576 - val_precision: 0.8088 - val_recall: 0.8536 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4054 - precision: 0.8345 - recall: 0.8642 - val_loss: 0.4565 - val_precision: 0.8412 - val_recall: 0.7920 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.3985 - precision: 0.8349 - recall: 0.8713 - val_loss: 0.4470 - val_precision: 0.8027 - val_recall: 0.8398 - lr: 5.0000e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x78478d05e5c0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12555, 3840, 3)\n",
            "(12555,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 12s 87ms/step - loss: 0.4935 - precision: 0.7855 - recall: 0.8322 - val_loss: 0.4725 - val_precision: 0.8003 - val_recall: 0.8450 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4528 - precision: 0.8124 - recall: 0.8397 - val_loss: 0.4504 - val_precision: 0.8222 - val_recall: 0.8275 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4391 - precision: 0.8200 - recall: 0.8417 - val_loss: 0.4487 - val_precision: 0.8064 - val_recall: 0.8450 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4377 - precision: 0.8163 - recall: 0.8469 - val_loss: 0.4446 - val_precision: 0.8052 - val_recall: 0.8450 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 38ms/step - loss: 0.4406 - precision: 0.8150 - recall: 0.8494 - val_loss: 0.4510 - val_precision: 0.8279 - val_recall: 0.8147 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4392 - precision: 0.8198 - recall: 0.8397 - val_loss: 0.4477 - val_precision: 0.8262 - val_recall: 0.8275 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4381 - precision: 0.8139 - recall: 0.8480 - val_loss: 0.4626 - val_precision: 0.7855 - val_recall: 0.8834 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4384 - precision: 0.8166 - recall: 0.8512 - val_loss: 0.4525 - val_precision: 0.8303 - val_recall: 0.8051 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4395 - precision: 0.8175 - recall: 0.8406 - val_loss: 0.4489 - val_precision: 0.8375 - val_recall: 0.8067 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4354 - precision: 0.8181 - recall: 0.8435 - val_loss: 0.4453 - val_precision: 0.8069 - val_recall: 0.8610 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4325 - precision: 0.8143 - recall: 0.8492 - val_loss: 0.4488 - val_precision: 0.8089 - val_recall: 0.8450 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4372 - precision: 0.8166 - recall: 0.8496 - val_loss: 0.4469 - val_precision: 0.8312 - val_recall: 0.8259 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4327 - precision: 0.8200 - recall: 0.8506 - val_loss: 0.4536 - val_precision: 0.8155 - val_recall: 0.8259 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.4310 - precision: 0.8236 - recall: 0.8458 - val_loss: 0.4499 - val_precision: 0.8164 - val_recall: 0.8450 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x78478d05e5c0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13001, 3840, 3)\n",
            "(13001,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 12s 128ms/step - loss: 0.4461 - precision: 0.8125 - recall: 0.8462 - val_loss: 0.4080 - val_precision: 0.8406 - val_recall: 0.8560 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 1s 43ms/step - loss: 0.4307 - precision: 0.8195 - recall: 0.8562 - val_loss: 0.4006 - val_precision: 0.8238 - val_recall: 0.8806 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4296 - precision: 0.8219 - recall: 0.8488 - val_loss: 0.3945 - val_precision: 0.8526 - val_recall: 0.8591 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4291 - precision: 0.8253 - recall: 0.8533 - val_loss: 0.4019 - val_precision: 0.8396 - val_recall: 0.8576 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4325 - precision: 0.8207 - recall: 0.8519 - val_loss: 0.4065 - val_precision: 0.8166 - val_recall: 0.8867 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4273 - precision: 0.8201 - recall: 0.8559 - val_loss: 0.3953 - val_precision: 0.8370 - val_recall: 0.8729 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 1s 39ms/step - loss: 0.4270 - precision: 0.8195 - recall: 0.8569 - val_loss: 0.4165 - val_precision: 0.8546 - val_recall: 0.8101 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4318 - precision: 0.8185 - recall: 0.8472 - val_loss: 0.4116 - val_precision: 0.8187 - val_recall: 0.8714 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 1s 40ms/step - loss: 0.4278 - precision: 0.8205 - recall: 0.8581 - val_loss: 0.4007 - val_precision: 0.8312 - val_recall: 0.8821 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.4251 - precision: 0.8187 - recall: 0.8553 - val_loss: 0.3990 - val_precision: 0.8346 - val_recall: 0.8652 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.4223 - precision: 0.8240 - recall: 0.8536 - val_loss: 0.4059 - val_precision: 0.8260 - val_recall: 0.8652 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 1s 41ms/step - loss: 0.4221 - precision: 0.8225 - recall: 0.8595 - val_loss: 0.4067 - val_precision: 0.8465 - val_recall: 0.8361 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 1s 42ms/step - loss: 0.4189 - precision: 0.8225 - recall: 0.8612 - val_loss: 0.4140 - val_precision: 0.8576 - val_recall: 0.8208 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x78478d05e5c0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training complete\n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "# sig_dict_chat = {\n",
        "#     \"EOG\": [0, 1],\n",
        "#     \"EEG\": [4, 5],\n",
        "#     \"ECG\": [15,16],\n",
        "#     \"Resp\": [9, 10],\n",
        "#     \"SPO2\": [13],\n",
        "#     \"CO2\": [14],\n",
        "# }\n",
        "\n",
        "# channel_list_chat = [\n",
        "#     [\"ECG\", \"SPO2\"]\n",
        "# ]\n",
        "\n",
        "# for ch in channel_list_chat:\n",
        "#     chs = []\n",
        "#     chstr = \"\"\n",
        "#     for name in ch:\n",
        "#         chstr += name\n",
        "#         chs = chs + sig_dict_chat[name]\n",
        "#     print(chstr, chs)\n",
        "#     config = {\n",
        "#         \"data_path\": data_path + 'chat_',\n",
        "#         \"model_path\": model_path,\n",
        "#         \"model_name\": \"model_3trasformerlayer_\"+ chstr,\n",
        "#         \"regression\": False,\n",
        "#         \"epochs\": 100,\n",
        "#         \"channels\": chs,\n",
        "#     }\n",
        "#     train(config, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fnbwtk7Saox0",
        "outputId": "801fee7b-8f7a-4c6c-898f-f58b24f186a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3506, 3840, 3)\n",
            "test starting\n",
            "78/78 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95/95 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 1s 7ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124/124 [==============================] - 1s 6ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 1s 6ms/step\n",
            "=========================================================================== \n",
            "[83.91269199676637, 85.39881344759394, 79.8079638520192, 85.60222672064778, 83.59954363947519] \n",
            "[83.8079739625712, 85.28021607022282, 77.42768595041323, 84.43443443443444, 82.30683090705487] \n",
            "[83.8079739625712, 84.87903225806451, 84.3556555993247, 86.73521850899742, 85.02024291497976] \n",
            "[84.0160642570281, 85.89909443725745, 75.22675736961452, 84.50423517688091, 82.21722003376478] \n",
            "[83.8079739625712, 85.07915122937015, 80.74333423108, 85.56936342886128, 83.64153627311522] \n",
            "[90.83265527529157, 91.57538009987618, 86.93589797577256, 92.13490572200384, 90.34885382366352] \n",
            "[88.8484297199888, 90.12326158903589, 85.13001954696466, 90.77013983768445, 88.30344409804339] \n",
            "Accuracy: 83.66 -+ 2.083 \n",
            "Precision: 82.65 -+ 2.787 \n",
            "Recall: 84.96 -+ 0.985 \n",
            "Specifity: 82.37 -+ 3.762 \n",
            "F1: 83.77 -+ 1.681 \n",
            "AUROC: 90.37 -+ 1.821 \n",
            "AUPRC: 88.64 -+ 1.960 \n",
            "$ 83.7 \\pm 2.1$& $82.7 \\pm 2.8$& $85.0 \\pm 1.0$& $83.8 \\pm 1.7$& $90.4 \\pm 1.8$& \n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "sig_dict_chat = {\n",
        "    \"EOG\": [0, 1],\n",
        "    \"EEG\": [4, 5],\n",
        "    \"ECG\": [15,16],\n",
        "    \"Resp\": [9, 10],\n",
        "    \"SPO2\": [13],\n",
        "    \"CO2\": [14],\n",
        "}\n",
        "\n",
        "channel_list_chat = [\n",
        "    [\"ECG\", \"SPO2\"],\n",
        "]\n",
        "\n",
        "for ch in channel_list_chat:\n",
        "    chs = []\n",
        "    chstr = \"\"\n",
        "    for name in ch:\n",
        "        chstr += name\n",
        "        chs = chs + sig_dict_chat[name]\n",
        "    print(chstr, chs)\n",
        "    config = {\n",
        "        \"data_path\": data_path + 'chat_',\n",
        "        \"model_path\": model_path,\n",
        "        \"model_name\": \"model_3trasformerlayer_\"+ chstr,\n",
        "        \"channels\": chs,\n",
        "    }\n",
        "    test(config, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10 layers"
      ],
      "metadata": {
        "id": "jk7xDXRQtJrr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwXjc2kraWPp"
      },
      "outputs": [],
      "source": [
        "input_shape = (128 * 30, 3)\n",
        "num_patches = 30\n",
        "\n",
        "transformer_layers = 10 #changed to 10 layers\n",
        "num_heads = 4\n",
        "transformer_units = 32\n",
        "reg = False\n",
        "drop_out = 0.25\n",
        "l2_weight = 0.001\n",
        "\n",
        "model = create_transformer_model(input_shape, num_patches,\n",
        "                                projection_dim=transformer_units, transformer_layers=transformer_layers,\n",
        "                                num_heads=num_heads,\n",
        "                                transformer_units = [transformer_units*2, transformer_units],\n",
        "                                mlp_head_units=[256, 128],\n",
        "                                num_classes=1, drop_out=drop_out, reg=reg, l2_weight=l2_weight, demographic=False)\n",
        "loss_func = BinaryCrossentropy()\n",
        "optimizer = \"adam\"\n",
        "\n",
        "#Prevent over-fitting on same fold.\n",
        "def lr_schedule(epoch, lr):\n",
        "\n",
        "    if epoch > 50 and (epoch - 1) % 5 == 0:\n",
        "        lr *= 0.5\n",
        "\n",
        "    return lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSb9GvdtalOi",
        "outputId": "97db39e8-f299-46f8-82f6-e4c7d8320c80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "5\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n",
            "(3506, 3840, 3)\n",
            "training\n",
            "(14033, 3840, 3)\n",
            "(14033,)\n",
            "Epoch 1/100\n",
            "25/25 [==============================] - 34s 190ms/step - loss: 2.0731 - precision: 0.6337 - recall: 0.7586 - val_loss: 1.8605 - val_precision: 0.6165 - val_recall: 0.9234 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 1.6838 - precision: 0.7035 - recall: 0.8230 - val_loss: 1.5421 - val_precision: 0.7712 - val_recall: 0.6701 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 1.4314 - precision: 0.7461 - recall: 0.7968 - val_loss: 1.3658 - val_precision: 0.6741 - val_recall: 0.8866 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 1.2550 - precision: 0.7611 - recall: 0.8051 - val_loss: 1.1837 - val_precision: 0.7544 - val_recall: 0.7599 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 1.1183 - precision: 0.7722 - recall: 0.8051 - val_loss: 1.0756 - val_precision: 0.7518 - val_recall: 0.7894 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 1.0177 - precision: 0.7805 - recall: 0.8043 - val_loss: 0.9794 - val_precision: 0.7760 - val_recall: 0.7703 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.9377 - precision: 0.7825 - recall: 0.8022 - val_loss: 0.9114 - val_precision: 0.7682 - val_recall: 0.7761 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.8658 - precision: 0.7927 - recall: 0.8030 - val_loss: 0.8563 - val_precision: 0.7604 - val_recall: 0.8041 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.8099 - precision: 0.7945 - recall: 0.8120 - val_loss: 0.7940 - val_precision: 0.8021 - val_recall: 0.7879 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.7647 - precision: 0.8067 - recall: 0.8086 - val_loss: 0.7703 - val_precision: 0.7437 - val_recall: 0.8675 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.7303 - precision: 0.8030 - recall: 0.8168 - val_loss: 0.7288 - val_precision: 0.7748 - val_recall: 0.8409 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6953 - precision: 0.8101 - recall: 0.8214 - val_loss: 0.6939 - val_precision: 0.8099 - val_recall: 0.7968 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6683 - precision: 0.8154 - recall: 0.8181 - val_loss: 0.6819 - val_precision: 0.7574 - val_recall: 0.8689 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.6515 - precision: 0.8110 - recall: 0.8240 - val_loss: 0.6663 - val_precision: 0.8239 - val_recall: 0.7717 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.6410 - precision: 0.8090 - recall: 0.8169 - val_loss: 0.6353 - val_precision: 0.8249 - val_recall: 0.7703 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.6140 - precision: 0.8249 - recall: 0.8201 - val_loss: 0.6419 - val_precision: 0.7732 - val_recall: 0.8483 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.6034 - precision: 0.8143 - recall: 0.8278 - val_loss: 0.6142 - val_precision: 0.7901 - val_recall: 0.8262 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.5863 - precision: 0.8199 - recall: 0.8319 - val_loss: 0.5928 - val_precision: 0.8131 - val_recall: 0.8203 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.5826 - precision: 0.8184 - recall: 0.8256 - val_loss: 0.5914 - val_precision: 0.7947 - val_recall: 0.8380 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.5695 - precision: 0.8226 - recall: 0.8246 - val_loss: 0.5732 - val_precision: 0.8152 - val_recall: 0.8189 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 2s 90ms/step - loss: 0.5605 - precision: 0.8224 - recall: 0.8224 - val_loss: 0.5743 - val_precision: 0.7885 - val_recall: 0.8454 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.5558 - precision: 0.8182 - recall: 0.8299 - val_loss: 0.5791 - val_precision: 0.7602 - val_recall: 0.8778 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.5486 - precision: 0.8215 - recall: 0.8310 - val_loss: 0.5575 - val_precision: 0.7776 - val_recall: 0.8498 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.5412 - precision: 0.8233 - recall: 0.8316 - val_loss: 0.5409 - val_precision: 0.8072 - val_recall: 0.8262 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.5384 - precision: 0.8150 - recall: 0.8276 - val_loss: 0.5374 - val_precision: 0.8092 - val_recall: 0.8306 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.5288 - precision: 0.8273 - recall: 0.8342 - val_loss: 0.5385 - val_precision: 0.8152 - val_recall: 0.8189 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.5187 - precision: 0.8256 - recall: 0.8348 - val_loss: 0.5226 - val_precision: 0.7954 - val_recall: 0.8645 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.5219 - precision: 0.8216 - recall: 0.8377 - val_loss: 0.5326 - val_precision: 0.8003 - val_recall: 0.8498 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.5135 - precision: 0.8249 - recall: 0.8307 - val_loss: 0.5376 - val_precision: 0.7815 - val_recall: 0.8689 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.5252 - precision: 0.8215 - recall: 0.8308 - val_loss: 0.5364 - val_precision: 0.7636 - val_recall: 0.8895 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.5124 - precision: 0.8181 - recall: 0.8407 - val_loss: 0.5112 - val_precision: 0.8199 - val_recall: 0.8380 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.5054 - precision: 0.8272 - recall: 0.8345 - val_loss: 0.5143 - val_precision: 0.8284 - val_recall: 0.8174 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.5055 - precision: 0.8203 - recall: 0.8347 - val_loss: 0.5074 - val_precision: 0.8222 - val_recall: 0.8306 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.4987 - precision: 0.8313 - recall: 0.8321 - val_loss: 0.5132 - val_precision: 0.7823 - val_recall: 0.8733 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.4922 - precision: 0.8251 - recall: 0.8454 - val_loss: 0.5073 - val_precision: 0.8269 - val_recall: 0.8233 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.4995 - precision: 0.8248 - recall: 0.8356 - val_loss: 0.5027 - val_precision: 0.8377 - val_recall: 0.7982 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.4881 - precision: 0.8310 - recall: 0.8329 - val_loss: 0.4982 - val_precision: 0.8195 - val_recall: 0.8159 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.4859 - precision: 0.8303 - recall: 0.8364 - val_loss: 0.5279 - val_precision: 0.7534 - val_recall: 0.8866 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.4889 - precision: 0.8255 - recall: 0.8371 - val_loss: 0.4890 - val_precision: 0.8321 - val_recall: 0.8100 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4835 - precision: 0.8299 - recall: 0.8350 - val_loss: 0.4924 - val_precision: 0.8513 - val_recall: 0.7923 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4782 - precision: 0.8269 - recall: 0.8363 - val_loss: 0.5004 - val_precision: 0.7967 - val_recall: 0.8483 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.4780 - precision: 0.8267 - recall: 0.8415 - val_loss: 0.4837 - val_precision: 0.8022 - val_recall: 0.8542 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4720 - precision: 0.8293 - recall: 0.8374 - val_loss: 0.4844 - val_precision: 0.8416 - val_recall: 0.8218 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.4797 - precision: 0.8264 - recall: 0.8420 - val_loss: 0.4818 - val_precision: 0.8195 - val_recall: 0.8292 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.4706 - precision: 0.8308 - recall: 0.8379 - val_loss: 0.4942 - val_precision: 0.7978 - val_recall: 0.8719 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4710 - precision: 0.8294 - recall: 0.8420 - val_loss: 0.4963 - val_precision: 0.8338 - val_recall: 0.7982 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.4717 - precision: 0.8335 - recall: 0.8351 - val_loss: 0.4761 - val_precision: 0.8263 - val_recall: 0.8336 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4632 - precision: 0.8313 - recall: 0.8455 - val_loss: 0.4875 - val_precision: 0.8119 - val_recall: 0.8645 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.4643 - precision: 0.8277 - recall: 0.8435 - val_loss: 0.4829 - val_precision: 0.8258 - val_recall: 0.8380 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.4613 - precision: 0.8317 - recall: 0.8433 - val_loss: 0.4776 - val_precision: 0.8296 - val_recall: 0.8174 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4580 - precision: 0.8341 - recall: 0.8489 - val_loss: 0.4788 - val_precision: 0.8453 - val_recall: 0.7806 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.4549 - precision: 0.8343 - recall: 0.8471 - val_loss: 0.4674 - val_precision: 0.8287 - val_recall: 0.8409 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.4506 - precision: 0.8374 - recall: 0.8500 - val_loss: 0.4722 - val_precision: 0.8103 - val_recall: 0.8557 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4522 - precision: 0.8309 - recall: 0.8444 - val_loss: 0.4680 - val_precision: 0.8278 - val_recall: 0.8424 - lr: 5.0000e-04\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4497 - precision: 0.8336 - recall: 0.8470 - val_loss: 0.4688 - val_precision: 0.8165 - val_recall: 0.8586 - lr: 5.0000e-04\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4493 - precision: 0.8353 - recall: 0.8466 - val_loss: 0.4750 - val_precision: 0.7926 - val_recall: 0.8778 - lr: 5.0000e-04\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.4447 - precision: 0.8373 - recall: 0.8511 - val_loss: 0.4707 - val_precision: 0.8177 - val_recall: 0.8586 - lr: 2.5000e-04\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.4423 - precision: 0.8396 - recall: 0.8514 - val_loss: 0.4666 - val_precision: 0.8268 - val_recall: 0.8365 - lr: 2.5000e-04\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4426 - precision: 0.8433 - recall: 0.8497 - val_loss: 0.4677 - val_precision: 0.8152 - val_recall: 0.8513 - lr: 2.5000e-04\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.4425 - precision: 0.8364 - recall: 0.8502 - val_loss: 0.4655 - val_precision: 0.8184 - val_recall: 0.8498 - lr: 2.5000e-04\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.4386 - precision: 0.8396 - recall: 0.8569 - val_loss: 0.4665 - val_precision: 0.8294 - val_recall: 0.8380 - lr: 2.5000e-04\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4376 - precision: 0.8440 - recall: 0.8473 - val_loss: 0.4658 - val_precision: 0.8207 - val_recall: 0.8424 - lr: 1.2500e-04\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4378 - precision: 0.8404 - recall: 0.8564 - val_loss: 0.4655 - val_precision: 0.8195 - val_recall: 0.8424 - lr: 1.2500e-04\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.4349 - precision: 0.8445 - recall: 0.8561 - val_loss: 0.4640 - val_precision: 0.8196 - val_recall: 0.8498 - lr: 1.2500e-04\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.4367 - precision: 0.8388 - recall: 0.8537 - val_loss: 0.4627 - val_precision: 0.8311 - val_recall: 0.8336 - lr: 1.2500e-04\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.4367 - precision: 0.8420 - recall: 0.8519 - val_loss: 0.4609 - val_precision: 0.8256 - val_recall: 0.8439 - lr: 1.2500e-04\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.4332 - precision: 0.8437 - recall: 0.8526 - val_loss: 0.4621 - val_precision: 0.8200 - val_recall: 0.8454 - lr: 6.2500e-05\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4329 - precision: 0.8440 - recall: 0.8545 - val_loss: 0.4640 - val_precision: 0.8353 - val_recall: 0.8365 - lr: 6.2500e-05\n",
            "Epoch 69/100\n",
            "25/25 [==============================] - 2s 94ms/step - loss: 0.4336 - precision: 0.8413 - recall: 0.8564 - val_loss: 0.4609 - val_precision: 0.8273 - val_recall: 0.8395 - lr: 6.2500e-05\n",
            "Epoch 70/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.4352 - precision: 0.8428 - recall: 0.8521 - val_loss: 0.4638 - val_precision: 0.8153 - val_recall: 0.8454 - lr: 6.2500e-05\n",
            "Epoch 71/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4347 - precision: 0.8390 - recall: 0.8564 - val_loss: 0.4618 - val_precision: 0.8245 - val_recall: 0.8513 - lr: 6.2500e-05\n",
            "Epoch 72/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4324 - precision: 0.8443 - recall: 0.8553 - val_loss: 0.4629 - val_precision: 0.8258 - val_recall: 0.8380 - lr: 3.1250e-05\n",
            "Epoch 73/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4316 - precision: 0.8449 - recall: 0.8546 - val_loss: 0.4623 - val_precision: 0.8254 - val_recall: 0.8424 - lr: 3.1250e-05\n",
            "Epoch 74/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4315 - precision: 0.8456 - recall: 0.8554 - val_loss: 0.4632 - val_precision: 0.8209 - val_recall: 0.8439 - lr: 3.1250e-05\n",
            "Epoch 75/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4325 - precision: 0.8432 - recall: 0.8524 - val_loss: 0.4626 - val_precision: 0.8200 - val_recall: 0.8454 - lr: 3.1250e-05\n",
            "Epoch 76/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4316 - precision: 0.8430 - recall: 0.8553 - val_loss: 0.4626 - val_precision: 0.8226 - val_recall: 0.8468 - lr: 3.1250e-05\n",
            "Epoch 77/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.4326 - precision: 0.8433 - recall: 0.8535 - val_loss: 0.4629 - val_precision: 0.8226 - val_recall: 0.8468 - lr: 1.5625e-05\n",
            "Epoch 78/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 0.4327 - precision: 0.8396 - recall: 0.8540 - val_loss: 0.4625 - val_precision: 0.8251 - val_recall: 0.8409 - lr: 1.5625e-05\n",
            "Epoch 79/100\n",
            "25/25 [==============================] - 2s 96ms/step - loss: 0.4301 - precision: 0.8433 - recall: 0.8546 - val_loss: 0.4624 - val_precision: 0.8240 - val_recall: 0.8409 - lr: 1.5625e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7844ec819cf0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13473, 3840, 3)\n",
            "(13473,)\n",
            "Epoch 1/100\n",
            "24/24 [==============================] - 34s 191ms/step - loss: 0.4930 - precision: 0.8056 - recall: 0.8364 - val_loss: 0.4734 - val_precision: 0.8328 - val_recall: 0.8021 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 2s 96ms/step - loss: 0.4614 - precision: 0.8353 - recall: 0.8378 - val_loss: 0.4663 - val_precision: 0.7958 - val_recall: 0.8727 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 2s 94ms/step - loss: 0.4564 - precision: 0.8280 - recall: 0.8524 - val_loss: 0.4534 - val_precision: 0.8170 - val_recall: 0.8558 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 2s 93ms/step - loss: 0.4502 - precision: 0.8317 - recall: 0.8477 - val_loss: 0.4599 - val_precision: 0.8074 - val_recall: 0.8742 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 2s 92ms/step - loss: 0.4533 - precision: 0.8266 - recall: 0.8504 - val_loss: 0.4769 - val_precision: 0.8313 - val_recall: 0.8160 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 2s 91ms/step - loss: 0.4534 - precision: 0.8321 - recall: 0.8442 - val_loss: 0.4624 - val_precision: 0.8326 - val_recall: 0.8160 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 2s 95ms/step - loss: 0.4508 - precision: 0.8312 - recall: 0.8480 - val_loss: 0.4518 - val_precision: 0.8214 - val_recall: 0.8604 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 2s 92ms/step - loss: 0.4515 - precision: 0.8280 - recall: 0.8439 - val_loss: 0.4639 - val_precision: 0.8148 - val_recall: 0.8635 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 2s 93ms/step - loss: 0.4534 - precision: 0.8307 - recall: 0.8436 - val_loss: 0.4656 - val_precision: 0.8194 - val_recall: 0.8420 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 2s 93ms/step - loss: 0.4548 - precision: 0.8261 - recall: 0.8502 - val_loss: 0.4576 - val_precision: 0.8138 - val_recall: 0.8512 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 2s 93ms/step - loss: 0.4463 - precision: 0.8343 - recall: 0.8497 - val_loss: 0.4611 - val_precision: 0.8452 - val_recall: 0.8037 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 2s 93ms/step - loss: 0.4504 - precision: 0.8280 - recall: 0.8474 - val_loss: 0.4595 - val_precision: 0.8212 - val_recall: 0.8451 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 2s 93ms/step - loss: 0.4463 - precision: 0.8320 - recall: 0.8505 - val_loss: 0.4563 - val_precision: 0.8085 - val_recall: 0.8482 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 2s 93ms/step - loss: 0.4512 - precision: 0.8251 - recall: 0.8485 - val_loss: 0.4536 - val_precision: 0.8226 - val_recall: 0.8390 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 2s 93ms/step - loss: 0.4493 - precision: 0.8288 - recall: 0.8464 - val_loss: 0.4531 - val_precision: 0.8221 - val_recall: 0.8436 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 2s 92ms/step - loss: 0.4484 - precision: 0.8290 - recall: 0.8462 - val_loss: 0.4584 - val_precision: 0.8216 - val_recall: 0.8405 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 2s 97ms/step - loss: 0.4458 - precision: 0.8286 - recall: 0.8494 - val_loss: 0.4606 - val_precision: 0.8101 - val_recall: 0.8574 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7844ec819cf0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12966, 3840, 3)\n",
            "(12966,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 30s 187ms/step - loss: 0.4581 - precision: 0.8290 - recall: 0.8442 - val_loss: 0.4908 - val_precision: 0.7871 - val_recall: 0.8724 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 2s 93ms/step - loss: 0.4390 - precision: 0.8365 - recall: 0.8511 - val_loss: 0.4623 - val_precision: 0.8242 - val_recall: 0.8373 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 0.4286 - precision: 0.8456 - recall: 0.8590 - val_loss: 0.4705 - val_precision: 0.8252 - val_recall: 0.8134 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4302 - precision: 0.8427 - recall: 0.8543 - val_loss: 0.4691 - val_precision: 0.8185 - val_recall: 0.8198 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4258 - precision: 0.8462 - recall: 0.8543 - val_loss: 0.4648 - val_precision: 0.8063 - val_recall: 0.8565 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4256 - precision: 0.8427 - recall: 0.8551 - val_loss: 0.4810 - val_precision: 0.7795 - val_recall: 0.8740 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4243 - precision: 0.8382 - recall: 0.8612 - val_loss: 0.4622 - val_precision: 0.8018 - val_recall: 0.8708 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 0.4207 - precision: 0.8401 - recall: 0.8596 - val_loss: 0.4638 - val_precision: 0.8254 - val_recall: 0.8293 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4232 - precision: 0.8395 - recall: 0.8577 - val_loss: 0.4593 - val_precision: 0.8175 - val_recall: 0.8501 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 2s 93ms/step - loss: 0.4213 - precision: 0.8397 - recall: 0.8605 - val_loss: 0.4553 - val_precision: 0.8171 - val_recall: 0.8405 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4169 - precision: 0.8447 - recall: 0.8617 - val_loss: 0.4651 - val_precision: 0.8415 - val_recall: 0.7959 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4208 - precision: 0.8393 - recall: 0.8596 - val_loss: 0.4597 - val_precision: 0.8285 - val_recall: 0.8166 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 2s 94ms/step - loss: 0.4169 - precision: 0.8433 - recall: 0.8609 - val_loss: 0.4552 - val_precision: 0.8120 - val_recall: 0.8612 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4181 - precision: 0.8427 - recall: 0.8628 - val_loss: 0.4602 - val_precision: 0.8063 - val_recall: 0.8565 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4155 - precision: 0.8425 - recall: 0.8602 - val_loss: 0.4611 - val_precision: 0.7942 - val_recall: 0.8740 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4141 - precision: 0.8456 - recall: 0.8616 - val_loss: 0.4767 - val_precision: 0.7738 - val_recall: 0.8947 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4150 - precision: 0.8427 - recall: 0.8586 - val_loss: 0.4559 - val_precision: 0.8050 - val_recall: 0.8692 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4138 - precision: 0.8435 - recall: 0.8649 - val_loss: 0.4715 - val_precision: 0.7977 - val_recall: 0.8676 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4119 - precision: 0.8465 - recall: 0.8610 - val_loss: 0.4628 - val_precision: 0.7952 - val_recall: 0.8915 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 2s 93ms/step - loss: 0.4103 - precision: 0.8464 - recall: 0.8709 - val_loss: 0.4572 - val_precision: 0.8149 - val_recall: 0.8214 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4106 - precision: 0.8469 - recall: 0.8609 - val_loss: 0.4627 - val_precision: 0.7870 - val_recall: 0.8900 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4105 - precision: 0.8440 - recall: 0.8662 - val_loss: 0.4574 - val_precision: 0.8044 - val_recall: 0.8660 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 2s 94ms/step - loss: 0.4088 - precision: 0.8435 - recall: 0.8621 - val_loss: 0.4518 - val_precision: 0.8135 - val_recall: 0.8485 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 0.4092 - precision: 0.8456 - recall: 0.8607 - val_loss: 0.4572 - val_precision: 0.8127 - val_recall: 0.8581 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4125 - precision: 0.8438 - recall: 0.8605 - val_loss: 0.4558 - val_precision: 0.8018 - val_recall: 0.8644 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 2s 93ms/step - loss: 0.4089 - precision: 0.8451 - recall: 0.8626 - val_loss: 0.4494 - val_precision: 0.8325 - val_recall: 0.8246 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4101 - precision: 0.8440 - recall: 0.8600 - val_loss: 0.4711 - val_precision: 0.8058 - val_recall: 0.8469 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4124 - precision: 0.8471 - recall: 0.8629 - val_loss: 0.4485 - val_precision: 0.8268 - val_recall: 0.8453 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4085 - precision: 0.8482 - recall: 0.8600 - val_loss: 0.4699 - val_precision: 0.7977 - val_recall: 0.8740 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 2s 93ms/step - loss: 0.4086 - precision: 0.8415 - recall: 0.8605 - val_loss: 0.4614 - val_precision: 0.8169 - val_recall: 0.8325 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4120 - precision: 0.8431 - recall: 0.8602 - val_loss: 0.4526 - val_precision: 0.8056 - val_recall: 0.8724 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4064 - precision: 0.8455 - recall: 0.8642 - val_loss: 0.4658 - val_precision: 0.8228 - val_recall: 0.8293 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4063 - precision: 0.8499 - recall: 0.8617 - val_loss: 0.4702 - val_precision: 0.7815 - val_recall: 0.8900 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4124 - precision: 0.8409 - recall: 0.8668 - val_loss: 0.4501 - val_precision: 0.8069 - val_recall: 0.8596 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 2s 94ms/step - loss: 0.4083 - precision: 0.8461 - recall: 0.8614 - val_loss: 0.4452 - val_precision: 0.8172 - val_recall: 0.8485 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4028 - precision: 0.8475 - recall: 0.8650 - val_loss: 0.4666 - val_precision: 0.8150 - val_recall: 0.8293 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 0.4020 - precision: 0.8448 - recall: 0.8680 - val_loss: 0.4614 - val_precision: 0.8344 - val_recall: 0.8278 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 2s 93ms/step - loss: 0.4025 - precision: 0.8467 - recall: 0.8633 - val_loss: 0.4444 - val_precision: 0.8189 - val_recall: 0.8437 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 0.4067 - precision: 0.8488 - recall: 0.8655 - val_loss: 0.4493 - val_precision: 0.8278 - val_recall: 0.8357 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 0.4067 - precision: 0.8479 - recall: 0.8588 - val_loss: 0.4579 - val_precision: 0.8162 - val_recall: 0.8357 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4059 - precision: 0.8464 - recall: 0.8622 - val_loss: 0.4602 - val_precision: 0.8053 - val_recall: 0.8708 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 0.4009 - precision: 0.8453 - recall: 0.8668 - val_loss: 0.4637 - val_precision: 0.7954 - val_recall: 0.8740 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 2s 89ms/step - loss: 0.4081 - precision: 0.8443 - recall: 0.8616 - val_loss: 0.4548 - val_precision: 0.8077 - val_recall: 0.8708 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 0.4048 - precision: 0.8457 - recall: 0.8645 - val_loss: 0.4607 - val_precision: 0.8403 - val_recall: 0.7974 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 0.4157 - precision: 0.8400 - recall: 0.8551 - val_loss: 0.4637 - val_precision: 0.7939 - val_recall: 0.8660 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4055 - precision: 0.8466 - recall: 0.8657 - val_loss: 0.4593 - val_precision: 0.7970 - val_recall: 0.8581 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4022 - precision: 0.8485 - recall: 0.8636 - val_loss: 0.4625 - val_precision: 0.8197 - val_recall: 0.8485 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 2s 94ms/step - loss: 0.4020 - precision: 0.8500 - recall: 0.8635 - val_loss: 0.4807 - val_precision: 0.7814 - val_recall: 0.8724 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7844ec819cf0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12555, 3840, 3)\n",
            "(12555,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 31s 187ms/step - loss: 0.4598 - precision: 0.8188 - recall: 0.8373 - val_loss: 0.4592 - val_precision: 0.8198 - val_recall: 0.8333 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 2s 93ms/step - loss: 0.4519 - precision: 0.8233 - recall: 0.8294 - val_loss: 0.4504 - val_precision: 0.8034 - val_recall: 0.8696 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 2s 89ms/step - loss: 0.4382 - precision: 0.8325 - recall: 0.8460 - val_loss: 0.4518 - val_precision: 0.7982 - val_recall: 0.8944 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 0.4398 - precision: 0.8287 - recall: 0.8448 - val_loss: 0.4565 - val_precision: 0.8018 - val_recall: 0.8680 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4415 - precision: 0.8205 - recall: 0.8465 - val_loss: 0.4562 - val_precision: 0.8278 - val_recall: 0.8251 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4404 - precision: 0.8295 - recall: 0.8487 - val_loss: 0.4397 - val_precision: 0.8293 - val_recall: 0.8416 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4371 - precision: 0.8303 - recall: 0.8460 - val_loss: 0.4530 - val_precision: 0.7870 - val_recall: 0.8960 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4418 - precision: 0.8286 - recall: 0.8417 - val_loss: 0.4944 - val_precision: 0.7394 - val_recall: 0.9224 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4526 - precision: 0.8094 - recall: 0.8535 - val_loss: 0.4500 - val_precision: 0.8429 - val_recall: 0.7970 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 0.4464 - precision: 0.8241 - recall: 0.8376 - val_loss: 0.4444 - val_precision: 0.8203 - val_recall: 0.8284 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4381 - precision: 0.8325 - recall: 0.8394 - val_loss: 0.4363 - val_precision: 0.8295 - val_recall: 0.8350 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4508 - precision: 0.8203 - recall: 0.8476 - val_loss: 0.4424 - val_precision: 0.8227 - val_recall: 0.8498 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4365 - precision: 0.8266 - recall: 0.8489 - val_loss: 0.4450 - val_precision: 0.8183 - val_recall: 0.8399 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4349 - precision: 0.8323 - recall: 0.8458 - val_loss: 0.4470 - val_precision: 0.8320 - val_recall: 0.8333 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4367 - precision: 0.8327 - recall: 0.8389 - val_loss: 0.4590 - val_precision: 0.7944 - val_recall: 0.8861 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 0.4410 - precision: 0.8214 - recall: 0.8424 - val_loss: 0.4449 - val_precision: 0.8159 - val_recall: 0.8630 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4363 - precision: 0.8251 - recall: 0.8551 - val_loss: 0.4687 - val_precision: 0.8587 - val_recall: 0.7624 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4379 - precision: 0.8299 - recall: 0.8355 - val_loss: 0.4749 - val_precision: 0.7790 - val_recall: 0.9076 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4487 - precision: 0.8139 - recall: 0.8449 - val_loss: 0.4420 - val_precision: 0.8303 - val_recall: 0.8234 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 2s 89ms/step - loss: 0.4312 - precision: 0.8307 - recall: 0.8472 - val_loss: 0.4384 - val_precision: 0.8121 - val_recall: 0.8630 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 2s 93ms/step - loss: 0.4388 - precision: 0.8272 - recall: 0.8472 - val_loss: 0.4483 - val_precision: 0.8217 - val_recall: 0.8515 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7844ec819cf0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13001, 3840, 3)\n",
            "(13001,)\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 30s 190ms/step - loss: 0.4575 - precision: 0.8182 - recall: 0.8357 - val_loss: 0.4079 - val_precision: 0.8542 - val_recall: 0.8583 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4340 - precision: 0.8335 - recall: 0.8479 - val_loss: 0.3951 - val_precision: 0.8680 - val_recall: 0.8376 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 2s 92ms/step - loss: 0.4269 - precision: 0.8351 - recall: 0.8470 - val_loss: 0.4011 - val_precision: 0.8221 - val_recall: 0.8901 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4248 - precision: 0.8361 - recall: 0.8551 - val_loss: 0.3952 - val_precision: 0.8276 - val_recall: 0.8790 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 0.4272 - precision: 0.8318 - recall: 0.8546 - val_loss: 0.3999 - val_precision: 0.8715 - val_recall: 0.8312 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4330 - precision: 0.8329 - recall: 0.8515 - val_loss: 0.3959 - val_precision: 0.8567 - val_recall: 0.8471 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4232 - precision: 0.8352 - recall: 0.8558 - val_loss: 0.3994 - val_precision: 0.8639 - val_recall: 0.8392 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4259 - precision: 0.8338 - recall: 0.8529 - val_loss: 0.4065 - val_precision: 0.8228 - val_recall: 0.8949 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4285 - precision: 0.8318 - recall: 0.8551 - val_loss: 0.4041 - val_precision: 0.8316 - val_recall: 0.8806 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 2s 91ms/step - loss: 0.4271 - precision: 0.8344 - recall: 0.8515 - val_loss: 0.3992 - val_precision: 0.8276 - val_recall: 0.8790 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 2s 90ms/step - loss: 0.4218 - precision: 0.8370 - recall: 0.8596 - val_loss: 0.4037 - val_precision: 0.8519 - val_recall: 0.8519 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 2s 94ms/step - loss: 0.4289 - precision: 0.8343 - recall: 0.8541 - val_loss: 0.3996 - val_precision: 0.8328 - val_recall: 0.8726 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x7844ec819cf0>, because it is not built.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training complete\n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "# sig_dict_chat = {\n",
        "#     \"EOG\": [0, 1],\n",
        "#     \"EEG\": [4, 5],\n",
        "#     \"ECG\": [15,16],\n",
        "#     \"Resp\": [9, 10],\n",
        "#     \"SPO2\": [13],\n",
        "#     \"CO2\": [14],\n",
        "# }\n",
        "\n",
        "# channel_list_chat = [\n",
        "#     [\"ECG\", \"SPO2\"]\n",
        "# ]\n",
        "\n",
        "# for ch in channel_list_chat:\n",
        "#     chs = []\n",
        "#     chstr = \"\"\n",
        "#     for name in ch:\n",
        "#         chstr += name\n",
        "#         chs = chs + sig_dict_chat[name]\n",
        "#     print(chstr, chs)\n",
        "#     config = {\n",
        "#         \"data_path\": data_path + 'chat_',\n",
        "#         \"model_path\": model_path,\n",
        "#         \"model_name\": \"model_10trasformerlayer_\"+ chstr,\n",
        "#         \"regression\": False,\n",
        "#         \"epochs\": 100,\n",
        "#         \"channels\": chs,\n",
        "#     }\n",
        "#     train(config, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGDYZRgwap2O",
        "outputId": "2c514cae-c7b1-45ca-d33c-52bb57dd1adb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "(2474, 3840, 17)\n",
            "(2474, 3840, 3)\n",
            "(3034, 3840, 17)\n",
            "(3034, 3840, 3)\n",
            "(3541, 3840, 17)\n",
            "(3541, 3840, 3)\n",
            "(3952, 3840, 17)\n",
            "(3952, 3840, 3)\n",
            "(3506, 3840, 17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3506, 3840, 3)\n",
            "test starting\n",
            "78/78 [==============================] - 3s 15ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95/95 [==============================] - 3s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 3s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "124/124 [==============================] - 3s 14ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 3s 15ms/step\n",
            "=========================================================================== \n",
            "[84.03395311236864, 85.92617007251152, 80.48573849195144, 85.98178137651821, 84.45521962350256] \n",
            "[84.69217970049917, 86.11300204220558, 78.31074035453598, 86.50918635170603, 84.37862950058071] \n",
            "[82.83157038242473, 85.01344086021506, 84.52447945976364, 84.73007712082263, 84.03701561596299] \n",
            "[85.22088353413655, 86.80465717981889, 76.41723356009071, 87.19481813652217, 84.86212718064154] \n",
            "[83.75154257507198, 85.55968887385863, 81.29905277401895, 85.61038961038963, 84.20747609388583] \n",
            "[91.5688139049281, 92.61404735077689, 87.60829036172713, 92.18895818363237, 91.31102289293209] \n",
            "[90.13142981548908, 91.87645144016732, 86.57728616166679, 91.07255823789431, 90.01140651543938] \n",
            "Accuracy: 84.18 -+ 2.002 \n",
            "Precision: 84.00 -+ 2.958 \n",
            "Recall: 84.23 -+ 0.767 \n",
            "Specifity: 84.10 -+ 3.943 \n",
            "F1: 84.09 -+ 1.574 \n",
            "AUROC: 91.06 -+ 1.785 \n",
            "AUPRC: 89.93 -+ 1.810 \n",
            "$ 84.2 \\pm 2.0$& $84.0 \\pm 3.0$& $84.2 \\pm 0.8$& $84.1 \\pm 1.6$& $91.1 \\pm 1.8$& \n"
          ]
        }
      ],
      "source": [
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "sig_dict_chat = {\n",
        "    \"EOG\": [0, 1],\n",
        "    \"EEG\": [4, 5],\n",
        "    \"ECG\": [15,16],\n",
        "    \"Resp\": [9, 10],\n",
        "    \"SPO2\": [13],\n",
        "    \"CO2\": [14],\n",
        "}\n",
        "\n",
        "channel_list_chat = [\n",
        "    [\"ECG\", \"SPO2\"],\n",
        "]\n",
        "\n",
        "for ch in channel_list_chat:\n",
        "    chs = []\n",
        "    chstr = \"\"\n",
        "    for name in ch:\n",
        "        chstr += name\n",
        "        chs = chs + sig_dict_chat[name]\n",
        "    print(chstr, chs)\n",
        "    config = {\n",
        "        \"data_path\": data_path + 'chat_',\n",
        "        \"model_path\": model_path,\n",
        "        \"model_name\": \"model_10trasformerlayer_\"+ chstr,\n",
        "        \"channels\": chs,\n",
        "    }\n",
        "    test(config, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hqOfuYCu-aG",
        "outputId": "86458d5f-58e6-402a-b558-acc55ca40a20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: model/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO22/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO22/assets/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO22/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO22/keras_metadata.pb (deflated 92%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO22/saved_model.pb (deflated 89%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO22/variables/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO22/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO22/variables/variables.index (deflated 69%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO24/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO24/assets/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO24/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO24/keras_metadata.pb (deflated 92%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO24/saved_model.pb (deflated 89%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO24/variables/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO24/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO24/variables/variables.index (deflated 69%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO23/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO23/assets/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO23/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO23/keras_metadata.pb (deflated 92%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO23/saved_model.pb (deflated 89%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO23/variables/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO23/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO23/variables/variables.index (deflated 69%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO23/ (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO23/assets/ (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO23/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO23/keras_metadata.pb (deflated 94%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO23/saved_model.pb (deflated 91%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO23/variables/ (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO23/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO23/variables/variables.index (deflated 77%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO24/ (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO24/assets/ (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO24/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO24/keras_metadata.pb (deflated 94%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO24/saved_model.pb (deflated 91%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO24/variables/ (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO24/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO24/variables/variables.index (deflated 77%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO20/ (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO20/assets/ (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO20/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO20/keras_metadata.pb (deflated 94%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO20/saved_model.pb (deflated 91%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO20/variables/ (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO20/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO20/variables/variables.index (deflated 77%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO21/ (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO21/assets/ (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO21/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO21/keras_metadata.pb (deflated 94%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO21/saved_model.pb (deflated 91%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO21/variables/ (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO21/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO21/variables/variables.index (deflated 77%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO20/ (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO20/assets/ (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO20/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO20/keras_metadata.pb (deflated 94%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO20/saved_model.pb (deflated 90%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO20/variables/ (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO20/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO20/variables/variables.index (deflated 74%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO22/ (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO22/assets/ (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO22/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO22/keras_metadata.pb (deflated 94%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO22/saved_model.pb (deflated 91%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO22/variables/ (stored 0%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO22/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: model/model_10trasformerlayer_ECGSPO22/variables/variables.index (deflated 77%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO21/ (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO21/assets/ (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO21/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO21/keras_metadata.pb (deflated 94%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO21/saved_model.pb (deflated 90%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO21/variables/ (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO21/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO21/variables/variables.index (deflated 74%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO21/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO21/assets/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO21/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO21/keras_metadata.pb (deflated 92%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO21/saved_model.pb (deflated 89%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO21/variables/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO21/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO21/variables/variables.index (deflated 69%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO23/ (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO23/assets/ (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO23/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO23/keras_metadata.pb (deflated 94%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO23/saved_model.pb (deflated 90%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO23/variables/ (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO23/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO23/variables/variables.index (deflated 74%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO22/ (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO22/assets/ (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO22/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO22/keras_metadata.pb (deflated 94%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO22/saved_model.pb (deflated 90%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO22/variables/ (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO22/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO22/variables/variables.index (deflated 74%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO24/ (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO24/assets/ (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO24/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO24/keras_metadata.pb (deflated 94%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO24/saved_model.pb (deflated 90%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO24/variables/ (stored 0%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO24/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: model/model_3trasformerlayer_ECGSPO24/variables/variables.index (deflated 74%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO20/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO20/assets/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO20/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO20/keras_metadata.pb (deflated 92%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO20/saved_model.pb (deflated 89%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO20/variables/ (stored 0%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO20/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: model/model_1trasformerlayer_ECGSPO20/variables/variables.index (deflated 69%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r model.zip model/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWh3xQF0WgsU"
      },
      "source": [
        "####Discussion of ablation experiment\n",
        "As seen in the cells above, the performance is best for 10 layers, albeit not by much across all metrics. For instance, increasing from 5 layers to 10 layers has a percentage increase of .83% for accuracy and of .46% for AUROC. This is a bit surprising as we expect more transformer layers to be able to understand more complexities in the data. However, in the case of precision for example, it increases from 82.04 to 84.00 as the layers are increased from 5 to 10, thereby giving a bigger jump in performance. Overall, as observed by the results, more layers does not necessarily mean greatly better performance across all metrics.\n",
        "\n",
        "\n",
        "Below is a table summarizing these metrics for the different layer configurations. Values that are bolded are the highest values within each column. All of these results reported below are for experiments that had all factors the same besides the number of layers (i.e. all the number of epochs were 100, learning rate schedule was the same...).\n",
        "\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1W8NgzUSerGnUf_rA5GVPwUf6UZQDXqsg\"/>\n",
        "</div>\n",
        "\n",
        "One notable metric highlighted yellow is the Recall for 5 transformer layers. This indicates that out of all the positive apnea records, the model with 5 transformer layers had the best ability to detect these positive instances.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX6bCcZNuxmz"
      },
      "source": [
        "# Results\n",
        "In this section, you should finish training your model training or loading your trained model. That is a great experiment! You should share the results with others with necessary metrics and figures.\n",
        "\n",
        "Please test and report results for all experiments that you run with:\n",
        "\n",
        "*   specific numbers (accuracy, AUC, RMSE, etc)\n",
        "*   figures (loss shrinkage, outputs from GAN, annotation or label of sample pictures, etc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwxM_a4LCtD9"
      },
      "source": [
        "##Testing + Results Output\n",
        "After every experiment conducted above, there is a data table associated with its respective model performances.\n",
        "\n",
        "Each Model is tested using that fold's data (since it wasn't used in the training of that model). x_test and y_test are setup similar to the training, except we only use the respective fold's data.\n",
        "\n",
        "We use the author's metrics code to generate the results of the model. Each model's results are added to the results object. Once all fold's results are completed, the metrics are calculated and outputted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EAWAy_LwHlV"
      },
      "source": [
        "##Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOdhGrbwwG71"
      },
      "outputs": [],
      "source": [
        "# compare your model with others\n",
        "# you don't need to re-run all other experiments, instead, you can directly refer the metrics/numbers in the paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N9JbHB2ELRV"
      },
      "source": [
        "To highlight the main model's result, it is included here below:\n",
        "\n",
        "Our transformer model using ECG + SpO2 signals with 100 epochs on CHAT dataset had the following results:\n",
        "* F1: 83.69\n",
        "* AUROC: 90.64\n",
        "\n",
        "\n",
        "The original paper's ECG + SpO2  had the following F1 and AUROC using the CHAT Dataset (Found in Table 4 of the paper):\n",
        "* F1: 82.5(0.7)\n",
        "* AUROC: 89.4(0.7)\n",
        "\n",
        "These metrics are summarized in this table below.\n",
        "\n",
        "\n",
        "(**Note that the authors just reported F1 and AUROC, not all the other metrics defined in the Evaluation section**).\n",
        "\n",
        "<div>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1EyBiVyumg6lIuxuqxsqqtDFuUQ1ALWWY\"/>\n",
        "</div>\n",
        "\n",
        "It is interesting that although our model performance is similar to the author's model performance, it is actually somewhat better.\n",
        "We hypothesize this is because we used a different amount of data as compared to the author's. Perhaps the model was able to better generalize on our subset of the data.\n",
        "\n",
        "Ultimately, with respect to the original hypothesis to predict hyopnea-apnea in children, our implementation of the paper's transformer model performs well, on par with the author's model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH75TNU71eRH"
      },
      "source": [
        "# Discussion/Analyses\n",
        "\n",
        "In this section,you should discuss your work and make future plan. The discussion should address the following questions:\n",
        "  * Make assessment that the paper is reproducible or not.\n",
        "  * Explain why it is not reproducible if your results are kind negative.\n",
        "  * Describe “What was easy” and “What was difficult” during the reproduction.\n",
        "  * Make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
        "  * What will you do in next phase.\n",
        "\n",
        "---\n",
        "\n",
        "After looking through all the individual components of the original paper, we conclude that the paper is reproducible. For the draft, the model performance was not the same as what the original paper shows because we were only processing a small subset of the data, however we once we utilized more data, we achieved the results on par with what is described in the original paper. In fact, we got closer to the author's results by re-implementing the model correctly instead of using the hybrid-transformer as we discussed in the models section in **Draft Mistake**.\n",
        "\n",
        "The overall experience of reproducing the paper was satisfying as it had sections that were easy as well as difficult.\n",
        "\n",
        "The easiest section was understanding the overall flow of data throughout the high-level overview of the model. The authors' code in GitHub provided a great way to understand their implementation details.\n",
        "\n",
        "However, the actual implementation of the model was difficult because there were practical decisions that needed to be made. One such decision was where to store the data for easy use of preprocessing, training, and testing; we decided to upload all data to a Box account due to its ability to store large sizes of data and allow for easy connection and retrieval of data for machine learning tasks. Likewise, another difficult decision was determining resources that could be used to handle all the machine learning operations. The free version of Google Colab was used, which we found did not have enough RAM for training our model. We had to upgrade to Colab Pro to gain access to a higher RAM machine, which still did not have enough for the full processed dataset. We ended up using a subset of the data for training.\n",
        "\n",
        "One final difficult decision was whether we should utilize the same functions provided in the original paper’s GitHub; we decided that we could not use the same functions exactly as they were given due to some hard-coded values in those functions and so, instead we made some slight modifications to be able to work with our setup. In the process of reproducing the original paper, several helper functions needed to be implemented and many version-specific code libraries were utilized. In the future, these helper functions being available and explicit indications of the versions of libraries used will help improve reproducibility and allow individuals to focus more time on advancing the model and seeing better results.\n",
        "\n",
        "To the authors, we have a couple of suggestions. First, it would be helpful to make the code more generic for reproducibility. For instance, we had to manually copy and paste some functions that had hardcoded local data paths. If these data paths are accounted for in a config file, it would make those functions readily reproducible. Secondly, the authors should include a pip requirements file that shows which versions of packages they used; in one instance, we were met with an error during preprocessing because the latest \"mne\" library version we installed did not have the same functionality as the older \"mne\" version that the authors used. Thus, we had to install the specific version the authors used to get the code to work. FInally, we suggest that more comments in the code that links the ideas from the paper to the code would be helpful for a reader to bridge the gap between the theoretical solution to the solution in code. It was at first somewhat challenging to understand the segmentation and tokenization steps, so clearly outlining what the preprocessing steps are doing will help readers understand the data methodology better.\n",
        "\n",
        "#Final Draft Plans (completed)\n",
        "In the final submission phase, we changed the model we are using to the author's model to correct the mistake used in the first draft.\n",
        "\n",
        "We also used more CHAT data to train and test the model. We were not able to use all the data due to Colab size limitations, however we used more than what we did in the first draft.\n",
        "\n",
        "We also trained models using all 6 signals as well as discussed in the paper (EOG, EEG, ECG, Resp, SpO2, CO2).\n",
        "\n",
        "We compared our 2 Signal (ECG, SpO2) model to the authors, as well as to the 6 signal model. We additionally performed other experiments involving changing dropout, learning rate scheduler algorithm, and the number of epochs.\n",
        "\n",
        "As part of our ablations in our proposal, we removed transformer layers to see how it affected the model performance.\n",
        "\n",
        "Ultimately, the data and model implementations were reproducible and produced similar performance to that of the author's results.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHMI2chl9omn"
      },
      "source": [
        "# References\n",
        "\n",
        "1. Fayyaz H, Strang A, Beheshti R. Bringing At-home Pediatric Sleep Apnea Testing Closer to Reality: A Multi-modal Transformer Approach. Proc Mach Learn Res. 2023 Aug;219:167-185. PMID: 38344396; PMCID: PMC10854997.\n",
        "\n",
        "2. Choi Ji Ho, Kim Eun Joong, Choi June, Kwon Soon Young, Kim Tae Hoon, Lee Sang Hag, Lee Heung Man, Shin Choi, and Lee Seung Hoon. Obstructive sleep apnea syndrome: a child is not just a small adult. Annals of Otology, Rhinology & Laryngology, 119(10): 656–661, 2010.\n",
        "\n",
        "3. Gipson Kevin, Lu Mengdi, and Kinane T Bernard. Sleep-disordered breathing in children. Pediatrics in review, 40(1):3, 2019.\n",
        "\n",
        "4. Loughlin GM, Brouillette RT, Brooke LJ, Carroll JL, Chipps BE, England SJ, Ferber P, Ferraro NF, Gaultier C, Givan DC, et al. Standards and indications for cardiopulmonary sleep studies in children. American journal of respiratory and critical care medicine, 153 (2):866–878, 1996.\n",
        "\n",
        "5. Marcus Carole L, Brooks Lee J, Ward Sally Davidson, Draper Kari A, Gozal David, Halbower Ann C, Jones Jacqueline, Lehmann Christopher, Schechter Michael S, Sheldon Stephen, et al. Diagnosis and management of childhood obstructive sleep apnea syndrome. Pediatrics, 130(3):e714–e755, 2012.\n",
        "\n",
        "6. Spielmanns Marc, Bost David, Windisch Wolfram, Alter Peter, Greulich Tim, Nell Christoph, Storre Jan Henrik, Koczulla Andreas Rembert, and Boeselt Tobias. Measuring sleep quality and\n",
        "efficiency with an activity monitoring device in comparison to polysomnography. Journal of clinical medicine research, 11(12):825, 2019.\n",
        "\n",
        "7. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017b.\n",
        "\n",
        "8. Hu Shuaicong, Cai Wenjie, Gao Tijie, and Wang Mingjie. A hybrid transformer model for obstructive sleep apnea detection based on self-attention mechanism using single-lead ecg. IEEE Transactions on Instrumentation and Measurement, 71:1–11, 2022.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAe2BdBGMDdx"
      },
      "source": [
        "**Draft Mistake (corrected in final submission) ** The model we created is actually the hybrid-transformer (Hu et al., 2022) that the author's compared their original model to. When checking the author's GitHub Repository, it looks like the last configuration they setup was for the comparison to the hybrid-transformer, which led to our confusion. Due to first draft deadline, we could not  train the author's model in time. For the final draft, we trained and tested the author's original model (provided in line 109 https://github.com/healthylaife/Pediatric-Apnea-Detection/blob/main/models/models.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m450bfOHpjQ"
      },
      "outputs": [],
      "source": [
        "# this function is provided in the paper's github repo but we included it here for clarity/describing key components\n",
        "# from create_hybrid_transformer_model - https://github.com/healthylaife/Pediatric-Apnea-Detection/blob/main/models/transformer.py\n",
        "\n",
        "\n",
        "\n",
        "#input shape used in paper (didn't work): ((60 * 32, 3))\n",
        "#Used ((128*30,3)) which matches dataloader.\n",
        "def create_model(input_shape):\n",
        "    transformer_units = [32,32]\n",
        "    transformer_layers = 2\n",
        "    num_heads = 4\n",
        "    l2_weight = 0.001\n",
        "    drop_out= 0.25\n",
        "    mlp_head_units = [256, 128]\n",
        "    num_patches= 30\n",
        "    projection_dim= 32\n",
        "\n",
        "    input1 = Input(shape=input_shape)\n",
        "    conv11 = Conv1D(16, 256)(input1)\n",
        "    conv12 = Conv1D(16, 256)(input1)\n",
        "    conv13 = Conv1D(16, 256)(input1)\n",
        "\n",
        "    pwconv1 = SeparableConvolution1D(32, 1)(input1)\n",
        "    pwconv2 = SeparableConvolution1D(32, 1)(pwconv1)\n",
        "\n",
        "    conv21 = Conv1D(16, 256)(conv11)\n",
        "    conv22 = Conv1D(16, 256)(conv12)\n",
        "    conv23 = Conv1D(16, 256)(conv13)\n",
        "\n",
        "    concat = concatenate([conv21, conv22, conv23], axis=-1)\n",
        "    concat = Dense(64, activation=relu)(concat)\n",
        "    concat = Dense(64, activation=sigmoid)(concat)\n",
        "    concat = SeparableConvolution1D(32,1)(concat)\n",
        "    concat = concatenate([concat, pwconv2], axis=1)\n",
        "\n",
        "    ####################################################################################################################\n",
        "    patch_size = input_shape[0] / num_patches\n",
        "\n",
        "    normalized_inputs = tfa.layers.InstanceNormalization(axis=-1, epsilon=1e-6, center=False, scale=False,\n",
        "                                                            beta_initializer=\"glorot_uniform\",\n",
        "                                                            gamma_initializer=\"glorot_uniform\")(concat)\n",
        "\n",
        "    patches = Patches(patch_size=patch_size)(normalized_inputs)\n",
        "    encoded_patches = PatchEncoder(num_patches=num_patches, projection_dim=projection_dim, l2_weight=l2_weight)(patches)\n",
        "\n",
        "    for i in range(transformer_layers):\n",
        "        x1 = encoded_patches # LayerNormalization(epsilon=1e-6)(encoded_patches) # TODO\n",
        "        attention_output = MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=drop_out, kernel_regularizer=L2(l2_weight),  # i *\n",
        "            bias_regularizer=L2(l2_weight))(x1, x1)\n",
        "        x2 = Add()([attention_output, encoded_patches])\n",
        "        x3 = LayerNormalization(epsilon=1e-6)(x2)\n",
        "        x3 = mlp(x3, transformer_units, drop_out, l2_weight)  # i *\n",
        "        encoded_patches = Add()([x3, x2])\n",
        "\n",
        "    x = LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    #x = Concatenate()([x, demo])\n",
        "    features = mlp(x, mlp_head_units, 0.0, l2_weight)\n",
        "\n",
        "    logits = Dense(1, kernel_regularizer=L2(l2_weight), bias_regularizer=L2(l2_weight),\n",
        "                   activation='sigmoid')(features)\n",
        "\n",
        "    ####################################################################################################################\n",
        "\n",
        "    model = Model(inputs=input1, outputs=logits)\n",
        "    return model\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}