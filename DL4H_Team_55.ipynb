{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning for Healthcare Team 55 Project\n",
        "### Zeeshan Haidry, Hamza Mahmood, Nithin Nathan\n",
        "\n",
        "Team 55 GitHub Repo: https://github.com/zeeshanhaidry/cs598dlh-team55\n",
        "\n",
        "Project based on:\n",
        "Fayyaz H, Strang A, Beheshti R. Bringing At-home Pediatric Sleep Apnea Testing Closer to Reality: A Multi-modal Transformer Approach. Proc Mach Learn Res. 2023 Aug;219:167-185. PMID: 38344396; PMCID: PMC10854997.\n",
        "\n",
        "Original GitHub: https://github.com/healthylaife/Pediatric-Apnea-Detection"
      ],
      "metadata": {
        "id": "FGRuTbxYyOHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instead of drive, we will be using uofi box\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sfk8Zrul_E8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dependencies\n",
        "\n",
        "!pip install biosppy\n",
        "!pip install boxsdk\n",
        "!pip install mne==1.0\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow-addons\n",
        "!pip install gdown"
      ],
      "metadata": {
        "id": "3tf3Il_ls9eQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81a6007-9c37-4f7e-d33c-76218bcef8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biosppy in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: bidict in /usr/local/lib/python3.10/dist-packages (from biosppy) (0.23.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from biosppy) (3.9.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from biosppy) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.11.4)\n",
            "Requirement already satisfied: shortuuid in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.0.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.4.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from biosppy) (4.8.0.76)\n",
            "Requirement already satisfied: pywavelets in /usr/local/lib/python3.10/dist-packages (from biosppy) (1.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->biosppy) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->biosppy) (3.4.0)\n",
            "Collecting boxsdk\n",
            "  Using cached boxsdk-3.9.2-py2.py3-none-any.whl (139 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from boxsdk) (23.2.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from boxsdk) (2.0.7)\n",
            "Requirement already satisfied: requests<3,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from boxsdk) (2.31.0)\n",
            "Collecting requests-toolbelt>=0.4.0 (from boxsdk)\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from boxsdk) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.4.3->boxsdk) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.4.3->boxsdk) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.4.3->boxsdk) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->boxsdk) (1.16.0)\n",
            "Installing collected packages: requests-toolbelt, boxsdk\n",
            "Successfully installed boxsdk-3.9.2 requests-toolbelt-1.0.0\n",
            "Collecting mne==1.0\n",
            "  Using cached mne-1.0.0-py3-none-any.whl (7.5 MB)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (4.66.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (1.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (4.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (24.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne==1.0) (3.1.3)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne==1.0) (4.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne==1.0) (2.31.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne==1.0) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne==1.0) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne==1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne==1.0) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne==1.0) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne==1.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne==1.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mne==1.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mne==1.0) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne==1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne==1.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne==1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne==1.0) (2024.2.2)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.0.0\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# authenticate to connect to uofi box\n",
        "\n",
        "# Data was uploaded to box from sleepdata website. (Link provided in data section)\n",
        "# Commented to allow remaining of project to run since secrets might not be setup.\n",
        "\n",
        "from google.colab import userdata\n",
        "from boxsdk import Client, OAuth2, CCGAuth\n",
        "from boxsdk.object import file, folder\n",
        "from pprint import pformat\n",
        "import json\n",
        "\n",
        "# CLIENT_ID = userdata.get('clientid2')\n",
        "# CLIENT_SECRET = userdata.get('clientsecret2')\n",
        "# ACCESS_TOKEN = userdata.get('token2')\n",
        "\n",
        "# oauth2 = OAuth2(CLIENT_ID, CLIENT_SECRET, access_token=ACCESS_TOKEN)\n",
        "# client = Client(oauth2)"
      ],
      "metadata": {
        "id": "T_IZxkMKF8ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "This is an introduction to your report, you should edit this text/mardown section to compose. In this text/markdown, you should introduce:\n",
        "\n",
        "*   Background of the problem\n",
        "  * what type of problem: disease/readmission/mortality prediction,  feature engineeing, data processing, etc\n",
        "  * what is the importance/meaning of solving the problem\n",
        "  * what is the difficulty of the problem\n",
        "  * the state of the art methods and effectiveness.\n",
        "*   Paper explanation\n",
        "  * what did the paper propose\n",
        "  * what is the innovations of the method\n",
        "  * how well the proposed method work (in its own metrics)\n",
        "  * what is the contribution to the reasearch regime (referring the Background above, how important the paper is to the problem).\n",
        "\n",
        "---\n",
        "\n",
        "Obstructive sleep apnea hypopnea syndrome (OSAHS) is a breathing disorder where breathing is obstructed while sleeping (Loughlin Et al, 1996). Sleep apnea affects 1%-5% of children in the United States and can lead to other health illnesses if left untreated (Loughlin Et al, 1996; Marcus et al, 2012). Currently, at-home diagnostic tools for sleep apnea are only available for adults, leaving room for models to be created to address the needs for children (Fayyaz et al, 2023). The current state-of-the-art sleep apnea detection models created for adults (CNN (Chang et al., 2020), SE-MSCNN (Chen et al., 2022), CNN+LSTM (Zarei et al., 2022), Hybrid Transformer (Hu et al., 2022)) are effective but cannot be used for children because the sleep data differs between the two, and OSAHS symptoms for children require more attention (Choi et al, 2010; Gipson et al, 2019).\n",
        "\n",
        "Polysomnography is commonly used to diagnose OSAHS. This process is used to collect various signals while sleeping such as brain activity (EEG), eye movement (EOG), heart rhythm (ECG), blood oxygen saturation (SpO2), blood CO2 levels (ETCO2), and air flow. Although polysomnography is the best method to diagnose OSAHS, it is complex, costly, intrusive, and requires clinician involvement (Spielmanns et al, 2019). Because of these issues, it is not easy for children and their families to use polysomnography to detect OSAHS at home. To address these issues, Fayyaz et al. propose a transformer-based model to help detect OSAHS in children.  Additionally, they compared using all the available polysomnography modalities to only a subset of the available modalities in the model, which is important because a subset of modalities may be significantly easier to collect at home, so finding if a subset performs as well as all polysomnography modalities data increases the feasibility of at-home detection. In terms of metrics, the proposed transformer-based model outperforms the current state-of-the-art sleep apnea detection models, and an additional edge of factoring demographic data into the modalities improves the proposed modelâ€™s performance even further.\n",
        "\n"
      ],
      "metadata": {
        "id": "MQ0sNuMePBXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope of Reproducibility:\n",
        "\n",
        "List hypotheses from the paper you will test and the corresponding experiments you will run.\n",
        "---\n",
        "\n",
        "The present study is based on the primary hypothesis that it is possible to achieve adult-level performance in detecting OSAHS. Specifically, through a custom transformer-based neural network, and its input in the form of preprocessed ECG and SPO2 signals, we hypothesize that we can effectively study and classify apnea-hypopnea in children."
      ],
      "metadata": {
        "id": "uygL9tTPSVHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology\n",
        "\n",
        "This methodology is the core of your project. It consists of run-able codes with necessary annotations to show the expeiment you executed for testing the hypotheses.\n",
        "\n",
        "The methodology at least contains two subsections **data** and **model** in your experiment."
      ],
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we will be re-using the authors code for data pre-processing and loading, we will also extract some code for the model\n",
        "!git clone https://github.com/healthylaife/Pediatric-Apnea-Detection.git"
      ],
      "metadata": {
        "id": "81txHSSEEPlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d29c5ae7-c0d5-40c9-c70b-e22bcde0f94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Pediatric-Apnea-Detection'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 75 (delta 33), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (75/75), 31.40 KiB | 2.62 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rename cloned github folder for easier access to its functions\n",
        "\n",
        "import os\n",
        "source = 'Pediatric-Apnea-Detection/'\n",
        "dest = 'PediatricApneaDetection/'\n",
        "os.rename(source, dest)"
      ],
      "metadata": {
        "id": "VSsNiJsK3BDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages needed for data preprocessing, loading, and model training/testing\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "import keras\n",
        "from keras import Model\n",
        "from keras.callbacks import LearningRateScheduler, EarlyStopping\n",
        "from keras.activations import sigmoid, relu\n",
        "from keras.layers import Dense, Input, Conv1D, SeparableConvolution1D, concatenate, Layer, MultiHeadAttention, Add, LayerNormalization, Dropout, GlobalAveragePooling1D\n",
        "from keras.regularizers import L2\n",
        "from keras.losses import BinaryCrossentropy\n",
        "\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check if gpu available.\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "metadata": {
        "id": "ZeTeJKQiwVt0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3dd5d40-d70c-4c9a-fd73-3c6e1202e91d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 10609431299909879245\n",
            "xla_global_id: -1\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Data\n",
        "Data includes raw data (MIMIC III tables), descriptive statistics (our homework questions), and data processing (feature engineering).\n",
        "  * Source of the data: where the data is collected from; if data is synthetic or self-generated, explain how. If possible, please provide a link to the raw datasets.\n",
        "  * Statistics: include basic descriptive statistics of the dataset like size, cross validation split, label distribution, etc.\n",
        "  * Data process: how do you munipulate the data, e.g., change the class labels, split the dataset to train/valid/test, refining the dataset.\n",
        "  * Illustration: printing results, plotting figures for illustration.\n",
        "  * You can upload your raw dataset to Google Drive and mount this Colab to the same directory. If your raw dataset is too large, you can upload the processed dataset and have a code to load the processed dataset.\n",
        "\n",
        "---\n",
        "\n",
        "The data is collected from the National Sleep Research Resource, an NHLBI-supported repository responsible for sharing large amounts of sleep data from various cohorts, clinical trials, and other data sources to advance sleep and circadian science. The two datasets we used can be found at these links: https://sleepdata.org/datasets/chat and https://sleepdata.org/datasets/nchsdb.\n",
        "\n",
        "We utilize two different datasets, one from a Childhood Adenotonsillectomy Trial (CHAT)\n",
        "And the other from the NCH Sleep Data Bank (NCHSDB).\n",
        "The CHAT dataset is roughly 969 GB in size and was collected from 1,243 subjects ages 5-9 over a period of 5 years (2007-2012). The NCHSDB dataset is roughly 2.07 TB in size and was collected from 3,673 subjects ages 0-58 over a period of 2 years (2017-2019).\n",
        "Both datasets will be pre-processed to only include necessary attributes before being loaded into the model for training and testing.\n",
        "The raw data has been uploaded to a Box account for storage since the University of Illinois provides us with unlimited Box storage. Because of the large size of the data, we are currently in the process of pre-processing subsets of data and uploading the processed datasets to a separate folder to be loaded into our model.\n",
        "\n",
        "\n",
        "**Due to large file sizes, we will only work on the CHAT dataset (only ~70GB available in Colab)**\n",
        "\n",
        "**For Draft: we will only use 10 files to ensure model training completes before deadline.**\n",
        "\n",
        "Two file types are used for the CHAT data construction, a \\*.edf file containing time-series for multiple signals and a \\*-nsrr.xml that contains annotations of the dataset. These annotations described events that happened during the study such as obstructive apnea, central apnea, hypopnea, SpO2 desaturation, EtCO2 artifact, limb movements, etc. These events include event type/concept (description), start time (onset), and duration.\n",
        "\n",
        "For this model, we only consider apnea (Obstructive and Central grouped together) and hypopnea events."
      ],
      "metadata": {
        "id": "2NbPHUTMbkD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Commented to allow rest of the nodebook to run. (No Data processing/loading/training for Submission)\n",
        "\n",
        "# def downloadFromBox(filepath, file_content):\n",
        "#   with open(filepath, \"wb\") as binary_file:\n",
        "#     binary_file.write(file_content)\n",
        "\n",
        "# #First Download processed data from box. (TODO)\n",
        "# chat_out = '/content/chatprocessed/'\n",
        "# os.makedirs(os.path.dirname(chat_out), exist_ok=True)\n",
        "\n",
        "# processed_data = os.listdir(chat_out)\n",
        "\n",
        "# #Second, download raw + annot data from BOX that is not already downloaded, not in badFiles list and is not in in processed (So we don't have to re-process data)\n",
        "# chat_data = '/chatdata/'\n",
        "# os.makedirs(os.path.dirname(chat_data), exist_ok=True)\n",
        "# curr_downloaded = os.listdir(chat_data)\n",
        "\n",
        "# #empirically known bad files (such as missing signals)\n",
        "# badFiles = [\"chat-baseline-300013.edf\"]\n",
        "\n",
        "# fields = [\n",
        "#     'type',\n",
        "#     'id',\n",
        "#     'name',\n",
        "# ]\n",
        "# folder_raw = client.folder(folder_id='257515840362').get_items(fields=fields)\n",
        "# folder_annot = client.folder(folder_id='257513450272').get_items(fields=fields)\n",
        "# filenames = curr_downloaded\n",
        "\n",
        "# i = 0\n",
        "# for item in folder_raw:\n",
        "#   if i>=10:\n",
        "#     break\n",
        "#   if not any(processed.startswith(item.name.split('.')[0]) for processed in processed_data) and item.name not in curr_downloaded and item.name not in badFiles:\n",
        "#     print(f'download \"{item.name}\"')\n",
        "#     file_content = client.file(item.id).content()\n",
        "#     downloadFromBox(chat_data + item.name, file_content)\n",
        "#     filenames.append(item.name)\n",
        "#     i = i + 1\n",
        "# print(filenames)\n",
        "# for item in folder_annot:\n",
        "#   if (item.name.split('-nsrr')[0] + '.edf') in filenames and item.name not in curr_downloaded:\n",
        "#     print(f'download \"{item.name}\"')\n",
        "#     file_content = client.file(item.id).content()\n",
        "#     downloadFromBox(chat_data + item.name, file_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9BmsYS95LIq",
        "outputId": "1a958541-4bfe-4d83-ec9e-078bc29ba720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download \"chat-baseline-300001.edf\"\n",
            "download \"chat-baseline-300002.edf\"\n",
            "download \"chat-baseline-300004.edf\"\n",
            "download \"chat-baseline-300007.edf\"\n",
            "download \"chat-baseline-300008.edf\"\n",
            "download \"chat-baseline-300014.edf\"\n",
            "download \"chat-baseline-300015.edf\"\n",
            "download \"chat-baseline-300019.edf\"\n",
            "download \"chat-baseline-300021.edf\"\n",
            "download \"chat-baseline-300024.edf\"\n",
            "['chat-baseline-300001.edf', 'chat-baseline-300002.edf', 'chat-baseline-300004.edf', 'chat-baseline-300007.edf', 'chat-baseline-300008.edf', 'chat-baseline-300014.edf', 'chat-baseline-300015.edf', 'chat-baseline-300019.edf', 'chat-baseline-300021.edf', 'chat-baseline-300024.edf']\n",
            "download \"chat-baseline-300001-nsrr.xml\"\n",
            "download \"chat-baseline-300002-nsrr.xml\"\n",
            "download \"chat-baseline-300004-nsrr.xml\"\n",
            "download \"chat-baseline-300007-nsrr.xml\"\n",
            "download \"chat-baseline-300008-nsrr.xml\"\n",
            "download \"chat-baseline-300014-nsrr.xml\"\n",
            "download \"chat-baseline-300015-nsrr.xml\"\n",
            "download \"chat-baseline-300019-nsrr.xml\"\n",
            "download \"chat-baseline-300021-nsrr.xml\"\n",
            "download \"chat-baseline-300024-nsrr.xml\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Annotation file conversion + Pre-processing\n",
        "Annotation File is required to be in tsv format in the paper's provided code.\n",
        "Since the Sleep data site only had this in XML, we had to convert it and change column names as shown below.\n",
        "\n",
        "The Pre-processing code does the following:\n",
        "\n",
        "\n",
        "*   Loads study using raw \\*.edf and annoations \\*-nsrr.tsv file using mne library. Annoations file is read in as a dataframe. (pandas read_cdv)\n",
        "*   Checks if required channels are avaiable in the study. If not, it is discarded.\n",
        "*   Finds event ids of apnea and hypopnea events in annoations\n",
        "*   Select specific channels from raw file.\n",
        "*   Signals are divided into equal length epochs (authors chose **30 EPOCH_LENGTH**),\n",
        "*   Epochs are resampled to a **frequency of 128**.\n",
        "*   For each Epoch, the intersection between the apnea events and hypopnea events are found in seconds, and appended to a labels_apnea and labels_hypopnea array. Essentially, these labels contains seconds of apnea and hypopnea, respectively, for each epoch.\n",
        "*   The numpy array containing data, labels_apnea, and labels_hypopnea are saved.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JhTUi_pRthQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import xml.etree.ElementTree as ET\n",
        "import csv\n",
        "\n",
        "def convert_xml_to_tsv(xml_file):\n",
        "\n",
        "  # parse the xml file\n",
        "  tree = ET.parse(xml_file)\n",
        "  root = tree.getroot()\n",
        "\n",
        "  # grab the relevant fields from the xml - Start (onset) , Duration (Duration), EventType (Description)\n",
        "  fields = ['onset', 'duration', 'description']\n",
        "\n",
        "  # create new tsv file\n",
        "  tsv_file_name = xml_file.replace(\".xml\", \".tsv\")\n",
        "\n",
        "  # create csv writer object\n",
        "  csv_writer = csv.writer(open(tsv_file_name, 'w'), delimiter='\\t')\n",
        "\n",
        "  # write the header row\n",
        "  csv_writer.writerow(fields)\n",
        "\n",
        "  # iterate over the xml elements and extract the data we want\n",
        "  for element in root:\n",
        "\n",
        "      if element.tag == \"ScoredEvents\":\n",
        "\n",
        "        # this is all events\n",
        "        for event in element:\n",
        "\n",
        "          # this is single event\n",
        "          for attr in event:\n",
        "\n",
        "            if attr.tag == \"Start\":\n",
        "              onset = attr.text\n",
        "\n",
        "            if attr.tag == \"Duration\":\n",
        "              duration = attr.text\n",
        "\n",
        "            if attr.tag == \"EventConcept\":\n",
        "              description = attr.text.split(\"|\")[0]\n",
        "\n",
        "          # for field in fields\n",
        "          row = [onset, duration, description]\n",
        "\n",
        "          # write row to csv file\n",
        "          csv_writer.writerow(row)"
      ],
      "metadata": {
        "id": "wqb5Jwsyh5P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Commented to allow rest of notebook to run. (No Data processing/loading/training for Submission)\n",
        "\n",
        "# import glob\n",
        "# import mne\n",
        "# from PediatricApneaDetection.data.chat import preprocessing\n",
        "\n",
        "# root = \"/chatdata/\"\n",
        "# OUT_FOLDER = ''\n",
        "\n",
        "# for edf_file in glob.glob(root + \"*.edf\"):\n",
        "#         print(\"preprocessing \" + edf_file)\n",
        "\n",
        "#         annot_file = edf_file.replace(\".edf\", \"-nsrr.xml\")\n",
        "#         convert_xml_to_tsv(annot_file)\n",
        "#         annot_file_tsv = edf_file.replace(\".edf\", \"-nsrr.tsv\")\n",
        "\n",
        "#         # preprocess data\n",
        "#         shape = preprocessing.preprocess((edf_file, annot_file_tsv), preprocessing.identity, OUT_FOLDER)\n",
        "\n",
        "#         print(f\"final preprocessing shape: {shape}\")"
      ],
      "metadata": {
        "id": "Eh5QH6ynXXc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed784061-313c-44b4-878f-caaa8fc21316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessing /chatdata/chat-baseline-300002.edf\n",
            "17:47:22 --- Processing chat-baseline-300002.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n",
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done  10 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=8)]: Done 365 tasks      | elapsed:    7.6s\n",
            "[Parallel(n_jobs=8)]: Done 5839 tasks      | elapsed:   15.1s\n",
            "[Parallel(n_jobs=8)]: Done 13840 tasks      | elapsed:   20.4s\n",
            "[Parallel(n_jobs=8)]: Done 24208 tasks      | elapsed:   28.7s\n",
            "[Parallel(n_jobs=8)]: Done 27198 out of 27198 | elapsed:   30.6s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final preprocessing shape: 971\n",
            "preprocessing /chatdata/chat-baseline-300007.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/PediatricApneaDetection/data/chat/preprocessing.py:98: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw.set_annotations(annotations)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:48:50 --- Processing chat-baseline-300007.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done  12 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=8)]: Done 1016 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=8)]: Done 3896 tasks      | elapsed:    7.1s\n",
            "[Parallel(n_jobs=8)]: Done 7928 tasks      | elapsed:   12.7s\n",
            "[Parallel(n_jobs=8)]: Done 13112 tasks      | elapsed:   21.5s\n",
            "[Parallel(n_jobs=8)]: Done 19448 tasks      | elapsed:   31.7s\n",
            "[Parallel(n_jobs=8)]: Done 21474 out of 21474 | elapsed:   34.7s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final preprocessing shape: 925\n",
            "preprocessing /chatdata/chat-baseline-300004.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/PediatricApneaDetection/data/chat/preprocessing.py:98: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw.set_annotations(annotations)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:51:19 --- Processing chat-baseline-300004.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done  12 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=8)]: Done 1528 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=8)]: Done 7288 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=8)]: Done 15352 tasks      | elapsed:    9.3s\n",
            "[Parallel(n_jobs=8)]: Done 22356 tasks      | elapsed:   15.1s\n",
            "[Parallel(n_jobs=8)]: Done 22518 out of 22518 | elapsed:   15.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final preprocessing shape: 925\n",
            "preprocessing /chatdata/chat-baseline-300014.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/PediatricApneaDetection/data/chat/preprocessing.py:98: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw.set_annotations(annotations)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:52:12 --- Processing chat-baseline-300014.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done  12 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=8)]: Done 2040 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=8)]: Done 13560 tasks      | elapsed:   10.2s\n",
            "[Parallel(n_jobs=8)]: Done 23928 tasks      | elapsed:   18.1s\n",
            "[Parallel(n_jobs=8)]: Done 24246 out of 24246 | elapsed:   18.5s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final preprocessing shape: 920\n",
            "preprocessing /chatdata/chat-baseline-300019.edf\n",
            "17:53:21 --- Processing chat-baseline-300019.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done  18 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=8)]: Done 1720 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=8)]: Done 12920 tasks      | elapsed:   14.5s\n",
            "[Parallel(n_jobs=8)]: Done 27423 tasks      | elapsed:   24.3s\n",
            "[Parallel(n_jobs=8)]: Done 27954 out of 27954 | elapsed:   25.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final preprocessing shape: 976\n",
            "preprocessing /chatdata/chat-baseline-300008.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/PediatricApneaDetection/data/chat/preprocessing.py:98: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw.set_annotations(annotations)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:54:59 --- Processing chat-baseline-300008.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done  12 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=8)]: Done 1016 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=8)]: Done 3896 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=8)]: Done 7928 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=8)]: Done 13112 tasks      | elapsed:   21.0s\n",
            "[Parallel(n_jobs=8)]: Done 19417 tasks      | elapsed:   29.8s\n",
            "[Parallel(n_jobs=8)]: Done 19476 out of 19476 | elapsed:   29.9s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final preprocessing shape: 932\n",
            "preprocessing /chatdata/chat-baseline-300021.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/PediatricApneaDetection/data/chat/preprocessing.py:98: RuntimeWarning: Limited 2 annotation(s) that were expanding outside the data range.\n",
            "  raw.set_annotations(annotations)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:57:20 --- Processing chat-baseline-300021.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done  12 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=8)]: Done 1528 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=8)]: Done 7288 tasks      | elapsed:    6.1s\n",
            "[Parallel(n_jobs=8)]: Done 15352 tasks      | elapsed:   14.1s\n",
            "[Parallel(n_jobs=8)]: Done 23612 tasks      | elapsed:   20.9s\n",
            "[Parallel(n_jobs=8)]: Done 23724 out of 23724 | elapsed:   21.1s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final preprocessing shape: 1011\n",
            "preprocessing /chatdata/chat-baseline-300024.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/PediatricApneaDetection/data/chat/preprocessing.py:98: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw.set_annotations(annotations)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:58:36 --- Processing chat-baseline-300024.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done  12 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=8)]: Done 2040 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=8)]: Done 13560 tasks      | elapsed:    9.2s\n",
            "[Parallel(n_jobs=8)]: Done 20466 out of 20466 | elapsed:   13.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final preprocessing shape: 785\n",
            "preprocessing /chatdata/chat-baseline-300001.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/PediatricApneaDetection/data/chat/preprocessing.py:98: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw.set_annotations(annotations)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17:59:23 --- Processing chat-baseline-300001.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=8)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=8)]: Done  18 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=8)]: Done 1720 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=8)]: Done 7480 tasks      | elapsed:    7.3s\n",
            "[Parallel(n_jobs=8)]: Done 15544 tasks      | elapsed:   14.9s\n",
            "[Parallel(n_jobs=8)]: Done 19350 out of 19350 | elapsed:   18.6s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final preprocessing shape: 955\n",
            "preprocessing /chatdata/chat-baseline-300015.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/PediatricApneaDetection/data/chat/preprocessing.py:98: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
            "  raw.set_annotations(annotations)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18:00:43 --- Processing chat-baseline-300015.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
            "[Parallel(n_jobs=8)]: Done  12 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=8)]: Done 1016 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=8)]: Done 3896 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=8)]: Done 7928 tasks      | elapsed:   12.8s\n",
            "[Parallel(n_jobs=8)]: Done 13112 tasks      | elapsed:   19.9s\n",
            "[Parallel(n_jobs=8)]: Done 19448 tasks      | elapsed:   30.2s\n",
            "[Parallel(n_jobs=8)]: Done 20214 out of 20214 | elapsed:   31.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final preprocessing shape: 690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Commented to allow rest of notebook to run. (No Data processing/loading/training for Submission)\n",
        "# moves npz files to processed folder\n",
        "\n",
        "# root = '/content/'\n",
        "# chat_out = '/content/chatprocessed/'\n",
        "# os.makedirs(os.path.dirname(chat_out), exist_ok=True)\n",
        "\n",
        "# for npz_file in glob.glob(root + \"*.npz\"):\n",
        "\n",
        "#   print(npz_file)\n",
        "\n",
        "#   dest = chat_out + npz_file.replace(\"/content/\",\"\").replace(\"\\\\\",\"\")\n",
        "\n",
        "#   print(dest)\n",
        "\n",
        "#   os.rename(npz_file, dest)\n",
        "\n",
        "#upload to box (TODO)"
      ],
      "metadata": {
        "id": "uNftpb3V3yt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3afda09b-47f7-4895-ae7b-f97cc15f3e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/\\chat-baseline-300002.edf_243_207.npz\n",
            "/content/chatprocessed/chat-baseline-300002.edf_243_207.npz\n",
            "/content/\\chat-baseline-300014.edf_1069_763.npz\n",
            "/content/chatprocessed/chat-baseline-300014.edf_1069_763.npz\n",
            "/content/\\chat-baseline-300021.edf_35_191.npz\n",
            "/content/chatprocessed/chat-baseline-300021.edf_35_191.npz\n",
            "/content/\\chat-baseline-300007.edf_16_160.npz\n",
            "/content/chatprocessed/chat-baseline-300007.edf_16_160.npz\n",
            "/content/\\chat-baseline-300004.edf_212_370.npz\n",
            "/content/chatprocessed/chat-baseline-300004.edf_212_370.npz\n",
            "/content/\\chat-baseline-300015.edf_108_12.npz\n",
            "/content/chatprocessed/chat-baseline-300015.edf_108_12.npz\n",
            "/content/\\chat-baseline-300019.edf_196_337.npz\n",
            "/content/chatprocessed/chat-baseline-300019.edf_196_337.npz\n",
            "/content/\\chat-baseline-300001.edf_160_104.npz\n",
            "/content/chatprocessed/chat-baseline-300001.edf_160_104.npz\n",
            "/content/\\chat-baseline-300024.edf_7_843.npz\n",
            "/content/chatprocessed/chat-baseline-300024.edf_7_843.npz\n",
            "/content/\\chat-baseline-300008.edf_186_103.npz\n",
            "/content/chatprocessed/chat-baseline-300008.edf_186_103.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CHAT Data Loading\n",
        "Chat Data Loading is done as dollowed:\n",
        "\n",
        "*   Path is provided containing processed \\*.npz files (from previous steps)\n",
        "*   Divide studies into folds (5 folds used here). For example, if 10 processed files are in the folder, each fold will have data from 2 processed files.\n",
        "*   For each study in each fold, the signals, apnea labels, and hypopnea labels are loaded.\n",
        "*   Then, the apnea labels and hypopnea labels are combined to y_c.\n",
        "*   To reduce the size of the data and improve model training performance, negative sampling is conducted. This is done by getting indexes for where y_c == 0 (negative samples) and where y_c>0 (positive samples). Then, a ratio between number of positive_samples and negative_samples is used to determine how many negative samples should be kept. The index of the kept negative_samples is stored in negative_survived as shown below. Only the indexes in negative_survived and positive_samples are kept in the data.\n",
        "*   Extract_rri is used to ensure ECG signal has equal length data points to other signals (EPOCH_LENGTH * FREQ). This is 30\\*128=3840, which can be found in the model input size shown later.\n",
        "\n"
      ],
      "metadata": {
        "id": "YWQj8JjAvafM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# due to hardcoded values, we had to copy the dataloader code and change it slightly to be able to run it\n",
        "# from - https://github.com/healthylaife/Pediatric-Apnea-Detection/blob/main/data/chat/dataloader.py\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.signal import resample\n",
        "from biosppy.signals.ecg import hamilton_segmenter, correct_rpeaks\n",
        "from biosppy.signals import tools as st\n",
        "from scipy.interpolate import splev, splrep\n",
        "\n",
        "from PediatricApneaDetection.data.chat import dataloader\n",
        "\n",
        "SIGS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
        "s_count = len(SIGS)\n",
        "\n",
        "FREQ = 128\n",
        "EPOCH_LENGTH = 30\n",
        "ECG_SIG = 8\n",
        "\n",
        "def load_data(path):\n",
        "    # demo = pd.read_csv(\"../misc/result.csv\")\n",
        "    # ahi = pd.read_csv(r\"C:\\Data\\AHI.csv\")\n",
        "    # ahi_dict = dict(zip(ahi.Study, ahi.AHI))\n",
        "    root_dir = os.path.expanduser(path)\n",
        "    file_list = os.listdir(root_dir)\n",
        "    print(file_list)\n",
        "    length = len(file_list)\n",
        "\n",
        "    ################################### Fold the data based on number of respiratory events #########################\n",
        "    study_event_counts = [i for i in range(0, length)]\n",
        "    folds = []\n",
        "    for i in range(5):\n",
        "        folds.append(study_event_counts[i::5])\n",
        "\n",
        "    x = []\n",
        "    y_apnea = []\n",
        "    y_hypopnea = []\n",
        "    counter = 0\n",
        "    for idx, fold in enumerate(folds):\n",
        "        first = True\n",
        "        for patient in fold:\n",
        "            rri_succ_counter = 0\n",
        "            rri_fail_counter = 0\n",
        "            counter += 1\n",
        "            print(counter)\n",
        "            # for study in glob.glob(PATH + patient[0] + \"_*\"):\n",
        "            study_data = np.load(path + file_list[patient - 1])\n",
        "            signals = study_data['data']\n",
        "            labels_apnea = study_data['labels_apnea']\n",
        "            labels_hypopnea = study_data['labels_hypopnea']\n",
        "\n",
        "            # identifier = study.split('\\\\')[-1].split('_')[0] + \"_\" + study.split('\\\\')[-1].split('_')[1]\n",
        "            # demo_arr = demo[demo['id'] == identifier].drop(columns=['id']).to_numpy().squeeze()\n",
        "\n",
        "            y_c = labels_apnea + labels_hypopnea\n",
        "            neg_samples = np.where(y_c == 0)[0]\n",
        "            pos_samples = list(np.where(y_c > 0)[0])\n",
        "            ratio = len(pos_samples) / len(neg_samples)\n",
        "            neg_survived = []\n",
        "            for s in range(len(neg_samples)):\n",
        "                if random.random() < ratio:\n",
        "                    neg_survived.append(neg_samples[s])\n",
        "            samples = neg_survived + pos_samples\n",
        "            signals = signals[samples, :, :]\n",
        "            labels_apnea = labels_apnea[samples]\n",
        "            labels_hypopnea = labels_hypopnea[samples]\n",
        "\n",
        "            data = np.zeros((signals.shape[0], EPOCH_LENGTH * FREQ, s_count + 2))\n",
        "            for i in range(signals.shape[0]):  # for each epoch\n",
        "                # data[i, :len(demo_arr), -3] = demo_arr\n",
        "                data[i, :, -1], data[i, :, -2], status = dataloader.extract_rri(signals[i, ECG_SIG, :], FREQ,\n",
        "                                                                     float(EPOCH_LENGTH))\n",
        "\n",
        "                if status:\n",
        "                    rri_succ_counter += 1\n",
        "                else:\n",
        "                    rri_fail_counter += 1\n",
        "\n",
        "                for j in range(s_count):  # for each signal\n",
        "                    data[i, :, j] = signals[i, SIGS[j], :]\n",
        "\n",
        "            if first:\n",
        "                aggregated_data = data\n",
        "                aggregated_label_apnea = labels_apnea\n",
        "                aggregated_label_hypopnea = labels_hypopnea\n",
        "                first = False\n",
        "            else:\n",
        "                aggregated_data = np.concatenate((aggregated_data, data), axis=0)\n",
        "                aggregated_label_apnea = np.concatenate((aggregated_label_apnea, labels_apnea), axis=0)\n",
        "                aggregated_label_hypopnea = np.concatenate((aggregated_label_hypopnea, labels_hypopnea), axis=0)\n",
        "            print(rri_succ_counter, rri_fail_counter)\n",
        "\n",
        "        x.append(aggregated_data)\n",
        "        y_apnea.append(aggregated_label_apnea)\n",
        "        y_hypopnea.append(aggregated_label_hypopnea)\n",
        "\n",
        "    return x, y_apnea, y_hypopnea\n"
      ],
      "metadata": {
        "id": "Yz6fikII_F2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove file to avoid issues in dataload\n",
        "%rmdir /content/chatprocessed/.ipynb_checkpoints"
      ],
      "metadata": {
        "id": "xW3u5Qi6ZOte",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e92dc4-a2ae-4f3c-bc4c-68ba7cee307d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rmdir: failed to remove '/content/chatprocessed/.ipynb_checkpoints': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Commented to allow rest of notebook to run (No Data processing/loading/training for Submission)\n",
        "\n",
        "# PATH = chat_out\n",
        "# OUT_PATH = '/content/chatloader/'\n",
        "# os.makedirs(os.path.dirname(OUT_PATH), exist_ok=True)\n",
        "\n",
        "# # load data\n",
        "# x, y_apnea, y_hypopnea = load_data(PATH)\n",
        "# # save data into .npz file\n",
        "# for i in range(5):\n",
        "#       print(x[i].shape, y_apnea[i].shape, y_hypopnea[i].shape)\n",
        "#       np.savez_compressed(OUT_PATH + \"chat_\" + str(i), x=x[i], y_apnea=y_apnea[i], y_hypopnea=y_hypopnea[i])\n",
        "\n",
        "# np.savez_compressed(OUT_PATH + \"chat_1\", x=x, y_apnea=y_apnea, y_hypopnea=y_hypopnea) #doesn't work because of mismatching shapes after first dimension\n",
        "\n"
      ],
      "metadata": {
        "id": "ZiQ3LfV49mCN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404ce1f3-7c41-4a0c-fd30-901688921505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['chat-baseline-300015.edf_108_12.npz', 'chat-baseline-300004.edf_212_370.npz', 'chat-baseline-300008.edf_186_103.npz', 'chat-baseline-300019.edf_196_337.npz', 'chat-baseline-300014.edf_1069_763.npz', 'chat-baseline-300002.edf_243_207.npz', 'chat-baseline-300001.edf_160_104.npz', 'chat-baseline-300024.edf_7_843.npz', 'chat-baseline-300007.edf_16_160.npz', 'chat-baseline-300021.edf_35_191.npz']\n",
            "[[0, 5], [1, 6], [2, 7], [3, 8], [4, 9]]\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "1\n",
            "41 0\n",
            "2\n",
            "278 0\n",
            "3\n",
            "22 0\n",
            "4\n",
            "66 0\n",
            "5\n",
            "101 0\n",
            "6\n",
            "48 0\n",
            "7\n",
            "71 0\n",
            "8\n",
            "160 0\n",
            "9\n",
            "107 0\n",
            "10\n",
            "40 0\n",
            "(319, 3840, 17) (319,) (319,)\n",
            "(88, 3840, 17) (88,) (88,)\n",
            "(149, 3840, 17) (149,) (149,)\n",
            "(231, 3840, 17) (231,) (231,)\n",
            "(147, 3840, 17) (147,) (147,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r chatprocessed.zip chatprocessed/\n",
        "# !zip -r chatloader.zip chatloader/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igPZzqKAPu59",
        "outputId": "d5aec189-e480-46c4-f330-49865bbca485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: chatprocessed/ (stored 0%)\n",
            "  adding: chatprocessed/chat-baseline-300015.edf_108_12.npz (deflated 0%)\n",
            "  adding: chatprocessed/chat-baseline-300004.edf_212_370.npz (deflated 0%)\n",
            "  adding: chatprocessed/chat-baseline-300008.edf_186_103.npz (deflated 0%)\n",
            "  adding: chatprocessed/chat-baseline-300019.edf_196_337.npz (deflated 0%)\n",
            "  adding: chatprocessed/chat-baseline-300014.edf_1069_763.npz (deflated 0%)\n",
            "  adding: chatprocessed/chat-baseline-300002.edf_243_207.npz (deflated 0%)\n",
            "  adding: chatprocessed/chat-baseline-300001.edf_160_104.npz (deflated 0%)\n",
            "  adding: chatprocessed/chat-baseline-300024.edf_7_843.npz (deflated 0%)\n",
            "  adding: chatprocessed/chat-baseline-300007.edf_16_160.npz (deflated 0%)\n",
            "  adding: chatprocessed/chat-baseline-300021.edf_35_191.npz (deflated 0%)\n",
            "  adding: chatloader/ (stored 0%)\n",
            "  adding: chatloader/chat_2.npz (deflated 0%)\n",
            "  adding: chatloader/chat_1.npz (deflated 0%)\n",
            "  adding: chatloader/chat_4.npz (deflated 0%)\n",
            "  adding: chatloader/chat_3.npz (deflated 0%)\n",
            "  adding: chatloader/chat_0.npz (deflated 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Model\n",
        "The model includes the model definitation which usually is a class, model training, and other necessary parts.\n",
        "  * Model architecture: layer number/size/type, activation function, etc\n",
        "  * Training objectives: loss function, optimizer, weight of each loss term, etc\n",
        "  * Others: whether the model is pretrained, Monte Carlo simulation for uncertainty analysis, etc\n",
        "  * The code of model should have classes of the model, functions of model training, model validation, etc.\n",
        "  * If your model training is done outside of this notebook, please upload the trained model here and develop a function to load and test it.\n",
        "\n",
        "---\n",
        "\n",
        "Similar to whatâ€™s documented in the original paper, we will be implementing a model consisting of four components: segmentor, tokenizer, transformer, and multi-layer perceptron.\n",
        "\n",
        "The segmentor will divide signals into equal-length epochs and forward them to the tokenizer. (This is done through pre-processing/dataloading steps shown previously.)\n",
        "\n",
        "The tokenizer will construct tokenized representations of the segmentorâ€™s output. Once these tokens have been generated, they will be passed to the transformer.\n",
        "*   The tokenizer will handle regular and irregular time series data as well as data in tabular format. For consistency, data from all three formats will be resampled using a desired frequency (shown in pre-processing/dataloading).\n",
        "*   Tokenizing can be seen in the model code below, between Input1 and before looping through transformer layers. Note that the Input shape is (Freq*Epoch_length, Num_signals). This input shapes needs to match what was created in preprocessing + dataloading steps.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The transformer will be constructed using five encoder modules. Each encoder module will consist of multi-head attention and a position-wise feed-forward network, supplemented by residual and normalization layers. The inspiration for each encoder module came from already established transformer architecture (Vaswani et al. 2017a); note we will not be using the decoder component from this architecture as it is typically used for generative tasks and thus is not needed for our model. The multi-head attention will consist of concatenated attention heads and a final fully connected layer to facilitate the modelâ€™s ability to focus on information across various representation sub-spaces. In terms of the position-wise feed- forward network, it will be comprised of one fully connected layer followed by a ReLU activation unit and then another fully connected layer. Output from the transformer unit will be forwarded to the multi-layer perceptron for analysis and prediction.\n",
        "\n",
        "The multi-layer perceptron will be a two-layer fully connected network for forecasting the likelihood of an apnea-hypopnea event happening within a given epoch. The initial and subsequent layers of this network will consist of 256 and 128 neurons, respectively. Our model will use binary cross-entropy to determine loss."
      ],
      "metadata": {
        "id": "3muyDPFPbozY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Draft Mistake** The model we created is actually the hybrid-transformer (Hu et al., 2022) that the author's compared their original model to. When checking the author's GitHub Repository, it looks like the last configuration they setup was for the comparison to the hybrid-transformer, which led to our confusion. Due to first draft deadline, we will not be able to train the author's model in time. For the final draft, we will train and test the author's original model (provided in line 109 https://github.com/healthylaife/Pediatric-Apnea-Detection/blob/main/models/models.py)."
      ],
      "metadata": {
        "id": "uAe2BdBGMDdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this function is provided in the paper's github repo but we included it here for clarity/describing key components\n",
        "# from create_hybrid_transformer_model - https://github.com/healthylaife/Pediatric-Apnea-Detection/blob/main/models/transformer.py\n",
        "\n",
        "class Patches(Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, input):\n",
        "        input = input[:, tf.newaxis, :, :]\n",
        "        batch_size = tf.shape(input)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=input,\n",
        "            sizes=[1, 1, self.patch_size, 1],\n",
        "            strides=[1, 1, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches,\n",
        "                             [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "\n",
        "class PatchEncoder(Layer):\n",
        "    def __init__(self, num_patches, projection_dim, l2_weight):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.projection_dim = projection_dim\n",
        "        self.l2_weight = l2_weight\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = Dense(units=projection_dim, kernel_regularizer=L2(l2_weight),\n",
        "                                bias_regularizer=L2(l2_weight))\n",
        "        self.position_embedding = tf.keras.layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim)\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch)# + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "def mlp(x, hidden_units, dropout_rate, l2_weight):\n",
        "    for _, units in enumerate(hidden_units):\n",
        "        x = Dense(units, activation=None, kernel_regularizer=L2(l2_weight), bias_regularizer=L2(l2_weight))(x)\n",
        "        x = tf.nn.gelu(x)\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "#input shape used in paper (didn't work): ((60 * 32, 3))\n",
        "#Used ((128*30,3)) which matches dataloader.\n",
        "def create_model(input_shape):\n",
        "    transformer_units = [32,32]\n",
        "    transformer_layers = 2\n",
        "    num_heads = 4\n",
        "    l2_weight = 0.001\n",
        "    drop_out= 0.25\n",
        "    mlp_head_units = [256, 128]\n",
        "    num_patches= 30\n",
        "    projection_dim= 32\n",
        "\n",
        "    input1 = Input(shape=input_shape)\n",
        "    conv11 = Conv1D(16, 256)(input1)\n",
        "    conv12 = Conv1D(16, 256)(input1)\n",
        "    conv13 = Conv1D(16, 256)(input1)\n",
        "\n",
        "    pwconv1 = SeparableConvolution1D(32, 1)(input1)\n",
        "    pwconv2 = SeparableConvolution1D(32, 1)(pwconv1)\n",
        "\n",
        "    conv21 = Conv1D(16, 256)(conv11)\n",
        "    conv22 = Conv1D(16, 256)(conv12)\n",
        "    conv23 = Conv1D(16, 256)(conv13)\n",
        "\n",
        "    concat = concatenate([conv21, conv22, conv23], axis=-1)\n",
        "    concat = Dense(64, activation=relu)(concat)\n",
        "    concat = Dense(64, activation=sigmoid)(concat)\n",
        "    concat = SeparableConvolution1D(32,1)(concat)\n",
        "    concat = concatenate([concat, pwconv2], axis=1)\n",
        "\n",
        "    ####################################################################################################################\n",
        "    patch_size = input_shape[0] / num_patches\n",
        "\n",
        "    normalized_inputs = tfa.layers.InstanceNormalization(axis=-1, epsilon=1e-6, center=False, scale=False,\n",
        "                                                            beta_initializer=\"glorot_uniform\",\n",
        "                                                            gamma_initializer=\"glorot_uniform\")(concat)\n",
        "\n",
        "    patches = Patches(patch_size=patch_size)(normalized_inputs)\n",
        "    encoded_patches = PatchEncoder(num_patches=num_patches, projection_dim=projection_dim, l2_weight=l2_weight)(patches)\n",
        "\n",
        "    for i in range(transformer_layers):\n",
        "        x1 = encoded_patches # LayerNormalization(epsilon=1e-6)(encoded_patches) # TODO\n",
        "        attention_output = MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim, dropout=drop_out, kernel_regularizer=L2(l2_weight),  # i *\n",
        "            bias_regularizer=L2(l2_weight))(x1, x1)\n",
        "        x2 = Add()([attention_output, encoded_patches])\n",
        "        x3 = LayerNormalization(epsilon=1e-6)(x2)\n",
        "        x3 = mlp(x3, transformer_units, drop_out, l2_weight)  # i *\n",
        "        encoded_patches = Add()([x3, x2])\n",
        "\n",
        "    x = LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    #x = Concatenate()([x, demo])\n",
        "    features = mlp(x, mlp_head_units, 0.0, l2_weight)\n",
        "\n",
        "    logits = Dense(1, kernel_regularizer=L2(l2_weight), bias_regularizer=L2(l2_weight),\n",
        "                   activation='sigmoid')(features)\n",
        "\n",
        "    ####################################################################################################################\n",
        "\n",
        "    model = Model(inputs=input1, outputs=logits)\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "3m450bfOHpjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model + training code is similar to https://github.com/healthylaife/Pediatric-Apnea-Detection/blob/main/train.py with slight adjustments and documentation\n",
        "\n",
        "# Commented to let rest of model to run. (No Data processing/loading/training for Submission). We will be loading model from drive.\n",
        "# model = create_model((128 * 30, 3))\n",
        "loss_func = BinaryCrossentropy()\n",
        "optimizer = \"adam\"\n",
        "\n",
        "#Prevent over-fitting on same fold.\n",
        "def lr_schedule(epoch, lr):\n",
        "\n",
        "    if epoch > 50 and (epoch - 1) % 5 == 0:\n",
        "        lr *= 0.5\n",
        "\n",
        "    return lr"
      ],
      "metadata": {
        "id": "5ld8EHtnrZ_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Training\n",
        "*   Load data from each fold and append to list.\n",
        "*   For each fold, set y = 1 for any seconds of apnea/hypopnea events and adjust x to only contain required signals (currently only [\"ECG\", \"SPO2\"])\n",
        "*   For each fold, we generate x_train and y_train based on data from all other folds. Then, the model is trainined on this set for 100 epochs. The epochs can be stopped early from early_stopper if loss isn't improving. LR_scheduled is used to reduce learning rate after 50 epochs to avoid over-fitting in the fold.\n",
        "*   A model for each fold is created and saved.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vSSZ38_J_ig7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training function for model\n",
        "\n",
        "def train(config, fold):\n",
        "  FOLD = fold\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(FOLD):\n",
        "    data = np.load(config[\"data_path\"] + str(i) + \".npz\", allow_pickle=True)\n",
        "    x.append(data['x'])\n",
        "    y.append(data['y_apnea'] + data['y_hypopnea'])\n",
        "\n",
        "  #x for specific channels\n",
        "  # print(x.shape)\n",
        "  x_chan = []\n",
        "  #  np.zeros( (x.shape[0],x.shape[1],x.shape[2], len(config[\"channels\"])))\n",
        "\n",
        "  print(len(x))\n",
        "  for i in range(FOLD):\n",
        "    x[i], y[i] = shuffle(x[i], y[i])\n",
        "    x[i] = np.nan_to_num(x[i], nan=-1)\n",
        "    y[i] = np.where(y[i] >= 1, 1, 0)\n",
        "    print(x[i].shape)\n",
        "    #Select specific channels from data.\n",
        "    x_chan.append(x[i][:, :, config[\"channels\"]])\n",
        "    print(x_chan[i].shape)\n",
        "\n",
        "  print(\"training\")\n",
        "  for fold in range(FOLD):\n",
        "    x_train, y_train = None, None\n",
        "    for i in range(FOLD):\n",
        "      if i != fold:\n",
        "        if isinstance(x_train, np.ndarray):\n",
        "          # x_train = x[i]\n",
        "          # y_train = y[i]\n",
        "          x_train = np.concatenate((x_train, x_chan[i]))\n",
        "          y_train = np.concatenate((y_train, y[i]))\n",
        "        else:\n",
        "          # x_train = np.concatenate((x_train, x[i]))\n",
        "          # y_train = np.concatenate((y_train, y[i]))\n",
        "          x_train = x_chan[i]\n",
        "          y_train = y[i]\n",
        "    print(x_train.shape)\n",
        "    print(y_train.shape)\n",
        "    model.compile(optimizer=optimizer, loss=loss_func,metrics=[keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "\n",
        "    # Early stopping stops training when\n",
        "    # the training loss is no longer going down by much, so it's not worth it to continue training\n",
        "    early_stopper = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "    model.fit(x=x_train, y=y_train, batch_size=512, epochs=config[\"epochs\"], validation_split=0.1,\n",
        "                    callbacks=[early_stopper, lr_scheduler])\n",
        "    model.save(config[\"model_path\"] + config[\"model_name\"] + str(fold))\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "  print(\"training complete\")\n"
      ],
      "metadata": {
        "id": "gBdVZoTvsSFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from - https://github.com/healthylaife/Pediatric-Apnea-Detection/blob/main/main_chat.py with slight modifications\n",
        "# Commented to allow for rest of notebook to run. (No Data processing/loading/training for Submission)\n",
        "\n",
        "# data_path = '/content/chatloader/'\n",
        "# model_path = '/content/model/'\n",
        "# os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "# sig_dict_chat = {\n",
        "#     \"EOG\": [0, 1],\n",
        "#     \"EEG\": [4, 5],\n",
        "#     \"ECG\": [15,16],\n",
        "#     \"Resp\": [9, 10],\n",
        "#     \"SPO2\": [13],\n",
        "#     \"CO2\": [14],\n",
        "# }\n",
        "\n",
        "# channel_list_chat = [\n",
        "#     [\"ECG\", \"SPO2\"],\n",
        "# ]\n",
        "\n",
        "# for ch in channel_list_chat:\n",
        "#     chs = []\n",
        "#     chstr = \"\"\n",
        "#     for name in ch:\n",
        "#         chstr += name\n",
        "#         chs = chs + sig_dict_chat[name]\n",
        "#     print(chstr, chs)\n",
        "#     config = {\n",
        "#         \"data_path\": data_path + 'chat_',\n",
        "#         \"model_path\": model_path,\n",
        "#         \"model_name\": \"model_hybrid_\"+ chstr,\n",
        "#         \"regression\": False,\n",
        "#         \"epochs\": 100,  # best 200\n",
        "#         \"channels\": chs,\n",
        "#     }\n",
        "#     train(config, 5)"
      ],
      "metadata": {
        "id": "7EobMyiMGSDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98550cf-a051-46a8-d463-dcee774b75a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "5\n",
            "(319, 3840, 17)\n",
            "(319, 3840, 3)\n",
            "(88, 3840, 17)\n",
            "(88, 3840, 3)\n",
            "(149, 3840, 17)\n",
            "(149, 3840, 3)\n",
            "(231, 3840, 17)\n",
            "(231, 3840, 3)\n",
            "(147, 3840, 17)\n",
            "(147, 3840, 3)\n",
            "training\n",
            "(615, 3840, 3)\n",
            "(615,)\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 52s 5s/step - loss: 1.2187 - precision: 0.5000 - recall: 0.0691 - val_loss: 1.1997 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 3s 379ms/step - loss: 1.1982 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.1804 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 3s 421ms/step - loss: 1.1777 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.1613 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 3s 418ms/step - loss: 1.1558 - precision: 0.7143 - recall: 0.0182 - val_loss: 1.1423 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 3s 420ms/step - loss: 1.1366 - precision: 0.6825 - recall: 0.1564 - val_loss: 1.1224 - val_precision: 0.5833 - val_recall: 0.2188 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 3s 380ms/step - loss: 1.1180 - precision: 0.6327 - recall: 0.5636 - val_loss: 1.1052 - val_precision: 0.5246 - val_recall: 1.0000 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 3s 376ms/step - loss: 1.1045 - precision: 0.5271 - recall: 0.6727 - val_loss: 1.0879 - val_precision: 0.6061 - val_recall: 0.6250 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 3s 399ms/step - loss: 1.0840 - precision: 0.5685 - recall: 0.4982 - val_loss: 1.0892 - val_precision: 0.5000 - val_recall: 0.0312 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 3s 415ms/step - loss: 1.0679 - precision: 0.6957 - recall: 0.2327 - val_loss: 1.0787 - val_precision: 0.5000 - val_recall: 0.0312 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 3s 415ms/step - loss: 1.0526 - precision: 0.6929 - recall: 0.3527 - val_loss: 1.0500 - val_precision: 0.6000 - val_recall: 0.0938 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 3s 370ms/step - loss: 1.0375 - precision: 0.6726 - recall: 0.4109 - val_loss: 1.0357 - val_precision: 0.6667 - val_recall: 0.1875 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 3s 345ms/step - loss: 1.0258 - precision: 0.6702 - recall: 0.4582 - val_loss: 1.0362 - val_precision: 0.3333 - val_recall: 0.0312 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 3s 370ms/step - loss: 1.0153 - precision: 0.6228 - recall: 0.5164 - val_loss: 1.0330 - val_precision: 0.3333 - val_recall: 0.0312 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 3s 372ms/step - loss: 1.0039 - precision: 0.6066 - recall: 0.5382 - val_loss: 1.0109 - val_precision: 0.6667 - val_recall: 0.1250 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 3s 411ms/step - loss: 0.9833 - precision: 0.7069 - recall: 0.4473 - val_loss: 1.0093 - val_precision: 0.6667 - val_recall: 0.1250 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 3s 347ms/step - loss: 0.9666 - precision: 0.6938 - recall: 0.4036 - val_loss: 1.0332 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 3s 445ms/step - loss: 0.9639 - precision: 0.7273 - recall: 0.3200 - val_loss: 0.9823 - val_precision: 0.6000 - val_recall: 0.0938 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 3s 364ms/step - loss: 0.9513 - precision: 0.7325 - recall: 0.4182 - val_loss: 0.9693 - val_precision: 0.6207 - val_recall: 0.5625 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 3s 366ms/step - loss: 0.9433 - precision: 0.6239 - recall: 0.7600 - val_loss: 0.9678 - val_precision: 0.5417 - val_recall: 0.4062 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 3s 362ms/step - loss: 0.9574 - precision: 0.5425 - recall: 0.8364 - val_loss: 0.9649 - val_precision: 0.5769 - val_recall: 0.4688 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 3s 402ms/step - loss: 0.9437 - precision: 0.5857 - recall: 0.7455 - val_loss: 0.9459 - val_precision: 0.5806 - val_recall: 0.5625 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 3s 419ms/step - loss: 0.9148 - precision: 0.6810 - recall: 0.5745 - val_loss: 0.9336 - val_precision: 0.6000 - val_recall: 0.7500 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 3s 415ms/step - loss: 0.9175 - precision: 0.6432 - recall: 0.5636 - val_loss: 0.9236 - val_precision: 0.5870 - val_recall: 0.8438 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 3s 411ms/step - loss: 0.9157 - precision: 0.6417 - recall: 0.5600 - val_loss: 0.9155 - val_precision: 0.6170 - val_recall: 0.9062 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 3s 380ms/step - loss: 0.8965 - precision: 0.6653 - recall: 0.5855 - val_loss: 0.9220 - val_precision: 0.5439 - val_recall: 0.9688 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 3s 371ms/step - loss: 0.8887 - precision: 0.6206 - recall: 0.7018 - val_loss: 0.9111 - val_precision: 0.5636 - val_recall: 0.9688 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 3s 408ms/step - loss: 0.8816 - precision: 0.6309 - recall: 0.7273 - val_loss: 0.8903 - val_precision: 0.6176 - val_recall: 0.6562 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 3s 367ms/step - loss: 0.8728 - precision: 0.6371 - recall: 0.6000 - val_loss: 0.8804 - val_precision: 0.6154 - val_recall: 0.7500 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 3s 377ms/step - loss: 0.8624 - precision: 0.6471 - recall: 0.6800 - val_loss: 0.8923 - val_precision: 0.5741 - val_recall: 0.9688 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 3s 396ms/step - loss: 0.8684 - precision: 0.5882 - recall: 0.7636 - val_loss: 0.8880 - val_precision: 0.5741 - val_recall: 0.9688 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 3s 368ms/step - loss: 0.8747 - precision: 0.5677 - recall: 0.7927 - val_loss: 0.8794 - val_precision: 0.6078 - val_recall: 0.9688 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 3s 410ms/step - loss: 0.8661 - precision: 0.5852 - recall: 0.7491 - val_loss: 0.8720 - val_precision: 0.5854 - val_recall: 0.7500 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 3s 396ms/step - loss: 0.8569 - precision: 0.6189 - recall: 0.6436 - val_loss: 0.8704 - val_precision: 0.7500 - val_recall: 0.4688 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 3s 364ms/step - loss: 0.8437 - precision: 0.7286 - recall: 0.5273 - val_loss: 0.8682 - val_precision: 0.7500 - val_recall: 0.3750 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 3s 345ms/step - loss: 0.8430 - precision: 0.7473 - recall: 0.4945 - val_loss: 0.9090 - val_precision: 0.6000 - val_recall: 0.0938 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 3s 388ms/step - loss: 0.8574 - precision: 0.7165 - recall: 0.3309 - val_loss: 0.8731 - val_precision: 0.6667 - val_recall: 0.2500 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 3s 381ms/step - loss: 0.8361 - precision: 0.6694 - recall: 0.5964 - val_loss: 0.8541 - val_precision: 0.6047 - val_recall: 0.8125 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 3s 362ms/step - loss: 0.8374 - precision: 0.5952 - recall: 0.8182 - val_loss: 0.8512 - val_precision: 0.6122 - val_recall: 0.9375 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 3s 364ms/step - loss: 0.8268 - precision: 0.6134 - recall: 0.7673 - val_loss: 0.8500 - val_precision: 0.5882 - val_recall: 0.6250 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 3s 377ms/step - loss: 0.8278 - precision: 0.6500 - recall: 0.6145 - val_loss: 0.8407 - val_precision: 0.6111 - val_recall: 0.6875 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 3s 366ms/step - loss: 0.8366 - precision: 0.7121 - recall: 0.5127 - val_loss: 0.8354 - val_precision: 0.5789 - val_recall: 0.6875 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 3s 389ms/step - loss: 0.8368 - precision: 0.6807 - recall: 0.4109 - val_loss: 0.8785 - val_precision: 0.5200 - val_recall: 0.8125 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 3s 346ms/step - loss: 0.8291 - precision: 0.5848 - recall: 0.7018 - val_loss: 0.8753 - val_precision: 0.5094 - val_recall: 0.8438 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 3s 393ms/step - loss: 0.8414 - precision: 0.5461 - recall: 0.9055 - val_loss: 0.8624 - val_precision: 0.5091 - val_recall: 0.8750 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 3s 390ms/step - loss: 0.8304 - precision: 0.5477 - recall: 0.8982 - val_loss: 0.8542 - val_precision: 0.4909 - val_recall: 0.8438 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 3s 378ms/step - loss: 0.8200 - precision: 0.5920 - recall: 0.7491 - val_loss: 0.8430 - val_precision: 0.5366 - val_recall: 0.6875 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 3s 408ms/step - loss: 0.8161 - precision: 0.6810 - recall: 0.5200 - val_loss: 0.8310 - val_precision: 0.6786 - val_recall: 0.5938 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 3s 411ms/step - loss: 0.8173 - precision: 0.7101 - recall: 0.3564 - val_loss: 0.8189 - val_precision: 0.6176 - val_recall: 0.6562 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 3s 346ms/step - loss: 0.8135 - precision: 0.7006 - recall: 0.4000 - val_loss: 0.8245 - val_precision: 0.5455 - val_recall: 0.9375 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 3s 412ms/step - loss: 0.8085 - precision: 0.6353 - recall: 0.6145 - val_loss: 0.8237 - val_precision: 0.5439 - val_recall: 0.9688 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 3s 344ms/step - loss: 0.8061 - precision: 0.6044 - recall: 0.6000 - val_loss: 0.8190 - val_precision: 0.5439 - val_recall: 0.9688 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 3s 361ms/step - loss: 0.7921 - precision: 0.6154 - recall: 0.6109 - val_loss: 0.8157 - val_precision: 0.5660 - val_recall: 0.9375 - lr: 5.0000e-04\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 3s 395ms/step - loss: 0.7857 - precision: 0.6190 - recall: 0.6145 - val_loss: 0.8168 - val_precision: 0.5490 - val_recall: 0.8750 - lr: 5.0000e-04\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 3s 417ms/step - loss: 0.7791 - precision: 0.6549 - recall: 0.6073 - val_loss: 0.8189 - val_precision: 0.5098 - val_recall: 0.8125 - lr: 5.0000e-04\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 3s 367ms/step - loss: 0.7706 - precision: 0.6318 - recall: 0.6364 - val_loss: 0.8152 - val_precision: 0.5102 - val_recall: 0.7812 - lr: 5.0000e-04\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 3s 405ms/step - loss: 0.7710 - precision: 0.6398 - recall: 0.6073 - val_loss: 0.8137 - val_precision: 0.5532 - val_recall: 0.8125 - lr: 5.0000e-04\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 3s 347ms/step - loss: 0.7707 - precision: 0.6639 - recall: 0.5891 - val_loss: 0.8171 - val_precision: 0.5098 - val_recall: 0.8125 - lr: 2.5000e-04\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 3s 415ms/step - loss: 0.7676 - precision: 0.6579 - recall: 0.6364 - val_loss: 0.8276 - val_precision: 0.5179 - val_recall: 0.9062 - lr: 2.5000e-04\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 3s 391ms/step - loss: 0.7687 - precision: 0.6312 - recall: 0.6909 - val_loss: 0.8395 - val_precision: 0.5088 - val_recall: 0.9062 - lr: 2.5000e-04\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 3s 389ms/step - loss: 0.7613 - precision: 0.6487 - recall: 0.7455 - val_loss: 0.8361 - val_precision: 0.5091 - val_recall: 0.8750 - lr: 2.5000e-04\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 3s 355ms/step - loss: 0.7550 - precision: 0.6334 - recall: 0.7164 - val_loss: 0.8223 - val_precision: 0.5185 - val_recall: 0.8750 - lr: 2.5000e-04\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 3s 414ms/step - loss: 0.7521 - precision: 0.6505 - recall: 0.6836 - val_loss: 0.8181 - val_precision: 0.5385 - val_recall: 0.8750 - lr: 1.2500e-04\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 3s 347ms/step - loss: 0.7500 - precision: 0.6571 - recall: 0.6691 - val_loss: 0.8157 - val_precision: 0.5490 - val_recall: 0.8750 - lr: 1.2500e-04\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 3s 344ms/step - loss: 0.7490 - precision: 0.6487 - recall: 0.6582 - val_loss: 0.8171 - val_precision: 0.5600 - val_recall: 0.8750 - lr: 1.2500e-04\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 3s 405ms/step - loss: 0.7461 - precision: 0.6629 - recall: 0.6436 - val_loss: 0.8155 - val_precision: 0.5385 - val_recall: 0.8750 - lr: 1.2500e-04\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 3s 419ms/step - loss: 0.7477 - precision: 0.6540 - recall: 0.6873 - val_loss: 0.8147 - val_precision: 0.5472 - val_recall: 0.9062 - lr: 1.2500e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x78d208f84b20>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(846, 3840, 3)\n",
            "(846,)\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 29s 15s/step - loss: 0.7629 - precision: 0.6901 - recall: 0.5870 - val_loss: 0.8144 - val_precision: 0.6042 - val_recall: 0.6591 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.7283 - precision: 0.6533 - recall: 0.7527 - val_loss: 0.8194 - val_precision: 0.5362 - val_recall: 0.8409 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.7322 - precision: 0.6164 - recall: 0.8995 - val_loss: 0.8031 - val_precision: 0.6038 - val_recall: 0.7273 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.7101 - precision: 0.6960 - recall: 0.7092 - val_loss: 0.7968 - val_precision: 0.6341 - val_recall: 0.5909 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.7180 - precision: 0.7548 - recall: 0.5353 - val_loss: 0.8070 - val_precision: 0.6364 - val_recall: 0.4773 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.7132 - precision: 0.7230 - recall: 0.5815 - val_loss: 0.7887 - val_precision: 0.6579 - val_recall: 0.5682 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6967 - precision: 0.7062 - recall: 0.7120 - val_loss: 0.7776 - val_precision: 0.6279 - val_recall: 0.6136 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6868 - precision: 0.6845 - recall: 0.7310 - val_loss: 0.7886 - val_precision: 0.6136 - val_recall: 0.6136 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6806 - precision: 0.6627 - recall: 0.7582 - val_loss: 0.7902 - val_precision: 0.6190 - val_recall: 0.5909 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6697 - precision: 0.6842 - recall: 0.7418 - val_loss: 0.7931 - val_precision: 0.6304 - val_recall: 0.6591 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6672 - precision: 0.6789 - recall: 0.7527 - val_loss: 0.7972 - val_precision: 0.6250 - val_recall: 0.6818 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6684 - precision: 0.6737 - recall: 0.7799 - val_loss: 0.7967 - val_precision: 0.6047 - val_recall: 0.5909 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6559 - precision: 0.6659 - recall: 0.7908 - val_loss: 0.8130 - val_precision: 0.6000 - val_recall: 0.4773 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6573 - precision: 0.6923 - recall: 0.7337 - val_loss: 0.8010 - val_precision: 0.6486 - val_recall: 0.5455 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6503 - precision: 0.6749 - recall: 0.8179 - val_loss: 0.7828 - val_precision: 0.6279 - val_recall: 0.6136 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6465 - precision: 0.6667 - recall: 0.8261 - val_loss: 0.7871 - val_precision: 0.6364 - val_recall: 0.6364 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6393 - precision: 0.6993 - recall: 0.7962 - val_loss: 0.7907 - val_precision: 0.6341 - val_recall: 0.5909 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x78d208f84b20>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(785, 3840, 3)\n",
            "(785,)\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 26s 13s/step - loss: 0.7090 - precision: 0.6987 - recall: 0.6374 - val_loss: 0.7812 - val_precision: 0.6034 - val_recall: 0.8140 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6946 - precision: 0.6461 - recall: 0.8275 - val_loss: 0.7846 - val_precision: 0.6182 - val_recall: 0.7907 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6997 - precision: 0.6420 - recall: 0.7865 - val_loss: 0.7785 - val_precision: 0.6444 - val_recall: 0.6744 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.7198 - precision: 0.7090 - recall: 0.6199 - val_loss: 0.7824 - val_precision: 0.6111 - val_recall: 0.5116 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.7089 - precision: 0.7163 - recall: 0.5906 - val_loss: 0.7737 - val_precision: 0.6383 - val_recall: 0.6977 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6869 - precision: 0.6835 - recall: 0.7135 - val_loss: 0.7801 - val_precision: 0.5833 - val_recall: 0.6512 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6914 - precision: 0.6490 - recall: 0.8216 - val_loss: 0.7939 - val_precision: 0.5957 - val_recall: 0.6512 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6876 - precision: 0.6556 - recall: 0.8070 - val_loss: 0.7813 - val_precision: 0.6000 - val_recall: 0.7674 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6642 - precision: 0.6821 - recall: 0.7778 - val_loss: 0.7917 - val_precision: 0.5797 - val_recall: 0.9302 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6687 - precision: 0.6726 - recall: 0.7690 - val_loss: 0.7970 - val_precision: 0.5902 - val_recall: 0.8372 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6527 - precision: 0.6683 - recall: 0.7778 - val_loss: 0.8042 - val_precision: 0.5686 - val_recall: 0.6744 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6613 - precision: 0.6734 - recall: 0.7836 - val_loss: 0.7830 - val_precision: 0.5909 - val_recall: 0.6047 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6573 - precision: 0.6959 - recall: 0.7427 - val_loss: 0.7640 - val_precision: 0.5686 - val_recall: 0.6744 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6606 - precision: 0.6848 - recall: 0.6988 - val_loss: 0.7682 - val_precision: 0.5965 - val_recall: 0.7907 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6570 - precision: 0.6548 - recall: 0.8099 - val_loss: 0.7697 - val_precision: 0.6061 - val_recall: 0.9302 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6512 - precision: 0.6455 - recall: 0.8304 - val_loss: 0.7641 - val_precision: 0.6061 - val_recall: 0.9302 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6435 - precision: 0.6601 - recall: 0.7895 - val_loss: 0.7776 - val_precision: 0.5800 - val_recall: 0.6744 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6534 - precision: 0.6578 - recall: 0.7982 - val_loss: 0.7967 - val_precision: 0.5581 - val_recall: 0.5581 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6716 - precision: 0.6632 - recall: 0.7427 - val_loss: 0.7579 - val_precision: 0.5349 - val_recall: 0.5349 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6518 - precision: 0.6844 - recall: 0.7164 - val_loss: 0.7682 - val_precision: 0.5690 - val_recall: 0.7674 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6439 - precision: 0.6776 - recall: 0.7865 - val_loss: 0.7584 - val_precision: 0.5738 - val_recall: 0.8140 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6562 - precision: 0.6658 - recall: 0.7339 - val_loss: 0.7764 - val_precision: 0.5652 - val_recall: 0.9070 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6419 - precision: 0.6968 - recall: 0.7661 - val_loss: 0.7622 - val_precision: 0.6000 - val_recall: 0.9070 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6381 - precision: 0.6565 - recall: 0.8158 - val_loss: 0.7382 - val_precision: 0.6154 - val_recall: 0.7442 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6352 - precision: 0.6592 - recall: 0.7749 - val_loss: 0.7472 - val_precision: 0.6136 - val_recall: 0.6279 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6257 - precision: 0.7005 - recall: 0.7456 - val_loss: 0.7455 - val_precision: 0.6047 - val_recall: 0.6047 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6224 - precision: 0.6954 - recall: 0.7544 - val_loss: 0.7238 - val_precision: 0.6222 - val_recall: 0.6512 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6155 - precision: 0.7014 - recall: 0.7485 - val_loss: 0.7326 - val_precision: 0.6200 - val_recall: 0.7209 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6099 - precision: 0.6842 - recall: 0.7982 - val_loss: 0.7303 - val_precision: 0.6250 - val_recall: 0.6977 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6080 - precision: 0.6799 - recall: 0.8012 - val_loss: 0.7279 - val_precision: 0.6170 - val_recall: 0.6744 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6167 - precision: 0.7224 - recall: 0.7076 - val_loss: 0.7184 - val_precision: 0.5926 - val_recall: 0.7442 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6040 - precision: 0.7063 - recall: 0.8158 - val_loss: 0.7198 - val_precision: 0.5818 - val_recall: 0.7442 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6089 - precision: 0.6713 - recall: 0.8421 - val_loss: 0.7334 - val_precision: 0.6400 - val_recall: 0.7442 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.5913 - precision: 0.7316 - recall: 0.7573 - val_loss: 0.7661 - val_precision: 0.6061 - val_recall: 0.4651 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6028 - precision: 0.7418 - recall: 0.7310 - val_loss: 0.7597 - val_precision: 0.5745 - val_recall: 0.6279 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6071 - precision: 0.6806 - recall: 0.8099 - val_loss: 0.7551 - val_precision: 0.5606 - val_recall: 0.8605 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6220 - precision: 0.6877 - recall: 0.7661 - val_loss: 0.8188 - val_precision: 0.5833 - val_recall: 0.6512 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6019 - precision: 0.6925 - recall: 0.8099 - val_loss: 0.8335 - val_precision: 0.6129 - val_recall: 0.4419 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6084 - precision: 0.7126 - recall: 0.7105 - val_loss: 0.8238 - val_precision: 0.5476 - val_recall: 0.5349 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6040 - precision: 0.7042 - recall: 0.7865 - val_loss: 0.7676 - val_precision: 0.5833 - val_recall: 0.8140 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.5851 - precision: 0.7113 - recall: 0.7924 - val_loss: 0.7449 - val_precision: 0.5581 - val_recall: 0.5581 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x78d208f84b20>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(703, 3840, 3)\n",
            "(703,)\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 22s 9s/step - loss: 0.6501 - precision: 0.6752 - recall: 0.7524 - val_loss: 0.8217 - val_precision: 0.5091 - val_recall: 0.7568 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 3s 813ms/step - loss: 0.7271 - precision: 0.5845 - recall: 0.9111 - val_loss: 0.7651 - val_precision: 0.5667 - val_recall: 0.9189 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 3s 838ms/step - loss: 0.6952 - precision: 0.6390 - recall: 0.7587 - val_loss: 0.7305 - val_precision: 0.6486 - val_recall: 0.6486 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 3s 766ms/step - loss: 0.6773 - precision: 0.6950 - recall: 0.5714 - val_loss: 0.7348 - val_precision: 0.6190 - val_recall: 0.7027 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 3s 807ms/step - loss: 0.6502 - precision: 0.6881 - recall: 0.7143 - val_loss: 0.7366 - val_precision: 0.6383 - val_recall: 0.8108 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 3s 780ms/step - loss: 0.6617 - precision: 0.7025 - recall: 0.6222 - val_loss: 0.7367 - val_precision: 0.6364 - val_recall: 0.7568 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 3s 841ms/step - loss: 0.6590 - precision: 0.6501 - recall: 0.7905 - val_loss: 0.7209 - val_precision: 0.6458 - val_recall: 0.8378 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 3s 772ms/step - loss: 0.6415 - precision: 0.6867 - recall: 0.6889 - val_loss: 0.7503 - val_precision: 0.6327 - val_recall: 0.8378 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 3s 770ms/step - loss: 0.6441 - precision: 0.6741 - recall: 0.7683 - val_loss: 0.7910 - val_precision: 0.6038 - val_recall: 0.8649 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 3s 818ms/step - loss: 0.6676 - precision: 0.6265 - recall: 0.8254 - val_loss: 0.7771 - val_precision: 0.5532 - val_recall: 0.7027 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 3s 794ms/step - loss: 0.6649 - precision: 0.6507 - recall: 0.7746 - val_loss: 0.7626 - val_precision: 0.6053 - val_recall: 0.6216 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 3s 757ms/step - loss: 0.6797 - precision: 0.7131 - recall: 0.5683 - val_loss: 0.7537 - val_precision: 0.5833 - val_recall: 0.7568 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 3s 794ms/step - loss: 0.6472 - precision: 0.7286 - recall: 0.6476 - val_loss: 0.7445 - val_precision: 0.6122 - val_recall: 0.8108 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 3s 819ms/step - loss: 0.6432 - precision: 0.6845 - recall: 0.7302 - val_loss: 0.7558 - val_precision: 0.5714 - val_recall: 0.6486 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 3s 753ms/step - loss: 0.6307 - precision: 0.6694 - recall: 0.7841 - val_loss: 0.8049 - val_precision: 0.5862 - val_recall: 0.4595 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 3s 760ms/step - loss: 0.6439 - precision: 0.6875 - recall: 0.7333 - val_loss: 0.8458 - val_precision: 0.6667 - val_recall: 0.2162 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 3s 797ms/step - loss: 0.6644 - precision: 0.6645 - recall: 0.6540 - val_loss: 0.8091 - val_precision: 0.5385 - val_recall: 0.3784 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x78d208f84b20>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(787, 3840, 3)\n",
            "(787,)\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 24s 11s/step - loss: 0.6720 - precision: 0.6611 - recall: 0.7746 - val_loss: 0.6958 - val_precision: 0.5897 - val_recall: 0.6970 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6714 - precision: 0.6481 - recall: 0.7521 - val_loss: 0.6877 - val_precision: 0.6400 - val_recall: 0.4848 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6629 - precision: 0.7574 - recall: 0.5803 - val_loss: 0.6941 - val_precision: 0.5714 - val_recall: 0.6061 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6350 - precision: 0.7222 - recall: 0.6958 - val_loss: 0.7151 - val_precision: 0.5490 - val_recall: 0.8485 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6341 - precision: 0.6752 - recall: 0.8141 - val_loss: 0.6970 - val_precision: 0.5714 - val_recall: 0.8485 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6272 - precision: 0.6724 - recall: 0.7746 - val_loss: 0.7033 - val_precision: 0.5714 - val_recall: 0.8485 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6310 - precision: 0.7084 - recall: 0.7324 - val_loss: 0.7072 - val_precision: 0.5714 - val_recall: 0.8485 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6221 - precision: 0.6967 - recall: 0.7831 - val_loss: 0.7115 - val_precision: 0.5625 - val_recall: 0.8182 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6361 - precision: 0.6708 - recall: 0.7690 - val_loss: 0.6808 - val_precision: 0.5455 - val_recall: 0.7273 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6256 - precision: 0.6809 - recall: 0.7634 - val_loss: 0.6622 - val_precision: 0.5778 - val_recall: 0.7879 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6099 - precision: 0.6823 - recall: 0.7803 - val_loss: 0.6770 - val_precision: 0.5652 - val_recall: 0.7879 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6158 - precision: 0.6728 - recall: 0.8282 - val_loss: 0.7097 - val_precision: 0.5200 - val_recall: 0.7879 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6170 - precision: 0.6901 - recall: 0.8028 - val_loss: 0.7080 - val_precision: 0.5400 - val_recall: 0.8182 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6084 - precision: 0.6948 - recall: 0.7887 - val_loss: 0.6931 - val_precision: 0.5490 - val_recall: 0.8485 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.5999 - precision: 0.7079 - recall: 0.8056 - val_loss: 0.6695 - val_precision: 0.5652 - val_recall: 0.7879 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.5895 - precision: 0.7169 - recall: 0.7775 - val_loss: 0.6633 - val_precision: 0.6053 - val_recall: 0.6970 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6110 - precision: 0.7434 - recall: 0.7099 - val_loss: 0.6710 - val_precision: 0.5778 - val_recall: 0.7879 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.5946 - precision: 0.7143 - recall: 0.7887 - val_loss: 0.7047 - val_precision: 0.5185 - val_recall: 0.8485 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6066 - precision: 0.6557 - recall: 0.8958 - val_loss: 0.6809 - val_precision: 0.5400 - val_recall: 0.8182 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6091 - precision: 0.6681 - recall: 0.8958 - val_loss: 0.6405 - val_precision: 0.6053 - val_recall: 0.6970 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.5987 - precision: 0.7120 - recall: 0.7662 - val_loss: 0.6436 - val_precision: 0.5814 - val_recall: 0.7576 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.5980 - precision: 0.7418 - recall: 0.7606 - val_loss: 0.6865 - val_precision: 0.5600 - val_recall: 0.8485 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6000 - precision: 0.7167 - recall: 0.8197 - val_loss: 0.7191 - val_precision: 0.5417 - val_recall: 0.7879 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6121 - precision: 0.6914 - recall: 0.8141 - val_loss: 0.7179 - val_precision: 0.5600 - val_recall: 0.8485 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.5984 - precision: 0.7382 - recall: 0.7944 - val_loss: 0.7274 - val_precision: 0.5490 - val_recall: 0.8485 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6070 - precision: 0.7239 - recall: 0.7606 - val_loss: 0.7135 - val_precision: 0.5455 - val_recall: 0.7273 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.5640 - precision: 0.7212 - recall: 0.7944 - val_loss: 0.7244 - val_precision: 0.5854 - val_recall: 0.7273 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.5837 - precision: 0.7178 - recall: 0.8169 - val_loss: 0.7362 - val_precision: 0.5400 - val_recall: 0.8182 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.5797 - precision: 0.6977 - recall: 0.8451 - val_loss: 0.7664 - val_precision: 0.5641 - val_recall: 0.6667 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6404 - precision: 0.7239 - recall: 0.7606 - val_loss: 0.7501 - val_precision: 0.5098 - val_recall: 0.7879 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.embedding.Embedding object at 0x78d208f84b20>, because it is not built.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r model.zip model/"
      ],
      "metadata": {
        "id": "9hqOfuYCu-aG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42652caa-1f59-4114-b49d-5989f0166129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: model/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO21/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO21/saved_model.pb (deflated 89%)\n",
            "  adding: model/model_hybrid_ECGSPO21/keras_metadata.pb (deflated 94%)\n",
            "  adding: model/model_hybrid_ECGSPO21/assets/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO21/variables/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO21/variables/variables.index (deflated 75%)\n",
            "  adding: model/model_hybrid_ECGSPO21/variables/variables.data-00000-of-00001 (deflated 41%)\n",
            "  adding: model/model_hybrid_ECGSPO21/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO22/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO22/saved_model.pb (deflated 89%)\n",
            "  adding: model/model_hybrid_ECGSPO22/keras_metadata.pb (deflated 94%)\n",
            "  adding: model/model_hybrid_ECGSPO22/assets/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO22/variables/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO22/variables/variables.index (deflated 75%)\n",
            "  adding: model/model_hybrid_ECGSPO22/variables/variables.data-00000-of-00001 (deflated 41%)\n",
            "  adding: model/model_hybrid_ECGSPO22/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO23/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO23/saved_model.pb (deflated 89%)\n",
            "  adding: model/model_hybrid_ECGSPO23/keras_metadata.pb (deflated 94%)\n",
            "  adding: model/model_hybrid_ECGSPO23/assets/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO23/variables/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO23/variables/variables.index (deflated 75%)\n",
            "  adding: model/model_hybrid_ECGSPO23/variables/variables.data-00000-of-00001 (deflated 41%)\n",
            "  adding: model/model_hybrid_ECGSPO23/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO20/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO20/saved_model.pb (deflated 90%)\n",
            "  adding: model/model_hybrid_ECGSPO20/keras_metadata.pb (deflated 94%)\n",
            "  adding: model/model_hybrid_ECGSPO20/assets/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO20/variables/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO20/variables/variables.index (deflated 74%)\n",
            "  adding: model/model_hybrid_ECGSPO20/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: model/model_hybrid_ECGSPO20/fingerprint.pb (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO24/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO24/saved_model.pb (deflated 90%)\n",
            "  adding: model/model_hybrid_ECGSPO24/keras_metadata.pb (deflated 94%)\n",
            "  adding: model/model_hybrid_ECGSPO24/assets/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO24/variables/ (stored 0%)\n",
            "  adding: model/model_hybrid_ECGSPO24/variables/variables.index (deflated 75%)\n",
            "  adding: model/model_hybrid_ECGSPO24/variables/variables.data-00000-of-00001 (deflated 41%)\n",
            "  adding: model/model_hybrid_ECGSPO24/fingerprint.pb (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "In this section, you should finish training your model training or loading your trained model. That is a great experiment! You should share the results with others with necessary metrics and figures.\n",
        "\n",
        "Please test and report results for all experiments that you run with:\n",
        "\n",
        "*   specific numbers (accuracy, AUC, RMSE, etc)\n",
        "*   figures (loss shrinkage, outputs from GAN, annotation or label of sample pictures, etc)\n"
      ],
      "metadata": {
        "id": "gX6bCcZNuxmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download pre-trained model + loaded data for evaluation using gdown.\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1g_yxkCwi4L4hu2H1-mNGeFY9ymsr4nsz/view?usp=drive_link\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1CAtL7c4q1VpSUMeadIwyJIuL2_6aSiz9/view?usp=drive_link\n",
        "!unzip model.zip\n",
        "!unzip chatloader.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elzppl7SUOHj",
        "outputId": "d87be96f-eb9a-4b4d-e440-3d7fa60815c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1g_yxkCwi4L4hu2H1-mNGeFY9ymsr4nsz\n",
            "To: /content/model.zip\n",
            "100% 18.8M/18.8M [00:00<00:00, 110MB/s] \n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1CAtL7c4q1VpSUMeadIwyJIuL2_6aSiz9\n",
            "From (redirected): https://drive.google.com/uc?id=1CAtL7c4q1VpSUMeadIwyJIuL2_6aSiz9&confirm=t&uuid=12eea0e7-aaee-498b-84ad-1942808e0ddc\n",
            "To: /content/chatloader.zip\n",
            "100% 457M/457M [00:03<00:00, 119MB/s] \n",
            "Archive:  model.zip\n",
            "   creating: model/\n",
            "   creating: model/model_hybrid_ECGSPO21/\n",
            "  inflating: model/model_hybrid_ECGSPO21/saved_model.pb  \n",
            "  inflating: model/model_hybrid_ECGSPO21/keras_metadata.pb  \n",
            "   creating: model/model_hybrid_ECGSPO21/assets/\n",
            "   creating: model/model_hybrid_ECGSPO21/variables/\n",
            "  inflating: model/model_hybrid_ECGSPO21/variables/variables.index  \n",
            "  inflating: model/model_hybrid_ECGSPO21/variables/variables.data-00000-of-00001  \n",
            " extracting: model/model_hybrid_ECGSPO21/fingerprint.pb  \n",
            "   creating: model/model_hybrid_ECGSPO22/\n",
            "  inflating: model/model_hybrid_ECGSPO22/saved_model.pb  \n",
            "  inflating: model/model_hybrid_ECGSPO22/keras_metadata.pb  \n",
            "   creating: model/model_hybrid_ECGSPO22/assets/\n",
            "   creating: model/model_hybrid_ECGSPO22/variables/\n",
            "  inflating: model/model_hybrid_ECGSPO22/variables/variables.index  \n",
            "  inflating: model/model_hybrid_ECGSPO22/variables/variables.data-00000-of-00001  \n",
            " extracting: model/model_hybrid_ECGSPO22/fingerprint.pb  \n",
            "   creating: model/model_hybrid_ECGSPO23/\n",
            "  inflating: model/model_hybrid_ECGSPO23/saved_model.pb  \n",
            "  inflating: model/model_hybrid_ECGSPO23/keras_metadata.pb  \n",
            "   creating: model/model_hybrid_ECGSPO23/assets/\n",
            "   creating: model/model_hybrid_ECGSPO23/variables/\n",
            "  inflating: model/model_hybrid_ECGSPO23/variables/variables.index  \n",
            "  inflating: model/model_hybrid_ECGSPO23/variables/variables.data-00000-of-00001  \n",
            " extracting: model/model_hybrid_ECGSPO23/fingerprint.pb  \n",
            "   creating: model/model_hybrid_ECGSPO20/\n",
            "  inflating: model/model_hybrid_ECGSPO20/saved_model.pb  \n",
            "  inflating: model/model_hybrid_ECGSPO20/keras_metadata.pb  \n",
            "   creating: model/model_hybrid_ECGSPO20/assets/\n",
            "   creating: model/model_hybrid_ECGSPO20/variables/\n",
            "  inflating: model/model_hybrid_ECGSPO20/variables/variables.index  \n",
            "  inflating: model/model_hybrid_ECGSPO20/variables/variables.data-00000-of-00001  \n",
            " extracting: model/model_hybrid_ECGSPO20/fingerprint.pb  \n",
            "   creating: model/model_hybrid_ECGSPO24/\n",
            "  inflating: model/model_hybrid_ECGSPO24/saved_model.pb  \n",
            "  inflating: model/model_hybrid_ECGSPO24/keras_metadata.pb  \n",
            "   creating: model/model_hybrid_ECGSPO24/assets/\n",
            "   creating: model/model_hybrid_ECGSPO24/variables/\n",
            "  inflating: model/model_hybrid_ECGSPO24/variables/variables.index  \n",
            "  inflating: model/model_hybrid_ECGSPO24/variables/variables.data-00000-of-00001  \n",
            " extracting: model/model_hybrid_ECGSPO24/fingerprint.pb  \n",
            "Archive:  chatloader.zip\n",
            "   creating: chatloader/\n",
            "  inflating: chatloader/chat_2.npz   \n",
            "  inflating: chatloader/chat_1.npz   \n",
            "  inflating: chatloader/chat_4.npz   \n",
            "  inflating: chatloader/chat_3.npz   \n",
            "  inflating: chatloader/chat_0.npz   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Testing + Results Output\n",
        "Each Model is tested using the that fold's data (since it wasn't used in the training of that model). x_test and y_test are setup similar to the training, except we only use the respective fold's data.\n",
        "\n",
        "We use the author's metrics code to generate the results of the model. Each model's results are added to the results object. Once all fold's results are completed, the metrics are calculated and outputted."
      ],
      "metadata": {
        "id": "wwxM_a4LCtD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Similar to https://github.com/healthylaife/Pediatric-Apnea-Detection/blob/main/test.py with some modications + comments\n",
        "from PediatricApneaDetection.metrics import Result\n",
        "\n",
        "def test(config, fold):\n",
        "  FOLD = fold\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(FOLD):\n",
        "    data = np.load(config[\"data_path\"] + str(i) + \".npz\", allow_pickle=True)\n",
        "    x.append(data['x'])\n",
        "    y.append(data['y_apnea'] + data['y_hypopnea'])\n",
        "\n",
        "  #x for specific channels\n",
        "  x_chan = []\n",
        "\n",
        "  for i in range(FOLD):\n",
        "    x[i], y[i] = shuffle(x[i], y[i])\n",
        "    x[i] = np.nan_to_num(x[i], nan=-1)\n",
        "    y[i] = np.where(y[i] >= 1, 1, 0)\n",
        "    print(x[i].shape)\n",
        "    #Select specific channels from data.\n",
        "    x_chan.append(x[i][:, :, config[\"channels\"]])\n",
        "    print(x_chan[i].shape)\n",
        "\n",
        "  print(\"test starting\")\n",
        "  result = Result()\n",
        "  for i in range(FOLD):\n",
        "    x_test = x_chan[i]\n",
        "    y_test = y[i]\n",
        "    model = tf.keras.models.load_model(config[\"model_path\"] + config[\"model_name\"] + str(i), compile=False)\n",
        "\n",
        "    predict = model.predict(x_test)\n",
        "    y_score = predict\n",
        "    y_predict = np.where(predict > 0.5, 1, 0)\n",
        "\n",
        "    result.add(y_test, y_predict, y_score)\n",
        "\n",
        "  result.print()\n",
        "  result.save(config[\"model_name\"] + \".txt\", config)\n",
        "\n",
        "  del data, x_test, y_test, model, predict, y_score, y_predict"
      ],
      "metadata": {
        "id": "Uw2KniQbYzpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test chat data\n",
        "\n",
        "data_path = '/content/chatloader/'\n",
        "model_path = '/content/model/'\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
        "\n",
        "sig_dict_chat = {\n",
        "    \"EOG\": [0, 1],\n",
        "    \"EEG\": [4, 5],\n",
        "    \"ECG\": [15,16],\n",
        "    \"Resp\": [9, 10],\n",
        "    \"SPO2\": [13],\n",
        "    \"CO2\": [14],\n",
        "}\n",
        "\n",
        "channel_list_chat = [\n",
        "    [\"ECG\", \"SPO2\"],\n",
        "]\n",
        "\n",
        "for ch in channel_list_chat:\n",
        "    chs = []\n",
        "    chstr = \"\"\n",
        "    for name in ch:\n",
        "        chstr += name\n",
        "        chs = chs + sig_dict_chat[name]\n",
        "    print(chstr, chs)\n",
        "    config = {\n",
        "        \"data_path\": data_path + 'chat_',\n",
        "        \"model_path\": model_path,\n",
        "        \"model_name\": \"model_hybrid_\"+ chstr,\n",
        "        \"channels\": chs,\n",
        "    }\n",
        "    test(config, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKgPpZSVe940",
        "outputId": "81ef9deb-576f-47a2-c817-c0040b2fb2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ECGSPO2 [15, 16, 13]\n",
            "(319, 3840, 17)\n",
            "(319, 3840, 3)\n",
            "(88, 3840, 17)\n",
            "(88, 3840, 3)\n",
            "(149, 3840, 17)\n",
            "(149, 3840, 3)\n",
            "(231, 3840, 17)\n",
            "(231, 3840, 3)\n",
            "(147, 3840, 17)\n",
            "(147, 3840, 3)\n",
            "test starting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 18s 2s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 4s 1s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 8s 2s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 11s 1s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:The given value for groups will be overwritten.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 8s 1s/step\n",
            "=========================================================================== \n",
            "[75.23510971786834, 60.22727272727273, 63.08724832214765, 65.36796536796537, 52.38095238095239] \n",
            "[69.63350785340315, 81.81818181818183, 74.4186046511628, 59.11949685534591, 51.14503816793893] \n",
            "[86.36363636363636, 36.734693877551024, 42.10526315789473, 86.23853211009175, 91.78082191780823] \n",
            "[64.84848484848484, 89.74358974358975, 84.93150684931507, 46.72131147540984, 13.513513513513514] \n",
            "[77.10144927536233, 50.70422535211267, 53.78151260504202, 70.14925373134328, 65.68627450980392] \n",
            "[79.89374262101535, 63.73626373626373, 71.17880317231436, 75.15415852007821, 64.29100333209922] \n",
            "[74.20033910409988, 73.1232469559524, 74.49199948320818, 68.03032088965331, 68.73917589493807] \n",
            "Accuracy: 63.26 -+ 7.422 \n",
            "Precision: 67.23 -+ 10.907 \n",
            "Recall: 68.64 -+ 24.006 \n",
            "Specifity: 59.95 -+ 27.810 \n",
            "F1: 63.48 -+ 9.921 \n",
            "AUROC: 70.85 -+ 6.230 \n",
            "AUPRC: 71.72 -+ 2.768 \n",
            "$ 63.3 \\pm 7.4$& $67.2 \\pm 10.9$& $68.6 \\pm 24.0$& $63.5 \\pm 9.9$& $70.9 \\pm 6.2$& \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Comparison"
      ],
      "metadata": {
        "id": "8EAWAy_LwHlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compare your model with others\n",
        "# you don't need to re-run all other experiments, instead, you can directly refer the metrics/numbers in the paper"
      ],
      "metadata": {
        "id": "uOdhGrbwwG71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ECG + SpO2 hybrid-transformer model had the following F1 and AUROC using the CHAT Dataset:\n",
        "* F1: 63.48 -+ 9.921\n",
        "* AUROC: 70.85 -+ 6.230\n",
        "\n",
        "The original paper's ECG + SpO2  had the following F1 and AUROC using the CHAT Dataset (Found in Table 4 of the paper):\n",
        "* F1: 78.8(0.4)\n",
        "* AUROC: 84.9(0.7)"
      ],
      "metadata": {
        "id": "_N9JbHB2ELRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion/Analyses\n",
        "\n",
        "In this section,you should discuss your work and make future plan. The discussion should address the following questions:\n",
        "  * Make assessment that the paper is reproducible or not.\n",
        "  * Explain why it is not reproducible if your results are kind negative.\n",
        "  * Describe â€œWhat was easyâ€ and â€œWhat was difficultâ€ during the reproduction.\n",
        "  * Make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
        "  * What will you do in next phase.\n",
        "\n",
        "---\n",
        "\n",
        "After looking through all the individual components of the original paper, we conclude that the paper is reproducible. Our current model performance might not be the same as what the original paper shows because we currently only processed a small subset of the data, however we are confident that once we utilize all the data available, we can achieve the same results as what is described in the original paper.\n",
        "\n",
        "We will likely get closer to the author's results by re-implementing the model correctly instead of using the hybrid-transformer as we discussed in the models section in **Draft Mistake**.\n",
        "\n",
        "The overall experience of reproducing the paper was satisfying as it had sections that were easy as well as difficult. The easiest section was understanding the overall flow of data throughout the high-level overview of the model. However, the actual implementation of the model was difficult because there were practical decisions that needed to be made. One such decision was where to store the data for easy use of preprocessing, training, and testing; we decided to upload all data to a Box account due to its ability to store large sizes of data and allow for easy connection and retrieval of data for machine learning tasks. Another difficult decision was determining resources that could be used to handle all the machine learning operations; Google Colab is currently being used, however if higher computational resources are needed we may utilize the University of Illinois at Urbana-Champaignâ€™s campus research computing resources. One final difficult decision was whether we should utilize the same functions provided in the original paperâ€™s GitHub; we decided that we could not use the same functions exactly as they were given but instead made some slight modifications to be able to work with our setup. In the process of reproducing the original paper, several helper functions needed to be implemented and many version-specific code libraries were utilized. In the future, these helper functions being available and explicit indications of the versions of libraries used will help improve reproducibility and allow individuals to focus more time on advancing the model and seeing better results.\n",
        "\n",
        "#Final Draft Plans\n",
        "In the next phase, we will first change the model we are using to the author's model to correct the mistake used in this first draft.\n",
        "\n",
        "We will also use more CHAT data to train and test the model. We won't be able to use all the data due to Colab size limitations, however we should be able to use more than what we did in this draft.\n",
        "\n",
        "We want to train models using all 6 signals as well as discussed in the paper (EOG, EEG, ECG, Resp, SpO2, CO2)\n",
        "\n",
        "Create Figure comparing our 2 Signal (ECG, SpO2) model to the authors, as well as compare the 6 signal model.\n",
        "\n",
        "As part of our ablations in our proposal, we will remove 1 transformer layer at a time to see how it affects the model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qH75TNU71eRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "1. Fayyaz H, Strang A, Beheshti R. Bringing At-home Pediatric Sleep Apnea Testing Closer to Reality: A Multi-modal Transformer Approach. Proc Mach Learn Res. 2023 Aug;219:167-185. PMID: 38344396; PMCID: PMC10854997.\n",
        "\n",
        "2. Choi Ji Ho, Kim Eun Joong, Choi June, Kwon Soon Young, Kim Tae Hoon, Lee Sang Hag, Lee Heung Man, Shin Choi, and Lee Seung Hoon. Obstructive sleep apnea syndrome: a child is not just a small adult. Annals of Otology, Rhinology & Laryngology, 119(10): 656â€“661, 2010.\n",
        "\n",
        "3. Gipson Kevin, Lu Mengdi, and Kinane T Bernard. Sleep-disordered breathing in children. Pediatrics in review, 40(1):3, 2019.\n",
        "\n",
        "4. Loughlin GM, Brouillette RT, Brooke LJ, Carroll JL, Chipps BE, England SJ, Ferber P, Ferraro NF, Gaultier C, Givan DC, et al. Standards and indications for cardiopulmonary sleep studies in children. American journal of respiratory and critical care medicine, 153 (2):866â€“878, 1996.\n",
        "\n",
        "5. Marcus Carole L, Brooks Lee J, Ward Sally Davidson, Draper Kari A, Gozal David, Halbower Ann C, Jones Jacqueline, Lehmann Christopher, Schechter Michael S, Sheldon Stephen, et al. Diagnosis and management of childhood obstructive sleep apnea syndrome. Pediatrics, 130(3):e714â€“e755, 2012.\n",
        "\n",
        "6. Spielmanns Marc, Bost David, Windisch Wolfram, Alter Peter, Greulich Tim, Nell Christoph, Storre Jan Henrik, Koczulla Andreas Rembert, and Boeselt Tobias. Measuring sleep quality and\n",
        "efficiency with an activity monitoring device in comparison to polysomnography. Journal of clinical medicine research, 11(12):825, 2019.\n",
        "\n",
        "7. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017b.\n",
        "\n",
        "8. Hu Shuaicong, Cai Wenjie, Gao Tijie, and Wang Mingjie. A hybrid transformer model for obstructive sleep apnea detection based on self-attention mechanism using single-lead ecg. IEEE Transactions on Instrumentation and Measurement, 71:1â€“11, 2022.\n",
        "\n"
      ],
      "metadata": {
        "id": "SHMI2chl9omn"
      }
    }
  ]
}